{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talefty123/testing_code/blob/main/Python/Unstructured/H_DetNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSmcwLZuptDU"
      },
      "source": [
        "# Proposed Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG5fZn_ypunP"
      },
      "source": [
        "# **Biblioheque**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--SvzvIspu-U"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from scipy.stats import rice\n",
        "import pickle\n",
        "# import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import sys\n",
        "import timeit\n",
        "import os\n",
        "\n",
        "torch.set_default_device('cpu')\n",
        "torch.set_default_dtype(torch.float64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBk01Vu0pvMm"
      },
      "source": [
        "# class to save results in file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06IymVCkpvYS"
      },
      "outputs": [],
      "source": [
        "class Record:\n",
        "    def __init__(self, TextName):\n",
        "        self.out_file = open(TextName, 'a')\n",
        "        self.old_stdout = sys.stdout\n",
        "        sys.stdout = self\n",
        "\n",
        "    def write(self, text):\n",
        "        self.old_stdout.write(text)\n",
        "        self.out_file.write(text)\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout = self.old_stdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xPamGjNpv8E"
      },
      "source": [
        "# **slicer the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlQdA0xHpwF7"
      },
      "outputs": [],
      "source": [
        "def slicer(data):\n",
        "    dataI = data[slice(0, len(data), 2)]\n",
        "    dataQ = data[slice(1, len(data), 2)]\n",
        "    return(dataI, dataQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOoiIo_LpwQl"
      },
      "source": [
        "# **Modulation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIftC8fvpwir"
      },
      "outputs": [],
      "source": [
        "def mapper_16QAM(QAM16, data):\n",
        "    map0 = 2*data[slice(0, len(data), 2)] + data[slice(1, len(data), 2)]\n",
        "    map0 = list(map(int, map0))\n",
        "    dataMapped = []\n",
        "    for i in range(len(map0)):\n",
        "        dataMapped.append(QAM16[map0[i]])\n",
        "    return(dataMapped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYhPgAIcqtGT"
      },
      "outputs": [],
      "source": [
        "def calculate_bits(Modulation,NumSubcarriers,NumDataSymb):\n",
        "    if Modulation=='QPSK':\n",
        "        Nbpscs=2\n",
        "    elif Modulation=='16QAM':\n",
        "        Nbpscs=4\n",
        "    return NumDataSymb*NumSubcarriers*Nbpscs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgX6tiqFpwvb"
      },
      "source": [
        "# **generate noise**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LQwZvGaprKZ"
      },
      "outputs": [],
      "source": [
        "def AWGN(IFsig, SNR):\n",
        "    dP = np.zeros(len(IFsig))\n",
        "    P = 0\n",
        "\n",
        "    for i in range(len(IFsig)):\n",
        "        dP[i] = abs(IFsig[i])**2\n",
        "        P = P + dP[i]\n",
        "\n",
        "    P = P/len(IFsig)\n",
        "    gamma = 10**(SNR/10)\n",
        "    N0 = P/gamma\n",
        "    n = ((N0/2)**(0.5))*np.random.standard_normal(len(IFsig))\n",
        "    IF_n = np.zeros((len(IFsig),1))\n",
        "\n",
        "    for i in range(len(IFsig)):\n",
        "        IF_n[i,:] = IFsig[i] + n[i]\n",
        "\n",
        "    return(IF_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ub0OzsUlmUP"
      },
      "source": [
        "# Generate channel model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEUqI9tTlmUP"
      },
      "outputs": [],
      "source": [
        "def Generate_channel(Nr, Nt, type):\n",
        "    if (type == 'gauss'):\n",
        "        return (np.random.normal(size=(Nr,Nt))+1j*np.random.normal(size=(Nr,Nt)))/np.sqrt(2)\n",
        "    if (type == 'rayleigh'):\n",
        "        return (np.random.rayleigh(scale=(1/np.sqrt(2)), size=(Nr,Nt)) + 1j*np.random.rayleigh(scale=(1/np.sqrt(2)), size=(Nr,Nt)))/np.sqrt(2)\n",
        "    if (type == 'rician'):\n",
        "        b = 1/np.sqrt(2)\n",
        "        return (rice.rvs(b, size=(Nr,Nt)) + 1j*rice.rvs(b, size=(Nr,Nt)))/np.sqrt(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eciNtnFjq2yd"
      },
      "source": [
        "# **Generate Dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE4Q6jZCq3CY"
      },
      "outputs": [],
      "source": [
        "DataSet_x   = []  # x dataset after modulation\n",
        "DataSet_y   = []  # y dataset\n",
        "DataSet_HH  = []  # H dataset\n",
        "DataSet_b   = []  # binary dataset\n",
        "SNR_min_dB  = 0\n",
        "SNR_max_dB  = 20\n",
        "step_dB     = 5\n",
        "num_dB      = int((SNR_max_dB - SNR_min_dB) / step_dB) + 1\n",
        "\n",
        "SNR         = np.linspace(SNR_min_dB, SNR_max_dB, num=num_dB)\n",
        "\n",
        "\n",
        "Nt = 8             # Tx: 8\n",
        "Nr = 64            # Rx: 128\n",
        "N_samp = 4000\n",
        "\n",
        "\n",
        "def Gen_dataset(mode, snr, imperfect, N_samp):\n",
        "    DataSet_x   = []  # x dataset after modulation\n",
        "    DataSet_y   = []  # y dataset\n",
        "    DataSet_H   = []\n",
        "    DataSet_HH  = []\n",
        "\n",
        "    NumSubcarriers = 1\n",
        "    Modulation = '16QAM'\n",
        "    QAM16 = [-1, -0.333, 0.333, 1]\n",
        "    NumDataSymb = 1\n",
        "    N_type = 'gauss'\n",
        "\n",
        "    if mode == 'train':\n",
        "        for snr in SNR:\n",
        "            for runIdx in range(0, N_samp):      # ! 20000 x Nt: samples\n",
        "                H = Generate_channel(Nt, Nr, N_type)\n",
        "                HH = np.concatenate((np.concatenate((H.real, H.imag), axis=1),\n",
        "                                    np.concatenate((-H.imag, H.real), axis=1)), axis=0)\n",
        "                x = np.zeros((2*Nt, NumSubcarriers))\n",
        "                a = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                DataRaw = np.zeros((Nt, a))\n",
        "                for t in range(Nt):\n",
        "                    #\"data symbol generate\"\n",
        "                    NumBits = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                    bit = np.random.randint(1, 3, NumBits)-1\n",
        "                    DataRaw[t, :] = bit\n",
        "                    for j in range(4):\n",
        "                        DataSet_b.append(bit[j])\n",
        "                    I = np.zeros((1, a))\n",
        "                    I[0, :] = DataRaw[t, :]\n",
        "                    (dataI, dataQ) = slicer(I[0])\n",
        "\n",
        "                    # Mapper\n",
        "                    mapI = mapper_16QAM(QAM16, dataI)\n",
        "                    mapQ = mapper_16QAM(QAM16, dataQ)\n",
        "                    x[t] = mapI[0]\n",
        "                    x[t+Nt] = mapQ[0]\n",
        "\n",
        "                # transpose\n",
        "                x = x.transpose()\n",
        "\n",
        "                y_wo_noise = np.matmul(x, HH)\n",
        "\n",
        "                # noise\n",
        "                noise = AWGN(y_wo_noise.transpose(), snr)\n",
        "\n",
        "                y = y_wo_noise + noise.transpose()\n",
        "\n",
        "                DataSet_x.append(x)    # ! I, Q sample distance by Nt.\n",
        "                DataSet_y.append(y)                 # ! output sample\n",
        "\n",
        "                # Imperfect channel: 5%\n",
        "                # coef = (2*np.random.randint(0,2,size=HH.shape) - 1)\n",
        "                # HH = HH + coef * HH * 0.05\n",
        "                DataSet_HH.append(HH)\n",
        "                DataSet_H.append(H)               # ! Generated channel\n",
        "\n",
        "    else:\n",
        "        for runIdx in range(0, N_samp):      # ! 20000 x Nt: samples\n",
        "            H = Generate_channel(Nt, Nr, N_type)\n",
        "            HH = np.concatenate((np.concatenate((H.real, H.imag), axis=1),\n",
        "                                np.concatenate((-H.imag, H.real), axis=1)), axis=0)\n",
        "            x = np.zeros((2*Nt, NumSubcarriers))\n",
        "            a = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "            DataRaw = np.zeros((Nt, a))\n",
        "            for t in range(Nt):\n",
        "                #\"data symbol generate\"\n",
        "                NumBits = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                bit = np.random.randint(1, 3, NumBits)-1\n",
        "                DataRaw[t, :] = bit\n",
        "                for j in range(4):\n",
        "                    DataSet_b.append(bit[j])\n",
        "                I = np.zeros((1, a))\n",
        "                I[0, :] = DataRaw[t, :]\n",
        "                (dataI, dataQ) = slicer(I[0])\n",
        "\n",
        "                # Mapper\n",
        "                mapI = mapper_16QAM(QAM16, dataI)\n",
        "                mapQ = mapper_16QAM(QAM16, dataQ)\n",
        "                x[t] = mapI[0]\n",
        "                x[t+Nt] = mapQ[0]\n",
        "\n",
        "            # transpose\n",
        "            x = x.transpose()\n",
        "\n",
        "            y_wo_noise = np.matmul(x, HH)\n",
        "\n",
        "            # noise\n",
        "            noise = AWGN(y_wo_noise.transpose(), snr)\n",
        "\n",
        "            y = y_wo_noise + noise.transpose()\n",
        "\n",
        "            DataSet_x.append(x)    # ! I, Q sample distance by Nt.\n",
        "            DataSet_y.append(y)                 # ! output sample\n",
        "\n",
        "            # Imperfect channel: 5%\n",
        "            DataSet_HH.append(HH)\n",
        "            DataSet_H.append(H)               # ! Generated channel\n",
        "\n",
        "\n",
        "    # Shuffle dataset\n",
        "    random.seed(1)\n",
        "    temp = list(zip(DataSet_x, DataSet_y, DataSet_H, DataSet_HH))\n",
        "    random.shuffle(temp)\n",
        "    DataSet_x, DataSet_y, DataSet_H, DataSet_HH = zip(*temp)\n",
        "\n",
        "    return DataSet_x, DataSet_y, DataSet_H, DataSet_HH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXvqlJYUlmUQ"
      },
      "outputs": [],
      "source": [
        "def reconstruct_channel (H):\n",
        "# H_raw = [R(H) I(H); -I(H) R(H)]\n",
        "# we have four version of H_est\n",
        "    H_est_1 = []\n",
        "    H_est_2 = []\n",
        "    H_est_3 = []\n",
        "    H_est_4 = []\n",
        "\n",
        "    H_est_Re_1 = H[0:Nt, 0:Nr]\n",
        "    H_est_Im_1 = H[0:Nt, Nr:2*Nr]\n",
        "    H_est_Im_2 = - H[Nt:2*Nt, 0:Nr]\n",
        "    H_est_Re_2 = H[Nt:2*Nt, Nr:2*Nr]\n",
        "\n",
        "    H_est_1 = H_est_Re_1 + 1j * H_est_Im_1\n",
        "    H_est_2 = H_est_Re_1 + 1j * H_est_Im_2\n",
        "    H_est_3 = H_est_Re_2 + 1j * H_est_Im_1\n",
        "    H_est_4 = H_est_Re_2 + 1j * H_est_Im_2\n",
        "\n",
        "    return H_est_1, H_est_2, H_est_3, H_est_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y36n19iClmUR"
      },
      "outputs": [],
      "source": [
        "# def NMSE(H_est, H_raw):\n",
        "#     H_est_1, H_est_2, H_est_3, H_est_4 = reconstruct_channel(H_est)\n",
        "#     H_est_vec_1 = torch.reshape(H_est_1, [Nt * Nr, 1])\n",
        "#     H_est_vec_2 = torch.reshape(H_est_2, [Nt * Nr, 1])\n",
        "#     H_est_vec_3 = torch.reshape(H_est_3, [Nt * Nr, 1])\n",
        "#     H_est_vec_4 = torch.reshape(H_est_4, [Nt * Nr, 1])\n",
        "\n",
        "#     H_raw_vec = torch.reshape(H_raw, [Nt * Nr, 1])\n",
        "\n",
        "#     mse_1       = (torch.norm(H_raw_vec - H_est_vec_1)**2) / len(H_raw_vec)\n",
        "#     mse_2       = (torch.norm(H_raw_vec - H_est_vec_2)**2) / len(H_raw_vec)\n",
        "#     mse_3       = (torch.norm(H_raw_vec - H_est_vec_3)**2) / len(H_raw_vec)\n",
        "#     mse_4       = (torch.norm(H_raw_vec - H_est_vec_4)**2) / len(H_raw_vec)\n",
        "\n",
        "#     sigEner   = torch.norm(H_raw_vec)**2\n",
        "\n",
        "#     nmse_1      = mse_1 / sigEner\n",
        "#     nmse_2      = mse_2 / sigEner\n",
        "#     nmse_3      = mse_3 / sigEner\n",
        "#     nmse_4      = mse_4 / sigEner\n",
        "\n",
        "#     # Best nmse\n",
        "#     nmse        = min([nmse_1, nmse_2, nmse_3, nmse_4])\n",
        "\n",
        "#     return torch.abs(nmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gQSADrXlmUR"
      },
      "outputs": [],
      "source": [
        "def NMSE(H_est, H_raw):\n",
        "    H_est_1, H_est_2, H_est_3, H_est_4 = reconstruct_channel(H_est)\n",
        "\n",
        "    # Lấy phần thực của các tensor nếu chúng là complex\n",
        "    H_est_vec_1 = torch.reshape(H_est_1, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_2 = torch.reshape(H_est_2, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_3 = torch.reshape(H_est_3, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_4 = torch.reshape(H_est_4, [Nt * Nr, 1]).abs()\n",
        "\n",
        "    H_raw_vec = torch.reshape(H_raw, [Nt * Nr, 1]).abs()\n",
        "\n",
        "    mse_1 = (torch.norm(H_raw_vec - H_est_vec_1)**2) / len(H_raw_vec)\n",
        "    mse_2 = (torch.norm(H_raw_vec - H_est_vec_2)**2) / len(H_raw_vec)\n",
        "    mse_3 = (torch.norm(H_raw_vec - H_est_vec_3)**2) / len(H_raw_vec)\n",
        "    mse_4 = (torch.norm(H_raw_vec - H_est_vec_4)**2) / len(H_raw_vec)\n",
        "\n",
        "    sigEner = torch.norm(H_raw_vec)**2\n",
        "\n",
        "    nmse_1 = mse_1 / sigEner\n",
        "    nmse_2 = mse_2 / sigEner\n",
        "    nmse_3 = mse_3 / sigEner\n",
        "    nmse_4 = mse_4 / sigEner\n",
        "\n",
        "    # Chọn NMSE tốt nhất\n",
        "    nmse = min([nmse_1, nmse_2, nmse_3, nmse_4])\n",
        "\n",
        "    return torch.abs(nmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyjIgxUurU0P"
      },
      "outputs": [],
      "source": [
        "def Input_ISDNN(mode, DataSet_x, DataSet_y, DataSet_H, DataSet_HH, N_samp):\n",
        "    H_in = []        # ! H_in    , np.diag(np.diag()) return a diag matrix instead of diag components.\n",
        "    H_true = []   # ! generated s\n",
        "    H_raw = []\n",
        "    v = []        # ! vector errors\n",
        "    xTx = []\n",
        "    xTy = []\n",
        "    # steering = [] # ! Steering vector: ZoA and AoA\n",
        "\n",
        "    if mode == 'train':\n",
        "        n_sample = N_samp * len(SNR)\n",
        "    else:\n",
        "        n_sample = N_samp\n",
        "\n",
        "    for i in range (n_sample):\n",
        "        H_true.append(torch.DoubleTensor(DataSet_HH[i]))\n",
        "        H_raw.append(torch.DoubleTensor(DataSet_H[i]))\n",
        "        xTy.append(torch.DoubleTensor(np.dot(DataSet_x[i].transpose(), DataSet_y[i])))\n",
        "        H_in.append(torch.zeros([2*Nt, 2*Nr]))\n",
        "        v.append(torch.zeros([2*Nt, 2*Nr]))\n",
        "        xTx.append(torch.DoubleTensor(np.dot(DataSet_x[i].transpose(), DataSet_x[i])))\n",
        "        # steering.append(torch.tensor(DataSet_Steering[i]))\n",
        "\n",
        "    H_true = torch.stack(H_true, dim=0)\n",
        "    H_raw = torch.stack(H_raw, dim=0)\n",
        "    H_in = torch.stack(H_in, dim=0)\n",
        "    v = torch.stack(v, dim=0)\n",
        "    xTx = torch.stack(xTx, dim=0)\n",
        "    xTy = torch.stack(xTy, dim=0)\n",
        "    # steering = torch.stack(steering, dim=0)\n",
        "\n",
        "    return H_true, H_raw, H_in, v, xTx, xTy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGhdBsghq3M9"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHceh5kuq3ZD"
      },
      "outputs": [],
      "source": [
        "class xv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(xv, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(4*Nr, 2*Nr)\n",
        "        self.fc2 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc3 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "\n",
        "        self.delta_1 = torch.nn.parameter.Parameter(torch.rand(1))\n",
        "        self.delta_2 = torch.nn.parameter.Parameter(torch.rand(1))\n",
        "\n",
        "    def forward(self, H, v, xTx, xTy):\n",
        "\n",
        "        xTxH = torch.matmul(xTx, H)\n",
        "\n",
        "        q    = H - self.delta_1 * xTy + self.delta_2 * xTxH\n",
        "\n",
        "        concat = torch.concat([q, v], 1)\n",
        "\n",
        "        z    = torch.tanh(self.fc1(concat))\n",
        "\n",
        "        H_oh = self.fc2(z)\n",
        "\n",
        "        v    = self.fc3(z)\n",
        "\n",
        "        return H_oh, v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woRjD7lJssRq"
      },
      "outputs": [],
      "source": [
        "class model_driven(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(model_driven, self).__init__()\n",
        "\n",
        "        self.layer1=xv()\n",
        "        self.layer2=xv()\n",
        "        self.layer3=xv()\n",
        "        self.layer4=xv()\n",
        "        self.layer5=xv()\n",
        "\n",
        "    def forward(self, H_in, v, xTx, xTy):\n",
        "        H_oh, v = self.layer1(H_in, v, xTx, xTy)\n",
        "        H       = torch.tanh(H_oh)\n",
        "\n",
        "        H_oh, v = self.layer2(H_in, v, xTx, xTy)\n",
        "        H       = torch.tanh(H_oh)\n",
        "\n",
        "        H_oh, v = self.layer3(H_in, v, xTx, xTy)\n",
        "        H       = torch.tanh(H_oh)\n",
        "\n",
        "        H_oh, v = self.layer4(H_in, v, xTx, xTy)\n",
        "\n",
        "        return H"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZjihTOXq3kG"
      },
      "source": [
        "# Define model, optimizer, and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp9fRd3gq3tw"
      },
      "outputs": [],
      "source": [
        "def def_model():\n",
        "    model = model_driven()\n",
        "    loss = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    folder_model = './model/'\n",
        "\n",
        "    if not os.path.isdir(folder_model):\n",
        "        os.makedirs(folder_model)\n",
        "\n",
        "    file_model = folder_model + 'H'\n",
        "    # if os.path.isfile(file_model):\n",
        "    #     generator = torch.load(file_model)\n",
        "\n",
        "    record_file = 'H'\n",
        "    return model, loss, optimizer, record_file, file_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYWM7SzItKzS"
      },
      "source": [
        "# Main program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv7lDwyxtFe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42621ef8-772f-40e9-a7f1-513e945278a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-3e5f3c45b18a>:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  dP[i] = abs(IFsig[i])**2\n",
            "<ipython-input-62-632f5add8c4a>:17: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:308.)\n",
            "  H_raw.append(torch.DoubleTensor(DataSet_H[i]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dữ liệu đã được sinh và lưu lại!\n",
            "Begin training...\n",
            "1 inf 0.492081077386947\n",
            "1 inf 0.5361688431382784\n",
            "1 inf 0.5154980490566218\n",
            "1 inf 0.5059926203681607\n",
            "1 inf 0.5464604129951836\n",
            "1 inf 0.46142323029305604\n",
            "1 inf 0.5090281205653701\n",
            "1 inf 0.5021329429774193\n",
            "1 inf 0.4855594784993942\n",
            "1 inf 0.4649099424168843\n",
            "1 inf 0.4961916930228779\n",
            "1 inf 0.4961930800184347\n",
            "1 inf 0.48191845933670996\n",
            "1 inf 0.4972618521197475\n",
            "1 inf 0.47310377031270834\n",
            "1 inf 0.5298418533714261\n",
            "1 inf 0.5075107394105148\n",
            "1 inf 0.5298456857331999\n",
            "1 inf 0.5298122990548627\n",
            "1 inf 0.5001108942404504\n",
            "1 inf 0.48724186051640955\n",
            "1 inf 0.511412552809943\n",
            "1 inf 0.4861311767508781\n",
            "1 inf 0.5259598689480443\n",
            "1 inf 0.520075749496675\n",
            "1 inf 0.511649731652498\n",
            "1 inf 0.47826392695853304\n",
            "1 inf 0.5146581588521585\n",
            "1 inf 0.4732655670461176\n",
            "1 inf 0.492074139216327\n",
            "1 inf 0.5128361191531134\n",
            "1 inf 0.52826705694341\n",
            "1 inf 0.49947120257207034\n",
            "1 inf 0.517813333661763\n",
            "1 inf 0.4969377515078278\n",
            "1 inf 0.46112799262340026\n",
            "1 inf 0.5220668357107126\n",
            "1 inf 0.5217825034704286\n",
            "1 inf 0.5112292561912308\n",
            "1 inf 0.5109413858943328\n",
            "1 inf 0.503237321167316\n",
            "1 inf 0.5228938952085507\n",
            "1 inf 0.4863189798577134\n",
            "1 inf 0.5056206544221329\n",
            "1 inf 0.5149643979508494\n",
            "1 inf 0.4869915702714903\n",
            "1 inf 0.5095623294216252\n",
            "1 inf 0.502468955594948\n",
            "1 inf 0.49794903145361585\n",
            "1 inf 0.4930218579081981\n",
            "1 inf 0.5346511234195744\n",
            "1 inf 0.49559645912199973\n",
            "1 inf 0.475750521756307\n",
            "1 inf 0.46556788675471217\n",
            "1 inf 0.4415397586500628\n",
            "1 inf 0.4585767479342397\n",
            "1 inf 0.5222820620865227\n",
            "1 inf 0.46717999652743253\n",
            "1 inf 0.5024412666972335\n",
            "1 inf 0.5205172370922421\n",
            "1 inf 0.5104217450227791\n",
            "1 inf 0.517605730525974\n",
            "1 inf 0.49522804605012993\n",
            "1 inf 0.4880371262437537\n",
            "1 inf 0.5011307678250588\n",
            "1 inf 0.5040661968011\n",
            "1 inf 0.4848085880769468\n",
            "1 inf 0.5411321253595065\n",
            "1 inf 0.5075246686420594\n",
            "1 inf 0.5095592705810797\n",
            "1 inf 0.47794756953496953\n",
            "1 inf 0.5111090523123776\n",
            "1 inf 0.514485488869302\n",
            "1 inf 0.5215005982133788\n",
            "1 inf 0.5392039847054753\n",
            "1 inf 0.4913398189056898\n",
            "1 inf 0.4530229896343414\n",
            "1 inf 0.47312562696579735\n",
            "1 inf 0.5013154271184206\n",
            "1 inf 0.5133041143434652\n",
            "1 inf 0.510901570245809\n",
            "1 inf 0.4964026312828176\n",
            "1 inf 0.49329770086178126\n",
            "1 inf 0.5117993167687084\n",
            "1 inf 0.5337669642163255\n",
            "1 inf 0.5050607403753757\n",
            "1 inf 0.5033751718996446\n",
            "1 inf 0.5152673294962027\n",
            "1 inf 0.49608948494302174\n",
            "1 inf 0.5107760069934425\n",
            "1 inf 0.49335042017087516\n",
            "1 inf 0.5411422259712162\n",
            "1 inf 0.49995356069781505\n",
            "1 inf 0.5112196470559358\n",
            "1 inf 0.4724351408612313\n",
            "1 inf 0.5104578530431313\n",
            "1 inf 0.5491603054672701\n",
            "1 inf 0.4892705650436056\n",
            "1 inf 0.5056994238759125\n",
            "1 inf 0.523123302200058\n",
            "1 inf 0.5104750044414914\n",
            "1 inf 0.5252481971764008\n",
            "1 inf 0.4928470867765951\n",
            "1 inf 0.503099181342022\n",
            "1 inf 0.5310397827928128\n",
            "1 inf 0.48943666642449346\n",
            "1 inf 0.4718911917319266\n",
            "1 inf 0.526579006206105\n",
            "1 inf 0.4794930906031327\n",
            "1 inf 0.49989588826333897\n",
            "1 inf 0.5210016047037533\n",
            "1 inf 0.5165822439969865\n",
            "1 inf 0.4866783544194331\n",
            "1 inf 0.5135699495398858\n",
            "1 inf 0.44689693223439575\n",
            "1 inf 0.5044166718875177\n",
            "1 inf 0.4862264647060367\n",
            "1 inf 0.4504814201672357\n",
            "1 inf 0.4803383758152547\n",
            "1 inf 0.4797294581662943\n",
            "1 inf 0.5464690093456003\n",
            "1 inf 0.5781598853797042\n",
            "1 inf 0.5139715960288561\n",
            "1 inf 0.5122550453845152\n",
            "1 inf 0.4956402756766941\n",
            "1 inf 0.47591467450769925\n",
            "1 inf 0.5025962182850562\n",
            "1 inf 0.48759497257041606\n",
            "1 inf 0.5211775323307637\n",
            "1 inf 0.48318104855593874\n",
            "1 inf 0.4932173485566091\n",
            "1 inf 0.5190445786633706\n",
            "1 inf 0.464549688443047\n",
            "1 inf 0.48169044305590314\n",
            "1 inf 0.5233260528963061\n",
            "1 inf 0.4662483233356378\n",
            "1 inf 0.5617346433556575\n",
            "1 inf 0.5123321956504534\n",
            "1 inf 0.4928570218730914\n",
            "1 inf 0.5149605270883396\n",
            "1 inf 0.5205778990869201\n",
            "1 inf 0.4896052784097117\n",
            "1 inf 0.5046136789378061\n",
            "1 inf 0.5208722386429405\n",
            "1 inf 0.4861085982695933\n",
            "1 inf 0.467570430300549\n",
            "1 inf 0.5008710210637011\n",
            "1 inf 0.4958918117598048\n",
            "1 inf 0.4915316258113446\n",
            "1 inf 0.4754242321405506\n",
            "1 inf 0.510804497113675\n",
            "1 inf 0.5009661969174753\n",
            "1 inf 0.47899526996810227\n",
            "1 inf 0.48398632681299136\n",
            "1 inf 0.5226155050633646\n",
            "1 inf 0.5233427074192547\n",
            "1 inf 0.4662907455490042\n",
            "1 inf 0.48785961114994314\n",
            "1 inf 0.5122732472954622\n",
            "1 inf 0.5040608908076751\n",
            "1 inf 0.5307224976643683\n",
            "1 inf 0.4704386380189993\n",
            "1 inf 0.48171945929481086\n",
            "1 inf 0.5254028185346812\n",
            "1 inf 0.4872090208582579\n",
            "1 inf 0.48846268733575526\n",
            "1 inf 0.5195955124048661\n",
            "1 inf 0.4928035218587264\n",
            "1 inf 0.515413315945055\n",
            "1 inf 0.4484956035546228\n",
            "1 inf 0.4946734652659046\n",
            "1 inf 0.4775209600880004\n",
            "1 inf 0.46086866399085136\n",
            "1 inf 0.4778068891196675\n",
            "1 inf 0.5054936815638937\n",
            "1 inf 0.452886728271623\n",
            "1 inf 0.5041096312366178\n",
            "1 inf 0.4932629847229074\n",
            "1 inf 0.5414755363724313\n",
            "1 inf 0.475380576817889\n",
            "1 inf 0.487810213651497\n",
            "1 inf 0.526118759397457\n",
            "1 inf 0.47512978641233405\n",
            "1 inf 0.49931049498139907\n",
            "1 inf 0.48477790889011463\n",
            "1 inf 0.4825689917282731\n",
            "1 inf 0.4861890850908305\n",
            "1 inf 0.475949499084813\n",
            "1 inf 0.5115342274404026\n",
            "1 inf 0.4846455334955074\n",
            "1 inf 0.49839151835116624\n",
            "1 inf 0.47387190576063976\n",
            "1 inf 0.45820475395346194\n",
            "1 inf 0.5306045995032624\n",
            "1 inf 0.5207143414659781\n",
            "1 inf 0.5023370349996114\n",
            "1 inf 0.4784984677812739\n",
            "1 inf 0.4967357599179615\n",
            "1 inf 0.5035920179866933\n",
            "1 inf 0.48509350148781927\n",
            "1 inf 0.4913027638693595\n",
            "1 inf 0.4533563234069929\n",
            "1 inf 0.4858397054272732\n",
            "1 inf 0.4699752561890639\n",
            "1 inf 0.4827217995558436\n",
            "1 inf 0.49530532453785925\n",
            "1 inf 0.5046777511914535\n",
            "1 inf 0.5036781267326689\n",
            "1 inf 0.514048198330201\n",
            "1 inf 0.47324713206680485\n",
            "1 inf 0.4886048760030266\n",
            "1 inf 0.5167996467064343\n",
            "1 inf 0.47587215672630195\n",
            "1 inf 0.5014973831290465\n",
            "1 inf 0.5192661800735987\n",
            "1 inf 0.4672490541577843\n",
            "1 inf 0.4832166275500558\n",
            "1 inf 0.5031114505624052\n",
            "1 inf 0.48513568000340707\n",
            "1 inf 0.4607053430930027\n",
            "1 inf 0.46614181032140123\n",
            "1 inf 0.46393580114747746\n",
            "1 inf 0.5066436083273318\n",
            "1 inf 0.5155273430591221\n",
            "1 inf 0.5097601216099438\n",
            "1 inf 0.4988689441177349\n",
            "1 inf 0.4896275882691719\n",
            "1 inf 0.4960742587501562\n",
            "1 inf 0.5153390545724698\n",
            "1 inf 0.5208957357881423\n",
            "1 inf 0.5099880305406606\n",
            "1 inf 0.49468308013105544\n",
            "1 inf 0.489826629184355\n",
            "1 inf 0.5034054195213682\n",
            "1 inf 0.4624882179963429\n",
            "1 inf 0.48326877362186604\n",
            "1 inf 0.5326064306055179\n",
            "1 inf 0.5487058563137195\n",
            "1 inf 0.5317051171859086\n",
            "1 inf 0.5659997475504807\n",
            "1 inf 0.46832612978659727\n",
            "1 inf 0.5043983433164606\n",
            "1 inf 0.5118076437823211\n",
            "1 inf 0.5191487880996875\n",
            "1 inf 0.5177747168855115\n",
            "1 inf 0.46934407548726914\n",
            "1 inf 0.48380771355924185\n",
            "1 inf 0.5053762692871342\n",
            "1 inf 0.5135052340476668\n",
            "1 inf 0.5381741599076588\n",
            "1 inf 0.5129954523129656\n",
            "1 inf 0.46457515527895565\n",
            "1 inf 0.4991301209909798\n",
            "1 inf 0.4852025286504206\n",
            "1 inf 0.47027486401867524\n",
            "1 inf 0.5037324986600976\n",
            "1 inf 0.4705054274905422\n",
            "1 inf 0.47188567965275474\n",
            "1 inf 0.5007178864584684\n",
            "1 inf 0.47886207501774747\n",
            "1 inf 0.5279932468962922\n",
            "1 inf 0.4756062205651497\n",
            "1 inf 0.4913131328190356\n",
            "1 inf 0.5004784430407359\n",
            "1 inf 0.550673502702072\n",
            "1 inf 0.5238123364220972\n",
            "1 inf 0.5364161329011469\n",
            "1 inf 0.48680758771024146\n",
            "1 inf 0.48764652207658027\n",
            "1 inf 0.47865217529839205\n",
            "1 inf 0.502101131851829\n",
            "1 inf 0.47186181307201536\n",
            "1 inf 0.528239742627032\n",
            "1 inf 0.4998697328026611\n",
            "1 inf 0.4808762651538186\n",
            "1 inf 0.501226943675783\n",
            "1 inf 0.4940360512005944\n",
            "1 inf 0.4734623924651977\n",
            "1 inf 0.4757722847958439\n",
            "1 inf 0.4764038216216471\n",
            "1 inf 0.4778781607203891\n",
            "1 inf 0.48924130755959716\n",
            "1 inf 0.4791409968288868\n",
            "1 inf 0.5273335385075992\n",
            "1 inf 0.5094442702437204\n",
            "1 inf 0.48414016510656754\n",
            "1 inf 0.5165766424250637\n",
            "1 inf 0.5175128942121777\n",
            "1 inf 0.5050531040921122\n",
            "1 inf 0.515707303475969\n",
            "1 inf 0.5665930245299299\n",
            "1 inf 0.5007557127682857\n",
            "1 inf 0.46672406232094527\n",
            "1 inf 0.49260717223493666\n",
            "1 inf 0.4866120608508445\n",
            "1 inf 0.5330546525153974\n",
            "1 inf 0.4823264764518001\n",
            "1 inf 0.5097660764485608\n",
            "1 inf 0.5038984289723408\n",
            "1 inf 0.5056357093505253\n",
            "1 inf 0.5260606978272641\n",
            "1 inf 0.4572049787255792\n",
            "1 inf 0.5237109498752461\n",
            "1 inf 0.5023495888426708\n",
            "1 inf 0.5215633346661666\n",
            "1 inf 0.4996460766651079\n",
            "1 inf 0.49662104180023714\n",
            "1 inf 0.5282706442278551\n",
            "1 inf 0.5074566633912726\n",
            "1 inf 0.549353602082757\n",
            "1 inf 0.5027100520530691\n",
            "1 inf 0.5101574652314421\n",
            "1 inf 0.48675529103070275\n",
            "1 inf 0.4936477455574709\n",
            "1 inf 0.45482937893955067\n",
            "1 inf 0.5240548884618402\n",
            "1 inf 0.5206373177729854\n",
            "1 inf 0.5353030349143856\n",
            "1 inf 0.4547463128908319\n",
            "1 inf 0.5055318405346293\n",
            "1 inf 0.49587373033540355\n",
            "1 inf 0.5223241133658288\n",
            "1 inf 0.516621762349957\n",
            "1 inf 0.4744112504459584\n",
            "1 inf 0.5301780774337769\n",
            "1 inf 0.5173991633293809\n",
            "1 inf 0.5069673649123471\n",
            "1 inf 0.4883788985327988\n",
            "1 inf 0.49054850952862095\n",
            "1 inf 0.4885932434263988\n",
            "1 inf 0.46955244967073445\n",
            "1 inf 0.5404829537878372\n",
            "1 inf 0.5267056915752255\n",
            "1 inf 0.4901421370955283\n",
            "1 inf 0.4695427278082275\n",
            "1 inf 0.5186762833095722\n",
            "1 inf 0.5165541768376698\n",
            "1 inf 0.47346736009028073\n",
            "1 inf 0.5080865389486394\n",
            "1 inf 0.49043034968309257\n",
            "1 inf 0.4943472100084225\n",
            "1 inf 0.4818203544116031\n",
            "1 inf 0.46503159815549744\n",
            "1 inf 0.5288383427022307\n",
            "1 inf 0.48164415405710875\n",
            "1 inf 0.5318621917355426\n",
            "1 inf 0.5204945412262748\n",
            "1 inf 0.5124419986996838\n",
            "1 inf 0.47229146412873446\n",
            "1 inf 0.5283376606979824\n",
            "1 inf 0.5085198894397173\n",
            "1 inf 0.5269192587999421\n",
            "1 inf 0.5102446107307355\n",
            "1 inf 0.5428386735098892\n",
            "1 inf 0.4724147401078046\n",
            "1 inf 0.5164969583133356\n",
            "1 inf 0.5041411927315326\n",
            "1 inf 0.5052384870043584\n",
            "1 inf 0.4863320672450882\n",
            "1 inf 0.4870402469601597\n",
            "1 inf 0.501105160592047\n",
            "1 inf 0.47353155563690275\n",
            "1 inf 0.5346833161414002\n",
            "1 inf 0.5321668067736763\n",
            "1 inf 0.4769711874997678\n",
            "1 inf 0.5231709978174164\n",
            "1 inf 0.4667484869174133\n",
            "1 inf 0.49621790184394354\n",
            "1 inf 0.47762170697127043\n",
            "1 inf 0.5091870910350149\n",
            "1 inf 0.5052880641471101\n",
            "1 inf 0.48647658552502615\n",
            "1 inf 0.49285149283397583\n",
            "1 inf 0.49662555517630874\n",
            "1 inf 0.4976250690054953\n",
            "1 inf 0.4910238072096873\n",
            "1 inf 0.4728341619184144\n",
            "1 inf 0.5339888819577984\n",
            "1 inf 0.5078828130511917\n",
            "1 inf 0.5147131153996781\n",
            "1 inf 0.4837799114380007\n",
            "1 inf 0.535523470843038\n",
            "1 inf 0.5023753337060547\n",
            "1 inf 0.48471853412641003\n",
            "1 inf 0.5079548777084066\n",
            "1 inf 0.5004233758339761\n",
            "1 inf 0.49546245025419966\n",
            "1 inf 0.46304426606969484\n",
            "1 inf 0.4857534788422283\n",
            "1 inf 0.5468996075797323\n",
            "1 inf 0.4909982051077445\n",
            "1 inf 0.4847885694407311\n",
            "1 inf 0.49259305286000804\n",
            "1 inf 0.5133874485399125\n",
            "1 inf 0.47416543880640616\n",
            "1 inf 0.4783525768847588\n",
            "1 inf 0.46388931484763346\n",
            "1 inf 0.4885440955160447\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-ab5899d5ec69>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# adjust parameters based on the calculated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                   \u001b[0mnmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mnmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmse\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_samp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_model\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-29cd7be2265b>\u001b[0m in \u001b[0;36mNMSE\u001b[0;34m(H_est, H_raw)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mNMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mH_est_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_est_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_est_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_est_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreconstruct_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_est\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Lấy phần thực của các tensor nếu chúng là complex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mH_est_vec_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_est_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mNr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-5158de321abd>\u001b[0m in \u001b[0;36mreconstruct_channel\u001b[0;34m(H)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mH_est_Re_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mNt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mNr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mH_est_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH_est_Re_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1j\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mH_est_Im_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mH_est_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH_est_Re_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1j\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mH_est_Im_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mH_est_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH_est_Re_2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1j\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mH_est_Im_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_device_constructors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# NB: This is directly called from C++ in torch/csrc/Device.cpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epoch         = 0\n",
        "expected_epoch = 20000\n",
        "num_samp      = N_samp * len(SNR)\n",
        "best_nmse     = 1e9\n",
        "early_stop    = 0\n",
        "best_model    = ''\n",
        "batch_size    = 1\n",
        "# Kiểm tra nếu file tĩnh tồn tại\n",
        "if os.path.exists('dataset_DetNet.pkl'):\n",
        "    # Nếu tồn tại, tải dữ liệu từ file tĩnh\n",
        "    with open('dataset_DetNet.pkl', 'rb') as f:\n",
        "        DataSet_x, DataSet_y, DataSet_H, DataSet_HH, H_true, H_raw, H_in, v, xTx, xTy = pickle.load(f)\n",
        "    print(\"Dữ liệu đã được tải từ file tĩnh!\")\n",
        "else:\n",
        "    # Sinh dữ liệu nếu file tĩnh không tồn tại\n",
        "    DataSet_x, DataSet_y, DataSet_H, DataSet_HH = Gen_dataset('train', 0, 0, N_samp)\n",
        "    H_true, H_raw, H_in, v, xTx, xTy = Input_ISDNN('train', DataSet_x, DataSet_y, DataSet_H, DataSet_HH, N_samp)\n",
        "\n",
        "    # Lưu dữ liệu để lần sau không phải sinh lại\n",
        "    with open('dataset_DetNet.pkl', 'wb') as f:\n",
        "        pickle.dump((DataSet_x, DataSet_y, DataSet_H, DataSet_HH, H_true, H_raw, H_in, v, xTx, xTy), f)\n",
        "    print(\"Dữ liệu đã được sinh và lưu lại!\")\n",
        "\n",
        "print(\"Begin training...\")\n",
        "starttime = timeit.default_timer()\n",
        "\n",
        "while(True):\n",
        "        epoch = epoch + 1\n",
        "\n",
        "#        init_loss = 1e9\n",
        "#        while( epoch == 1 and init_loss > 260):\n",
        "\n",
        "        model, loss, optimizer, record_file, file_model = def_model()\n",
        "#                init_loss = 0\n",
        "#                for bs in range (int(num_samp / batch_size)):\n",
        "#                    H_1 = model(\n",
        "#                                 torch.squeeze(H_in[0 + batch_size * bs:batch_size * (bs+1), :, :]),\n",
        "#                                 torch.squeeze(v[0 + batch_size * bs:batch_size * (bs+1), :, :]),\n",
        "#                                 torch.squeeze(xTx[0 + batch_size * bs:batch_size * (bs+1), :, :]),\n",
        "#                                 torch.squeeze(xTy[0 + batch_size * bs:batch_size * (bs+1), :, :]))   # predict output from the model\n",
        "#                    init_loss += loss(H_1, torch.squeeze(H_true[0 + batch_size * bs:batch_size * (bs+1), :, :])).item()\n",
        "#                print(init_loss)\n",
        "\n",
        "        optimizer.zero_grad()   # zero the parameter gradients\n",
        "        train_loss = 0\n",
        "        H_f = torch.empty([num_samp, 2*Nt, 2*Nr])\n",
        "        for bs in range (int(num_samp / batch_size)):\n",
        "                H_o = model(\n",
        "                        torch.squeeze(H_in[0 + batch_size * bs:batch_size * (bs+1), :, :]),\n",
        "                        torch.squeeze(v[0 + batch_size * bs:batch_size * (bs+1), :, :]),\n",
        "                        torch.squeeze(xTx[0 + batch_size * bs:batch_size * (bs+1), :, :]),\n",
        "                        torch.squeeze(xTy[0 + batch_size * bs:batch_size * (bs+1), :, :]))   # predict output from the model\n",
        "                H_f[0 + batch_size * bs:batch_size * (bs+1), :, :] = H_o\n",
        "                train_loss = loss(H_o,torch.squeeze(H_true[0 + batch_size * bs:batch_size * (bs+1), :, :]))   # calculate loss for the predicted output\n",
        "                train_loss.backward()   # backpropagate the loss\n",
        "                optimizer.step()        # adjust parameters based on the calculated gradients\n",
        "                for j in range(num_samp):\n",
        "                  nmse = NMSE(H_f[j], H_raw[j])\n",
        "                nmse = nmse / num_samp\n",
        "                torch.save(model.state_dict(), file_model +'_'+ str(epoch) + '.pth')\n",
        "                best_model = file_model + '.pth'\n",
        "                with Record(record_file + '_log.txt'):\n",
        "                    print(epoch, nmse.item(), train_loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOBK-_l-tRMO"
      },
      "source": [
        "# Test function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRRFGAX4tg_6"
      },
      "source": [
        "# Function to test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ0EJSBmlmUV"
      },
      "outputs": [],
      "source": [
        "#best_model=r'C:\\Users\\SON\\Desktop\\ISDNN\\Python\\Unstructured\\model_detnet_10k_4l_1\\H_1.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfvpexfwthNq"
      },
      "outputs": [],
      "source": [
        "# from scipy.io import savemat\n",
        "\n",
        "def test(H_raw, H_in, v, xTx, xTy, N_test, log):\n",
        "    # Load the model that we saved at the end of the training loop\n",
        "    model = model_driven()\n",
        "    model.load_state_dict(torch.load(best_model, map_location=torch.device('cpu')))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        H_f = torch.empty([N_test, 2*Nt, 2*Nr])\n",
        "        for bs in range (int(N_test / 1)):\n",
        "            H_o = model(\n",
        "                        torch.squeeze(H_in[0 + batch_size * bs:batch_size * (bs+1), :, :]),\n",
        "                        torch.squeeze(v[0 + batch_size * bs:batch_size * (bs+1), :, :]),\n",
        "                        torch.squeeze(xTx[0 + batch_size * bs:batch_size * (bs+1), :, :]),\n",
        "                        torch.squeeze(xTy[0 + batch_size * bs:batch_size * (bs+1), :, :]))   # predict output from the model\n",
        "            H_f[0 + batch_size * bs:batch_size * (bs+1), :, :] = H_o\n",
        "\n",
        "        nmse = 0\n",
        "        for j in range (N_test):\n",
        "            nmse += NMSE(H_f[j], H_raw[j])\n",
        "\n",
        "        nmse = nmse / N_test\n",
        "        with Record(log):\n",
        "            print(format(nmse.item(), '.7f'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AGgrlbWlmUV"
      },
      "outputs": [],
      "source": [
        "## Generate dataset for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOUGj0POlmUW"
      },
      "outputs": [],
      "source": [
        "def LS(DataSet_x, DataSet_y):\n",
        "    start = timeit.default_timer()\n",
        "    for i in range (len(DataSet_x)):\n",
        "        H_hat = np.matmul(\n",
        "                    np.matmul(\n",
        "                        np.linalg.pinv(np.matmul(DataSet_x[i].transpose(), DataSet_x[i])),\n",
        "                        DataSet_x[i].transpose()),\n",
        "                        DataSet_y[i])\n",
        "    print(timeit.default_timer() - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OM1kIPVwlmUW"
      },
      "outputs": [],
      "source": [
        "def MMSE(DataSet_x, DataSet_y, noise_dB, H_raw):\n",
        "    snr_dB = 10 ** (-noise_dB / 10)\n",
        "    start = timeit.default_timer()\n",
        "    # H_f = np.empty([len(DataSet_x), 2*Nt, 2*Nr])\n",
        "    for i in range (len(DataSet_x)):\n",
        "        H_hat = np.matmul(\n",
        "                    np.matmul(\n",
        "                        np.linalg.pinv(np.matmul(DataSet_x[i].transpose(), DataSet_x[i]) + snr_dB * np.eye(2*Nt, 2*Nt)),\n",
        "                        DataSet_x[i].transpose()),\n",
        "                        DataSet_y[i])\n",
        "        # H_f[i, :, :] = H_hat\n",
        "    print(timeit.default_timer() - start)\n",
        "    # nmse = 0\n",
        "    # for j in range (len(DataSet_x)):\n",
        "    #         # tmp =  H_o[j]\n",
        "    #         # tmp1 = tmp.numpy()\n",
        "    #         # savemat('H_est.mat', {'H_o': tmp1})\n",
        "    #     nmse += NMSE(torch.tensor(H_f[j]), torch.tensor(H_raw[j]))\n",
        "    # nmse = nmse / len(DataSet_x)\n",
        "    # print(format(nmse.item(), '.7f'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "3tgSz1sklmUW"
      },
      "outputs": [],
      "source": [
        "SNR_min_dB  = 0\n",
        "SNR_max_dB  = 20\n",
        "step_dB     = 2\n",
        "num_dB      = int((SNR_max_dB - SNR_min_dB) / step_dB) + 1\n",
        "\n",
        "SNR         = np.linspace(SNR_min_dB, SNR_max_dB, num=num_dB)\n",
        "log         = './model/log_test.txt'\n",
        "\n",
        "N_test = int(num_samp * 30 / 100)\n",
        "\n",
        "for i in range (100):\n",
        "    for snr in SNR:\n",
        "        # with Record(log):\n",
        "        #     print(snr)\n",
        "        DataSet_x, DataSet_y, DataSet_H, DataSet_HH = Gen_dataset('test', snr, 0, N_test)\n",
        "        H_true, H_raw, H_in, v, xTx, xTy = Input_ISDNN('test', DataSet_x, DataSet_y, DataSet_H, DataSet_HH, N_test)\n",
        "\n",
        "        # LS(DataSet_x, DataSet_y)\n",
        "        # MMSE(DataSet_x, DataSet_y, snr, H_raw)\n",
        "        test(H_raw, H_in, v, xTx, xTy, N_test, log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmcQBxfHlmUX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
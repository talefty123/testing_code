{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talefty123/testing_code/blob/main/Python/Unstructured/H_ISD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSmcwLZuptDU"
      },
      "source": [
        "# Proposed Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG5fZn_ypunP"
      },
      "source": [
        "# **Biblioheque**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--SvzvIspu-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687431a6-4293-40ad-8403-4a6299d1feff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n",
            "  _C._set_default_tensor_type(t)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from scipy.stats import rice\n",
        "import pickle\n",
        "# import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import sys\n",
        "import timeit\n",
        "import os\n",
        "\n",
        "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
        "torch.set_default_dtype(torch.float64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBk01Vu0pvMm"
      },
      "source": [
        "# class to save results in file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06IymVCkpvYS"
      },
      "outputs": [],
      "source": [
        "class Record:\n",
        "    def __init__(self, TextName):\n",
        "        self.out_file = open(TextName, 'a')\n",
        "        self.old_stdout = sys.stdout\n",
        "        sys.stdout = self\n",
        "\n",
        "    def write(self, text):\n",
        "        self.old_stdout.write(text)\n",
        "        self.out_file.write(text)\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout = self.old_stdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xPamGjNpv8E"
      },
      "source": [
        "# **slicer the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlQdA0xHpwF7"
      },
      "outputs": [],
      "source": [
        "def slicer(data):\n",
        "    dataI = data[slice(0, len(data), 2)]\n",
        "    dataQ = data[slice(1, len(data), 2)]\n",
        "    return(dataI, dataQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOoiIo_LpwQl"
      },
      "source": [
        "# **Modulation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIftC8fvpwir"
      },
      "outputs": [],
      "source": [
        "def mapper_16QAM(QAM16, data):\n",
        "    map0 = 2*data[slice(0, len(data), 2)] + data[slice(1, len(data), 2)]\n",
        "    map0 = list(map(int, map0))\n",
        "    dataMapped = []\n",
        "    for i in range(len(map0)):\n",
        "        dataMapped.append(QAM16[map0[i]])\n",
        "    return(dataMapped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYhPgAIcqtGT"
      },
      "outputs": [],
      "source": [
        "def calculate_bits(Modulation,NumSubcarriers,NumDataSymb):\n",
        "    if Modulation=='QPSK':\n",
        "        Nbpscs=2\n",
        "    elif Modulation=='16QAM':\n",
        "        Nbpscs=4\n",
        "    return NumDataSymb*NumSubcarriers*Nbpscs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgX6tiqFpwvb"
      },
      "source": [
        "# **generate noise**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LQwZvGaprKZ"
      },
      "outputs": [],
      "source": [
        "def AWGN(IFsig, SNR):\n",
        "    dP = np.zeros(len(IFsig))\n",
        "    P = 0\n",
        "\n",
        "    for i in range(len(IFsig)):\n",
        "        dP[i] = abs(IFsig[i])**2\n",
        "        P = P + dP[i]\n",
        "\n",
        "    P = P/len(IFsig)\n",
        "    gamma = 10**(SNR/10)\n",
        "    N0 = P/gamma\n",
        "    n = ((N0/2)**(0.5))*np.random.standard_normal(len(IFsig))\n",
        "    IF_n = np.zeros((len(IFsig),1))\n",
        "\n",
        "    for i in range(len(IFsig)):\n",
        "        IF_n[i,:] = IFsig[i] + n[i]\n",
        "\n",
        "    return(IF_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDx6TEAyimk9"
      },
      "source": [
        "# Generate channel model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnoArgs7imk9"
      },
      "outputs": [],
      "source": [
        "def Generate_channel(Nr, Nt, type):\n",
        "    if (type == 'gauss'):\n",
        "        return (np.random.normal(size=(Nr,Nt))+1j*np.random.normal(size=(Nr,Nt)))/np.sqrt(2)\n",
        "    if (type == 'rayleigh'):\n",
        "        return (np.random.rayleigh(scale=(1/np.sqrt(2)), size=(Nr,Nt)) + 1j*np.random.rayleigh(scale=(1/np.sqrt(2)), size=(Nr,Nt)))/np.sqrt(2)\n",
        "    if (type == 'rician'):\n",
        "        b = 1/np.sqrt(2)\n",
        "        return (rice.rvs(b, size=(Nr,Nt)) + 1j*rice.rvs(b, size=(Nr,Nt)))/np.sqrt(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eciNtnFjq2yd"
      },
      "source": [
        "# **Generate Dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE4Q6jZCq3CY"
      },
      "outputs": [],
      "source": [
        "DataSet_x   = []  # x dataset after modulation\n",
        "DataSet_y   = []  # y dataset\n",
        "DataSet_HH  = []  # H dataset\n",
        "DataSet_b   = []  # binary dataset\n",
        "SNR_min_dB  = 0\n",
        "SNR_max_dB  = 20\n",
        "step_dB     = 5\n",
        "num_dB      = int((SNR_max_dB - SNR_min_dB) / step_dB) + 1\n",
        "\n",
        "SNR         = np.linspace(SNR_min_dB, SNR_max_dB, num=num_dB)\n",
        "\n",
        "\n",
        "Nt = 8             # Tx: 8\n",
        "Nr = 64            # Rx: 128\n",
        "N_samp = 4000\n",
        "\n",
        "\n",
        "def Gen_dataset(mode, snr, imperfect, N_samp):\n",
        "    DataSet_x   = []  # x dataset after modulation\n",
        "    DataSet_y   = []  # y dataset\n",
        "    DataSet_H   = []\n",
        "    DataSet_HH  = []\n",
        "\n",
        "    NumSubcarriers = 1\n",
        "    Modulation = '16QAM'\n",
        "    QAM16 = [-1, -0.333, 0.333, 1]\n",
        "    NumDataSymb = 1\n",
        "    N_type = 'gauss'\n",
        "\n",
        "    if mode == 'train':\n",
        "        for snr in SNR:\n",
        "            for runIdx in range(0, N_samp):      # ! 20000 x Nt: samples\n",
        "                H = Generate_channel(Nt, Nr, N_type)\n",
        "                HH = np.concatenate((np.concatenate((H.real, H.imag), axis=1),\n",
        "                                    np.concatenate((-H.imag, H.real), axis=1)), axis=0)\n",
        "                x = np.zeros((2*Nt, NumSubcarriers))\n",
        "                a = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                DataRaw = np.zeros((Nt, a))\n",
        "                for t in range(Nt):\n",
        "                    #\"data symbol generate\"\n",
        "                    NumBits = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                    bit = np.random.randint(1, 3, NumBits)-1\n",
        "                    DataRaw[t, :] = bit\n",
        "                    for j in range(4):\n",
        "                        DataSet_b.append(bit[j])\n",
        "                    I = np.zeros((1, a))\n",
        "                    I[0, :] = DataRaw[t, :]\n",
        "                    (dataI, dataQ) = slicer(I[0])\n",
        "\n",
        "                    # Mapper\n",
        "                    mapI = mapper_16QAM(QAM16, dataI)\n",
        "                    mapQ = mapper_16QAM(QAM16, dataQ)\n",
        "                    x[t] = mapI[0]\n",
        "                    x[t+Nt] = mapQ[0]\n",
        "\n",
        "                # transpose\n",
        "                x = x.transpose()\n",
        "\n",
        "                y_wo_noise = np.matmul(x, HH)\n",
        "\n",
        "                # noise\n",
        "                noise = AWGN(y_wo_noise.transpose(), snr)\n",
        "\n",
        "                y = y_wo_noise + noise.transpose()\n",
        "\n",
        "                DataSet_x.append(x)    # ! I, Q sample distance by Nt.\n",
        "                DataSet_y.append(y)                 # ! output sample\n",
        "\n",
        "                # Imperfect channel: 5%\n",
        "                # coef = (2*np.random.randint(0,2,size=HH.shape) - 1)\n",
        "                # HH = HH + coef * HH * 0.05\n",
        "                DataSet_HH.append(HH)\n",
        "                DataSet_H.append(H)               # ! Generated channel\n",
        "\n",
        "    else:\n",
        "        for runIdx in range(0, N_samp):      # ! 20000 x Nt: samples\n",
        "            H = Generate_channel(Nt, Nr, N_type)\n",
        "            HH = np.concatenate((np.concatenate((H.real, H.imag), axis=1),\n",
        "                                np.concatenate((-H.imag, H.real), axis=1)), axis=0)\n",
        "            x = np.zeros((2*Nt, NumSubcarriers))\n",
        "            a = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "            DataRaw = np.zeros((Nt, a))\n",
        "            for t in range(Nt):\n",
        "                #\"data symbol generate\"\n",
        "                NumBits = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                bit = np.random.randint(1, 3, NumBits)-1\n",
        "                DataRaw[t, :] = bit\n",
        "                for j in range(4):\n",
        "                    DataSet_b.append(bit[j])\n",
        "                I = np.zeros((1, a))\n",
        "                I[0, :] = DataRaw[t, :]\n",
        "                (dataI, dataQ) = slicer(I[0])\n",
        "\n",
        "                # Mapper\n",
        "                mapI = mapper_16QAM(QAM16, dataI)\n",
        "                mapQ = mapper_16QAM(QAM16, dataQ)\n",
        "                x[t] = mapI[0]\n",
        "                x[t+Nt] = mapQ[0]\n",
        "\n",
        "            # transpose\n",
        "            x = x.transpose()\n",
        "\n",
        "            y_wo_noise = np.matmul(x, HH)\n",
        "\n",
        "            # noise\n",
        "            noise = AWGN(y_wo_noise.transpose(), snr)\n",
        "\n",
        "            y = y_wo_noise + noise.transpose()\n",
        "\n",
        "            DataSet_x.append(x)    # ! I, Q sample distance by Nt.\n",
        "            DataSet_y.append(y)                 # ! output sample\n",
        "\n",
        "            # Imperfect channel: 5%\n",
        "            DataSet_HH.append(HH)\n",
        "            DataSet_H.append(H)               # ! Generated channel\n",
        "\n",
        "\n",
        "    # Shuffle dataset\n",
        "    random.seed(1)\n",
        "    temp = list(zip(DataSet_x, DataSet_y, DataSet_H, DataSet_HH))\n",
        "    random.shuffle(temp)\n",
        "    DataSet_x, DataSet_y, DataSet_H, DataSet_HH = zip(*temp)\n",
        "\n",
        "    return DataSet_x, DataSet_y, DataSet_H, DataSet_HH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nWo2pTrimk-"
      },
      "outputs": [],
      "source": [
        "def reconstruct_channel (H):\n",
        "# H_raw = [R(H) I(H); -I(H) R(H)]\n",
        "# we have four version of H_est\n",
        "    H_est_1 = []\n",
        "    H_est_2 = []\n",
        "    H_est_3 = []\n",
        "    H_est_4 = []\n",
        "\n",
        "    H_est_Re_1 = H[0:Nt, 0:Nr]\n",
        "    H_est_Im_1 = H[0:Nt, Nr:2*Nr]\n",
        "    H_est_Im_2 = - H[Nt:2*Nt, 0:Nr]\n",
        "    H_est_Re_2 = H[Nt:2*Nt, Nr:2*Nr]\n",
        "\n",
        "    H_est_1 = H_est_Re_1 + 1j * H_est_Im_1\n",
        "    H_est_2 = H_est_Re_1 + 1j * H_est_Im_2\n",
        "    H_est_3 = H_est_Re_2 + 1j * H_est_Im_1\n",
        "    H_est_4 = H_est_Re_2 + 1j * H_est_Im_2\n",
        "\n",
        "    return H_est_1, H_est_2, H_est_3, H_est_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQUDE5Q1imk-"
      },
      "outputs": [],
      "source": [
        "# def NMSE(H_est, H_raw):\n",
        "#     H_est_1, H_est_2, H_est_3, H_est_4 = reconstruct_channel(H_est)\n",
        "#     H_est_vec_1 = torch.reshape(H_est_1, [Nt * Nr, 1])\n",
        "#     H_est_vec_2 = torch.reshape(H_est_2, [Nt * Nr, 1])\n",
        "#     H_est_vec_3 = torch.reshape(H_est_3, [Nt * Nr, 1])\n",
        "#     H_est_vec_4 = torch.reshape(H_est_4, [Nt * Nr, 1])\n",
        "\n",
        "#     H_raw_vec = torch.reshape(H_raw, [Nt * Nr, 1])\n",
        "\n",
        "#     mse_1       = (torch.norm(H_raw_vec - H_est_vec_1)**2) / len(H_raw_vec)\n",
        "#     mse_2       = (torch.norm(H_raw_vec - H_est_vec_2)**2) / len(H_raw_vec)\n",
        "#     mse_3       = (torch.norm(H_raw_vec - H_est_vec_3)**2) / len(H_raw_vec)\n",
        "#     mse_4       = (torch.norm(H_raw_vec - H_est_vec_4)**2) / len(H_raw_vec)\n",
        "\n",
        "#     sigEner   = torch.norm(H_raw_vec)**2\n",
        "\n",
        "#     nmse_1      = mse_1 / sigEner\n",
        "#     nmse_2      = mse_2 / sigEner\n",
        "#     nmse_3      = mse_3 / sigEner\n",
        "#     nmse_4      = mse_4 / sigEner\n",
        "\n",
        "#     # Best nmse\n",
        "#     nmse        = min([nmse_1, nmse_2, nmse_3, nmse_4])\n",
        "\n",
        "#     return torch.abs(nmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knU4OnL3imk_"
      },
      "outputs": [],
      "source": [
        "def NMSE(H_est, H_raw):\n",
        "    H_est_1, H_est_2, H_est_3, H_est_4 = reconstruct_channel(H_est)\n",
        "\n",
        "    # Lấy phần thực của các tensor nếu chúng là complex\n",
        "    H_est_vec_1 = torch.reshape(H_est_1, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_2 = torch.reshape(H_est_2, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_3 = torch.reshape(H_est_3, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_4 = torch.reshape(H_est_4, [Nt * Nr, 1]).abs()\n",
        "\n",
        "    H_raw_vec = torch.reshape(H_raw, [Nt * Nr, 1]).abs()\n",
        "\n",
        "    mse_1 = (torch.norm(H_raw_vec - H_est_vec_1)**2) / len(H_raw_vec)\n",
        "    mse_2 = (torch.norm(H_raw_vec - H_est_vec_2)**2) / len(H_raw_vec)\n",
        "    mse_3 = (torch.norm(H_raw_vec - H_est_vec_3)**2) / len(H_raw_vec)\n",
        "    mse_4 = (torch.norm(H_raw_vec - H_est_vec_4)**2) / len(H_raw_vec)\n",
        "\n",
        "    sigEner = torch.norm(H_raw_vec)**2\n",
        "\n",
        "    nmse_1 = mse_1 / sigEner\n",
        "    nmse_2 = mse_2 / sigEner\n",
        "    nmse_3 = mse_3 / sigEner\n",
        "    nmse_4 = mse_4 / sigEner\n",
        "\n",
        "    # Chọn NMSE tốt nhất\n",
        "    nmse = min([nmse_1, nmse_2, nmse_3, nmse_4])\n",
        "\n",
        "    return torch.abs(nmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyjIgxUurU0P"
      },
      "outputs": [],
      "source": [
        "def Input_ISDNN(mode, DataSet_x, DataSet_y, DataSet_H, DataSet_HH, N_samp):\n",
        "    H_in = []        # ! H_in    , np.diag(np.diag()) return a diag matrix instead of diag components.\n",
        "    H_true = []   # ! generated s\n",
        "    H_raw = []\n",
        "    e = []        # ! vector errors\n",
        "    xTx = []\n",
        "    xTy = []\n",
        "    Di = []\n",
        "    # steering = [] # ! Steering vector: ZoA and AoA\n",
        "\n",
        "    if mode == 'train':\n",
        "        n_sample = N_samp * len(SNR)\n",
        "    else:\n",
        "        n_sample = N_samp\n",
        "\n",
        "    for i in range (n_sample):\n",
        "        H_true.append(torch.tensor(DataSet_HH[i]))\n",
        "        H_raw.append(torch.tensor(DataSet_H[i]))\n",
        "        Di.append(torch.tensor(np.linalg.pinv(np.diag(np.diag(np.dot(DataSet_x[i].transpose(), DataSet_x[i]))))))\n",
        "        xTy.append(torch.tensor(np.dot(DataSet_x[i].transpose(), DataSet_y[i])))\n",
        "        H_in.append(torch.matmul(Di[i], xTy[i]))\n",
        "        e.append(torch.rand([2*Nt, 2*Nr]))\n",
        "        xTx.append(torch.tensor(np.dot(DataSet_x[i].transpose(), DataSet_x[i])))\n",
        "        # steering.append(torch.tensor(DataSet_Steering[i]))\n",
        "\n",
        "    H_true = torch.stack(H_true, dim=0)\n",
        "    H_raw = torch.stack(H_raw, dim=0)\n",
        "    H_in = torch.stack(H_in, dim=0)\n",
        "    e = torch.stack(e, dim=0)\n",
        "    xTx = torch.stack(xTx, dim=0)\n",
        "    xTy = torch.stack(xTy, dim=0)\n",
        "    Di = torch.stack(Di, dim=0)\n",
        "    # steering = torch.stack(steering, dim=0)\n",
        "\n",
        "    return H_true, H_raw, H_in, e, xTx, xTy, Di"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGhdBsghq3M9"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHceh5kuq3ZD"
      },
      "outputs": [],
      "source": [
        "class xv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(xv, self).__init__()\n",
        "\n",
        "        self.alpha1 = torch.nn.parameter.Parameter(torch.rand(1))\n",
        "        self.alpha2 = torch.nn.parameter.Parameter(torch.tensor([0.5]))\n",
        "\n",
        "    def forward(self, Di, H, e, xTx, xTy):\n",
        "\n",
        "        xTxH = torch.bmm(xTx, H)\n",
        "\n",
        "        z    = H + torch.bmm(Di, torch.sub(xTy, xTxH)) + self.alpha1 * e\n",
        "\n",
        "        e    = torch.sub(xTy, xTxH)\n",
        "\n",
        "        H    = torch.add((1 - self.alpha2) * z, self.alpha2 * H)\n",
        "\n",
        "        return H, e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woRjD7lJssRq"
      },
      "outputs": [],
      "source": [
        "class model_driven(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(model_driven, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc2 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc3 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc4 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc5 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc6 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc7 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc8 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        #self.fc9 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        #self.fc10 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        #self.fc11 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        #self.fc12 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "\n",
        "        self.layer1=xv()\n",
        "        self.layer2=xv()\n",
        "        self.layer3=xv()\n",
        "        self.layer4=xv()\n",
        "        #self.layer5=xv()\n",
        "        #self.layer6=xv()\n",
        "\n",
        "    def forward(self, Di, H_in, e, xTx, xTy):\n",
        "        e = self.fc1(e)\n",
        "        e = self.fc2(e)\n",
        "        H, e = self.layer1(Di, H_in, e, xTx, xTy)\n",
        "        H = torch.tanh(H)\n",
        "\n",
        "        e = self.fc3(e)\n",
        "        e = self.fc4(e)\n",
        "        H, e = self.layer2(Di, H, e, xTx, xTy)\n",
        "        H = torch.tanh(H)\n",
        "\n",
        "        e = self.fc5(e)\n",
        "        e = self.fc6(e)\n",
        "        H, e = self.layer3(Di, H, e, xTx, xTy)\n",
        "        H = torch.tanh(H)\n",
        "\n",
        "        e = self.fc7(e)\n",
        "        e = self.fc8(e)\n",
        "        H, e = self.layer4(Di, H, e, xTx, xTy)\n",
        "        #H = torch.tanh(H)\n",
        "\n",
        "        #e = self.fc9(e)\n",
        "        #e = self.fc10(e)\n",
        "        #H, e = self.layer5(Di, H, e, xTx, xTy)\n",
        "        #H = torch.tanh(H)\n",
        "\n",
        "        #e = self.fc11(e)\n",
        "        #e = self.fc12(e)\n",
        "        #H, e = self.layer6(Di, H, e, xTx, xTy)\n",
        "\n",
        "        return H, e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZjihTOXq3kG"
      },
      "source": [
        "# Define model, optimizer, and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp9fRd3gq3tw"
      },
      "outputs": [],
      "source": [
        "def def_model():\n",
        "    model = model_driven()\n",
        "    loss = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    folder_model = './model/'\n",
        "\n",
        "    if not os.path.isdir(folder_model):\n",
        "        os.makedirs(folder_model)\n",
        "\n",
        "    file_model = folder_model + 'H'\n",
        "    # if os.path.isfile(file_model):\n",
        "    #     generator = torch.load(file_model)\n",
        "\n",
        "    record_file = 'H'\n",
        "    return model, loss, optimizer, record_file, file_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYWM7SzItKzS"
      },
      "source": [
        "# Main program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv7lDwyxtFe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b34897-82bf-4c90-8038-73dc9554bf08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3e5f3c45b18a>:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  dP[i] = abs(IFsig[i])**2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dữ liệu đã được sinh và lưu lại!\n",
            "Begin training...\n",
            "154.78635855419293\n",
            "153.21659044247536\n",
            "154.50854255041466\n",
            "152.32479750316324\n",
            "154.36468336335668\n",
            "153.9468788076276\n",
            "151.34816890756795\n",
            "152.63675868400503\n",
            "152.39251993712648\n",
            "151.1004693264369\n",
            "155.5160915155365\n",
            "153.41327710717619\n",
            "155.47806617944488\n",
            "152.79876169054884\n",
            "152.7684135721932\n",
            "154.50695914858943\n",
            "152.996843064879\n",
            "154.22786485242082\n",
            "157.1134261476013\n",
            "155.94336422564467\n",
            "151.33167608934053\n",
            "152.67614111132664\n",
            "152.34256255953062\n",
            "156.58842195238225\n",
            "157.48995956634266\n",
            "153.52936524367036\n",
            "155.32924895629915\n",
            "156.30639827214318\n",
            "155.75432231524357\n",
            "157.3165640858106\n",
            "153.46613799427368\n",
            "153.64511598525556\n",
            "155.29495021090827\n",
            "156.97120298318032\n",
            "156.92537493176485\n",
            "155.0089702622513\n",
            "156.3817806649039\n",
            "154.0371419622439\n",
            "155.88895931108598\n",
            "154.75125765834196\n",
            "155.45218546354\n",
            "153.79115557901042\n",
            "151.12524123963857\n",
            "156.93365251005184\n",
            "151.3664953458651\n",
            "151.4204219592\n",
            "151.8110924264924\n",
            "151.25566068567466\n",
            "157.12105178930946\n",
            "150.0992808675309\n",
            "149.31542971041267\n",
            "150.93546812930933\n",
            "154.06783382591175\n",
            "151.39108884969735\n",
            "157.16628692211717\n",
            "158.70068331531039\n",
            "154.49312507022486\n",
            "153.16422111447721\n",
            "156.5753254503568\n",
            "152.6590684231535\n",
            "154.68599172054257\n",
            "159.28610902397386\n",
            "154.89096165623633\n",
            "153.38010506250913\n",
            "154.99566236385647\n",
            "150.67692975345628\n",
            "151.04272608319812\n",
            "156.8967737576796\n",
            "151.78959312577484\n",
            "156.5719749818919\n",
            "156.0763378884495\n",
            "154.49035616255503\n",
            "154.82790176042792\n",
            "150.47245244006382\n",
            "153.33452497721322\n",
            "150.9771577753112\n",
            "157.48741218287915\n",
            "155.46836118445376\n",
            "153.6415179384742\n",
            "152.54233738936756\n",
            "155.9931946159758\n",
            "154.51671498014426\n",
            "159.5014600974357\n",
            "154.54429997847382\n",
            "154.6830515079164\n",
            "154.11581000070473\n",
            "158.85851637926427\n",
            "155.339562205298\n",
            "153.9822008723201\n",
            "151.20725033368205\n",
            "156.87968563468988\n",
            "153.38662511301848\n",
            "157.11950749707418\n",
            "157.5835313952648\n",
            "153.75000986351478\n",
            "156.80428329865964\n",
            "152.7514567467105\n",
            "156.3244282847303\n",
            "156.17952822635888\n",
            "154.82141078752625\n",
            "151.22596613995702\n",
            "154.1525801401783\n",
            "155.06839217890607\n",
            "153.99573396645204\n",
            "153.89791831759493\n",
            "153.059283650019\n",
            "153.68018442380742\n",
            "154.86494793683198\n",
            "150.84137362451648\n",
            "151.15593125283914\n",
            "152.50841776407987\n",
            "153.29550546134618\n",
            "159.97256992042242\n",
            "155.88076186566906\n",
            "155.24334829359992\n",
            "155.48209695559248\n",
            "156.22824033125153\n",
            "156.40789008384294\n",
            "153.88142073616226\n",
            "153.88141791513345\n",
            "154.3555201307428\n",
            "147.69840351017737\n",
            "155.04348537804327\n",
            "154.96554503898443\n",
            "154.15531694042957\n",
            "154.57265012762457\n",
            "151.70100277749216\n",
            "155.17606208702645\n",
            "156.51697709248805\n",
            "155.92258158881162\n",
            "150.23530473036968\n",
            "151.07547063358012\n",
            "154.29471631241756\n",
            "154.76781219897788\n",
            "151.93756511843873\n",
            "156.76927116125307\n",
            "159.25884699080717\n",
            "155.66923340595068\n",
            "155.61474547795595\n",
            "154.29425785984535\n",
            "155.9874635378001\n",
            "153.61311190625668\n",
            "154.38726980844393\n",
            "154.24092750184673\n",
            "153.84658818036513\n",
            "152.111322698062\n",
            "150.58943833076205\n",
            "156.03201537136937\n",
            "155.56153846320197\n",
            "154.6552845808133\n",
            "149.4922394616283\n",
            "154.46571586090928\n",
            "150.75888098484145\n",
            "154.86425584907352\n",
            "153.18085649270952\n",
            "155.46576616878127\n",
            "158.88252955689615\n",
            "153.85192809132008\n",
            "159.6653970341315\n",
            "153.90599813695576\n",
            "151.79485498931894\n",
            "153.6843584178077\n",
            "153.8068371028137\n",
            "155.1648220990518\n",
            "153.85126078545372\n",
            "149.99479649244606\n",
            "154.072666388788\n",
            "150.81321061469637\n",
            "156.12425926639173\n",
            "155.95247282781023\n",
            "154.09099130877533\n",
            "154.3112239148349\n",
            "155.72397759275185\n",
            "153.4451629982698\n",
            "155.8913818886175\n",
            "151.71581748647134\n",
            "149.79509468622695\n",
            "153.50759605097622\n",
            "153.9069559262241\n",
            "156.60907383994012\n",
            "155.2769828549844\n",
            "155.8361091679459\n",
            "152.94709307750125\n",
            "155.65536400604344\n",
            "155.10778758667576\n",
            "155.59780161017667\n",
            "155.85283883451993\n",
            "154.9340244807904\n",
            "154.97443293329133\n",
            "152.83601038117203\n",
            "152.6604771424398\n",
            "150.40537166332976\n",
            "157.77576395758868\n",
            "156.07270510736382\n",
            "154.72371096314177\n",
            "156.3761480610447\n",
            "156.50323141949713\n",
            "154.6019460436085\n",
            "155.8145350172501\n",
            "153.75239159709048\n",
            "157.39996463054453\n",
            "157.14564147746182\n",
            "153.34584540771226\n",
            "155.64705578004182\n",
            "151.82713137039855\n",
            "154.9016787017458\n",
            "155.04771130249134\n",
            "154.65763857768573\n",
            "153.4310230822438\n",
            "151.7150823174291\n",
            "157.29149075709088\n",
            "155.45396255609808\n",
            "156.31315214101195\n",
            "156.31741970906606\n",
            "152.77491400014\n",
            "155.48393223109838\n",
            "156.3634410580674\n",
            "158.8311217808383\n",
            "152.40808910742336\n",
            "156.96753087432825\n",
            "152.40219419917415\n",
            "154.5767761958409\n",
            "159.57435239633435\n",
            "153.6440804574267\n",
            "152.8870987036256\n",
            "154.38119334875057\n",
            "154.02685774799914\n",
            "154.2243299450921\n",
            "155.38635553321248\n",
            "156.93739964622264\n",
            "154.13423150272413\n",
            "158.23521252662886\n",
            "153.14677882654715\n",
            "155.62989067370415\n",
            "151.60896632163977\n",
            "155.48479035380197\n",
            "154.8834312213539\n",
            "156.25170345884288\n",
            "150.66869096554728\n",
            "154.24164926659907\n",
            "150.2548500550337\n",
            "151.99851973804385\n",
            "157.816685837923\n",
            "154.0732475701281\n",
            "153.9817354902358\n",
            "153.56513507675928\n",
            "149.26073699401272\n",
            "156.32803700051375\n",
            "155.8095046516667\n",
            "158.48295673333052\n",
            "156.09573904583382\n",
            "150.39899140074522\n",
            "151.45555479155252\n",
            "157.843457113816\n",
            "155.06132087609268\n",
            "151.48697270104378\n",
            "151.27452392146392\n",
            "152.08201108010513\n",
            "153.09434349882932\n",
            "154.88049803704664\n",
            "158.28382988852786\n",
            "151.28175278338517\n",
            "156.36137646329541\n",
            "157.42932301710093\n",
            "152.01110667725098\n",
            "158.2727922920166\n",
            "155.07682458371326\n",
            "155.78036956997562\n",
            "155.3290332109755\n",
            "156.51719012306478\n",
            "157.003832255554\n",
            "155.81624357170844\n",
            "152.3884246237062\n",
            "152.60980035523784\n",
            "154.56586138457658\n",
            "152.9129609673949\n",
            "156.29758376783516\n",
            "152.2048745795476\n",
            "156.46824785039112\n",
            "155.5087233543964\n",
            "156.68665581315878\n",
            "156.1719352851944\n",
            "154.87448234550456\n",
            "154.60400800278768\n",
            "149.28674695154814\n",
            "152.4864768373174\n",
            "155.0090771923768\n",
            "152.74026845810516\n",
            "155.08942092158622\n",
            "154.9768747363748\n",
            "156.3181856217632\n",
            "150.03274263998247\n",
            "152.08178639650123\n",
            "151.0843907403503\n",
            "154.8427858460596\n",
            "153.42269226540142\n",
            "155.17760901416958\n",
            "153.92818996446505\n",
            "157.01993467857474\n",
            "151.99234496720194\n",
            "151.56148641607248\n",
            "156.03812763128423\n",
            "154.46429367675282\n",
            "154.36625545906813\n",
            "158.44357407564962\n",
            "153.04565518335383\n",
            "154.20883671310003\n",
            "156.11731111807055\n",
            "151.85751187852827\n",
            "154.04390479359552\n",
            "150.04485276207555\n",
            "157.2901428591798\n",
            "156.11537309206074\n",
            "154.90888635963725\n",
            "156.8337879835409\n",
            "157.4069912679136\n",
            "150.19104094394376\n",
            "153.31808233448547\n",
            "153.6296737824582\n",
            "156.3365096542659\n",
            "156.0380132946518\n",
            "156.98056965486873\n",
            "155.23611931162748\n",
            "146.5155365037277\n",
            "154.01242226770077\n",
            "152.90648428228835\n",
            "151.1998026594579\n",
            "155.57355789005263\n",
            "152.39106623297354\n",
            "157.85785401877177\n",
            "156.5906847493043\n",
            "152.65334949825214\n",
            "155.25297377713403\n",
            "152.52018058377735\n",
            "150.53412630809544\n",
            "156.00466898328355\n",
            "152.17560843655897\n",
            "157.50769221392324\n",
            "155.61204882420282\n",
            "153.50314615791766\n",
            "153.80814232808854\n",
            "153.0405228918461\n",
            "152.66938251947047\n",
            "152.92257252427248\n",
            "155.14956486265794\n",
            "154.11149817162917\n",
            "151.55282670478005\n",
            "154.79292270279598\n",
            "155.56112312161346\n",
            "153.1290452687698\n",
            "153.69078443758\n",
            "154.419111224995\n",
            "154.54528206484406\n",
            "154.56924131136975\n",
            "154.07812014121723\n",
            "156.22478424516427\n",
            "160.91725980751434\n",
            "155.86501801572277\n",
            "156.96150245109246\n",
            "155.49865957780574\n",
            "152.55286867996452\n",
            "153.27603366628625\n",
            "157.44228344913182\n",
            "154.72427340786106\n",
            "153.8174191105197\n",
            "152.82063796776495\n",
            "155.46563984474963\n",
            "154.11176512707206\n",
            "151.6355777164395\n",
            "156.93335832182083\n",
            "156.66636778896324\n",
            "160.31676603279251\n",
            "153.10843225698542\n",
            "152.5983294340154\n",
            "155.9337608838332\n",
            "156.92853929717828\n",
            "151.80649854086525\n",
            "153.46843677993246\n",
            "156.67792795500836\n",
            "156.2610980432755\n",
            "156.06983345882222\n",
            "153.8790478818089\n",
            "152.0800367517538\n",
            "153.4151900220389\n",
            "146.37620020645642\n",
            "152.1125818366791\n",
            "153.18663869997619\n",
            "155.32314535290013\n",
            "155.23460825226167\n",
            "155.71303050123117\n",
            "157.8395692229191\n",
            "156.61598037074657\n",
            "150.79054320767855\n",
            "156.2815763276632\n",
            "156.59709304367726\n",
            "156.88063601981565\n",
            "157.87124277977347\n",
            "152.58976779327756\n",
            "152.8765021275801\n",
            "154.19010757926029\n",
            "151.571493930537\n",
            "154.62761449192504\n",
            "154.45026958019443\n",
            "155.96771842280899\n",
            "152.9064869862817\n",
            "154.64011576877755\n",
            "154.37769866376948\n",
            "154.2658322496278\n",
            "154.5724866954198\n",
            "151.44051222736874\n",
            "155.277636393778\n",
            "150.88288612109238\n",
            "156.5384731341039\n",
            "153.47237363227327\n",
            "156.59955624493932\n",
            "157.31789919217405\n",
            "148.99552407782738\n",
            "153.34624977497728\n",
            "153.6937317814668\n",
            "155.02764713739322\n",
            "155.84634587557375\n",
            "155.76561009850582\n",
            "152.84515661979702\n",
            "155.25482693194462\n",
            "154.1775905481629\n",
            "155.71498262265632\n",
            "156.22023437796875\n",
            "154.13717291882278\n",
            "152.9320624622068\n",
            "155.35318608416654\n",
            "153.86334728266868\n",
            "152.92595619527003\n",
            "155.5846577484352\n",
            "156.02377676561866\n",
            "152.78232572238522\n",
            "153.58391003326696\n",
            "153.90884524908424\n",
            "157.37379838689688\n",
            "152.15335534473212\n",
            "156.59537748891017\n",
            "154.63941965150443\n",
            "156.57902248259796\n",
            "151.0371725707727\n",
            "155.2066809878103\n",
            "152.36518357358966\n",
            "156.85236450824002\n",
            "152.81247400582942\n",
            "155.60064108794856\n",
            "152.6031375000998\n",
            "154.81447593540236\n",
            "150.31152939255756\n",
            "157.11487865489212\n",
            "155.31747552085997\n",
            "154.23611531872456\n",
            "151.69169560059464\n",
            "159.01776243105908\n",
            "155.04442184150753\n",
            "155.10398656521772\n",
            "155.60552033269042\n",
            "152.07954412422563\n",
            "154.40507703026424\n",
            "155.90060448710298\n",
            "153.693860951189\n",
            "153.43664966728176\n",
            "152.8056676870117\n",
            "153.34624181853727\n",
            "156.93591839060088\n",
            "156.50705207419938\n",
            "153.98770863299865\n",
            "152.04954744478266\n",
            "158.14969732458826\n",
            "156.16415742087895\n",
            "153.3335134067337\n",
            "149.9178265925352\n",
            "154.73338860268095\n",
            "155.65714915753068\n",
            "152.16783359110676\n",
            "153.96547683166938\n",
            "151.74967287920876\n",
            "151.3043713314931\n",
            "153.0915448327267\n",
            "150.91875069314656\n",
            "156.0209583706118\n",
            "155.78086792515256\n",
            "154.33218871298303\n",
            "149.08035320222763\n",
            "154.25639273294394\n",
            "158.27732371341497\n",
            "155.54104591791065\n",
            "157.20003582647468\n",
            "154.0727196736273\n",
            "153.78412883815997\n",
            "156.66890166181997\n",
            "153.11845138550873\n",
            "155.54104640727135\n",
            "155.66353011882845\n",
            "155.87284331821192\n",
            "153.60776438467516\n",
            "150.77618871485387\n",
            "150.34612501030026\n",
            "159.52696136477107\n",
            "148.3675833484045\n",
            "149.4557257684788\n",
            "157.30794517314393\n",
            "155.0973415153467\n",
            "150.95416318033887\n",
            "157.08797137289812\n",
            "152.23286172202594\n",
            "152.924313634801\n",
            "156.1314694345002\n",
            "154.47718514962884\n",
            "154.808689204047\n",
            "1 0.06894773856734426 32.889460412357145\n",
            "100 0.0005778445273595807 0.7443719495169985\n",
            "200 0.0019798007134545926 1.0873162751929037\n",
            "300 0.0006368162082497264 1.2881819680244184\n",
            "400 0.0005918923453127592 0.7664832838954055\n",
            "1924.943876992\n"
          ]
        }
      ],
      "source": [
        "epoch         = 0\n",
        "expected_epoch = 20000\n",
        "num_samp      = N_samp * len(SNR)\n",
        "best_nmse     = 1e9\n",
        "early_stop    = 0\n",
        "best_model    = ''\n",
        "batch_size    = int(num_samp / 512)\n",
        "\n",
        "# Kiểm tra nếu file tĩnh tồn tại\n",
        "if os.path.exists('dataset_ISDNN.pkl'):\n",
        "    with open('dataset_ISDNN.pkl', 'rb') as f:\n",
        "        DataSet_x, DataSet_y, DataSet_H, DataSet_HH, H_true, H_raw, H_in, e, xTx, xTy, Di = pickle.load(f)\n",
        "    print(\"Dữ liệu đã được tải từ file tĩnh!\")\n",
        "else:\n",
        "    # Sinh dữ liệu nếu file tĩnh không tồn tại\n",
        "    DataSet_x, DataSet_y, DataSet_H, DataSet_HH = Gen_dataset('train', 0, 0, N_samp)\n",
        "    H_true, H_raw, H_in, e, xTx, xTy, Di = Input_ISDNN('train', DataSet_x, DataSet_y, DataSet_H, DataSet_HH, N_samp)\n",
        "\n",
        "    # Lưu dữ liệu để lần sau không phải sinh lại\n",
        "    with open('dataset_ISDNN.pkl', 'wb') as f:\n",
        "        pickle.dump((DataSet_x, DataSet_y, DataSet_H, DataSet_HH, H_true, H_raw, H_in, e, xTx, xTy, Di), f)\n",
        "    print(\"Dữ liệu đã được sinh và lưu lại!\")\n",
        "\n",
        "print(\"Begin training...\")\n",
        "starttime = timeit.default_timer()\n",
        "\n",
        "while(True):\n",
        "        epoch = epoch + 1\n",
        "\n",
        "        init_loss = 1e9\n",
        "        while( epoch == 1 and init_loss > 200):\n",
        "\n",
        "                model, loss, optimizer, record_file, file_model = def_model()\n",
        "                for bs in range (int(num_samp / batch_size)):\n",
        "                    H_1, e_1 = model(Di[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 H_in[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 e[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTx[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTy[0 + batch_size * bs:batch_size * (bs+1), :, :])   # predict output from the model\n",
        "                    init_loss = loss(H_1, H_true[0 + batch_size * bs:batch_size * (bs+1), :, :]).item()\n",
        "                    print(init_loss)\n",
        "\n",
        "        optimizer.zero_grad()   # zero the parameter gradients\n",
        "        train_loss = 0\n",
        "        H_f = torch.empty([num_samp, 2*Nt, 2*Nr])\n",
        "        for bs in range (int(num_samp / batch_size)):\n",
        "                H_o, e_o = model(Di[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 H_in[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 e[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTx[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTy[0 + batch_size * bs:batch_size * (bs+1), :, :])   # predict output from the model\n",
        "                H_f[0 + batch_size * bs:batch_size * (bs+1), :, :] = H_o\n",
        "                train_loss = loss(H_o,\n",
        "                                  H_true[0 + batch_size * bs:batch_size * (bs+1), :, :])   # calculate loss for the predicted output\n",
        "                train_loss.backward()   # backpropagate the loss\n",
        "                optimizer.step()        # adjust parameters based on the calculated gradients\n",
        "\n",
        "        if (epoch % 100 == 0 or epoch == 1):\n",
        "                nmse = 0\n",
        "                for j in range (num_samp):\n",
        "                        nmse += NMSE(H_f[j], H_raw[j])\n",
        "                nmse = nmse / num_samp\n",
        "\n",
        "                if (nmse <= best_nmse):\n",
        "                        torch.save(model.state_dict(), file_model + '_' + str(epoch) + '.pth')\n",
        "                        best_model = file_model + '_' + str(epoch) + '.pth'\n",
        "                        best_nmse = nmse\n",
        "                        early_stop = 0\n",
        "                else:\n",
        "                        early_stop += 1\n",
        "\n",
        "                if (nmse > best_nmse and early_stop == 3):\n",
        "                        with Record(record_file + '_log.txt'):\n",
        "                                print(epoch, nmse.item(), train_loss.item())\n",
        "                                print(str(timeit.default_timer()-starttime))\n",
        "                        break\n",
        "\n",
        "                with Record(record_file + '_log.txt'):\n",
        "                        print(epoch, nmse.item(), train_loss.item())\n",
        "\n",
        "        if epoch  == expected_epoch:\n",
        "                torch.save(model.state_dict(), file_model + '_' + str(epoch) + '.pth')\n",
        "                best_model = file_model + '_' + str(epoch) + '.pth'\n",
        "                with Record(record_file + '_log.txt'):\n",
        "                        print(\"epoch:\\n\", epoch)\n",
        "                        print(\"Latest NMSE:\\n\", nmse.item())\n",
        "                        print(\"Latest Loss:\\n\", train_loss.item())\n",
        "                        print(str(timeit.default_timer()-starttime))\n",
        "\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOBK-_l-tRMO"
      },
      "source": [
        "# Test function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRRFGAX4tg_6"
      },
      "source": [
        "# Function to test the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#best_model = './model/H_500.pth'"
      ],
      "metadata": {
        "id": "hbzTeVvCcKJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfvpexfwthNq"
      },
      "outputs": [],
      "source": [
        "def test(H_raw, Di, H_in, e, xTx, xTy, N_test, log):\n",
        "    # Load the model that we saved at the end of the training loop\n",
        "    model = model_driven()\n",
        "    model.load_state_dict(torch.load(best_model, map_location=torch.device('cpu')))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        H_o, e_o = model(Di, H_in, e, xTx, xTy)\n",
        "\n",
        "        nmse = 0\n",
        "        for j in range (N_test):\n",
        "            nmse += NMSE(H_o[j], H_raw[j])\n",
        "\n",
        "        nmse = nmse / N_test\n",
        "        with Record(log):\n",
        "            print(format(nmse.item(), '.7f'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlrHA2aWimlC"
      },
      "outputs": [],
      "source": [
        "## Generate dataset for test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE_IiAiKimlC"
      },
      "outputs": [],
      "source": [
        "def LS(DataSet_x, DataSet_y):\n",
        "    start = timeit.default_timer()\n",
        "    for i in range (len(DataSet_x)):\n",
        "        H_hat = np.matmul(\n",
        "                    np.matmul(\n",
        "                        np.linalg.pinv(np.matmul(DataSet_x[i].transpose(), DataSet_x[i])),\n",
        "                        DataSet_x[i].transpose()),\n",
        "                        DataSet_y[i])\n",
        "    print(timeit.default_timer() - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "PAf8LBUFimlC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ca4058c-89b4-4aa9-eae4-b602bdeebd22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3e5f3c45b18a>:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  dP[i] = abs(IFsig[i])**2\n",
            "<ipython-input-18-173530151950>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model, map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0005762\n",
            "0.0005775\n",
            "0.0005772\n",
            "0.0005772\n",
            "0.0005773\n",
            "0.0005770\n",
            "0.0005771\n",
            "0.0005776\n",
            "0.0005751\n",
            "0.0005762\n",
            "0.0005765\n",
            "0.0005761\n",
            "0.0005786\n",
            "0.0005755\n",
            "0.0005776\n",
            "0.0005770\n",
            "0.0005757\n",
            "0.0005782\n",
            "0.0005776\n",
            "0.0005779\n",
            "0.0005762\n",
            "0.0005758\n",
            "0.0005797\n",
            "0.0005791\n",
            "0.0005782\n",
            "0.0005764\n",
            "0.0005772\n",
            "0.0005779\n",
            "0.0005760\n",
            "0.0005777\n",
            "0.0005760\n",
            "0.0005774\n",
            "0.0005773\n",
            "0.0005778\n",
            "0.0005769\n",
            "0.0005748\n",
            "0.0005760\n",
            "0.0005763\n",
            "0.0005772\n",
            "0.0005777\n",
            "0.0005756\n",
            "0.0005761\n",
            "0.0005788\n",
            "0.0005787\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f92b04bd01ee>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#     print(snr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mDataSet_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_HH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mH_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxTx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxTy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput_ISDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# LS(DataSet_x, DataSet_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-965ca8a78d1a>\u001b[0m in \u001b[0;36mInput_ISDNN\u001b[0;34m(mode, DataSet_x, DataSet_y, DataSet_H, DataSet_HH, N_samp)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mH_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataSet_HH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mH_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataSet_H\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mDi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataSet_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mxTy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataSet_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mH_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxTy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mpinv\u001b[0;34m(a, rcond, hermitian)\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m     \u001b[0;31m# discard small singular values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2025\u001b[0;31m     \u001b[0mcutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrcond\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2026\u001b[0m     \u001b[0mlarge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2027\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlarge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2825\u001b[0m     \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mequivalent\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \"\"\"\n\u001b[0;32m-> 2827\u001b[0;31m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[1;32m   2828\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     passkwargs = {k: v for k, v in kwargs.items()\n\u001b[0m\u001b[1;32m     73\u001b[0m                   if v is not np._NoValue}\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "SNR_min_dB  = 0\n",
        "SNR_max_dB  = 20\n",
        "step_dB     = 5\n",
        "num_dB      = int((SNR_max_dB - SNR_min_dB) / step_dB) + 1\n",
        "\n",
        "SNR         = np.linspace(SNR_min_dB, SNR_max_dB, num=num_dB)\n",
        "log         = './model/log_test.txt'\n",
        "\n",
        "N_test = int(num_samp * 30/100)\n",
        "\n",
        "for i in range (100):\n",
        "    for snr in SNR:\n",
        "        # with Record(log):\n",
        "        #     print(snr)\n",
        "        DataSet_x, DataSet_y, DataSet_H, DataSet_HH = Gen_dataset('test', snr, 0, N_test)\n",
        "        H_true, H_raw, H_in, e, xTx, xTy, Di = Input_ISDNN('test', DataSet_x, DataSet_y, DataSet_H, DataSet_HH, N_test)\n",
        "\n",
        "        # LS(DataSet_x, DataSet_y)\n",
        "        test(H_raw, Di, H_in, e, xTx, xTy, N_test, log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6_n95BiimlC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
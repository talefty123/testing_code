{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talefty123/testing_code/blob/main/Python/Structured/H_structured_ISD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSmcwLZuptDU"
      },
      "source": [
        "# Proposed Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG5fZn_ypunP"
      },
      "source": [
        "# **Biblioheque**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "--SvzvIspu-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6244dc7-c05e-4247-fdc6-e53788ffbfe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n",
            "  _C._set_default_tensor_type(t)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from scipy.stats import rice\n",
        "# import pandas as pd\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import sys\n",
        "import timeit\n",
        "import os\n",
        "\n",
        "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
        "torch.set_default_dtype(torch.float64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBk01Vu0pvMm"
      },
      "source": [
        "# class to save results in file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "06IymVCkpvYS"
      },
      "outputs": [],
      "source": [
        "class Record:\n",
        "    def __init__(self, TextName):\n",
        "        self.out_file = open(TextName, 'a')\n",
        "        self.old_stdout = sys.stdout\n",
        "        sys.stdout = self\n",
        "\n",
        "    def write(self, text):\n",
        "        self.old_stdout.write(text)\n",
        "        self.out_file.write(text)\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout = self.old_stdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xPamGjNpv8E"
      },
      "source": [
        "# **slicer the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dlQdA0xHpwF7"
      },
      "outputs": [],
      "source": [
        "def slicer(data):\n",
        "    dataI = data[slice(0, len(data), 2)]\n",
        "    dataQ = data[slice(1, len(data), 2)]\n",
        "    return(dataI, dataQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOoiIo_LpwQl"
      },
      "source": [
        "# **Modulation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xIftC8fvpwir"
      },
      "outputs": [],
      "source": [
        "def mapper_16QAM(QAM16, data):\n",
        "    map0 = 2*data[slice(0, len(data), 2)] + data[slice(1, len(data), 2)]\n",
        "    map0 = list(map(int, map0))\n",
        "    dataMapped = []\n",
        "    for i in range(len(map0)):\n",
        "        dataMapped.append(QAM16[map0[i]])\n",
        "    return(dataMapped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AYhPgAIcqtGT"
      },
      "outputs": [],
      "source": [
        "def calculate_bits(Modulation,NumSubcarriers,NumDataSymb):\n",
        "    if Modulation=='QPSK':\n",
        "        Nbpscs=2\n",
        "    elif Modulation=='16QAM':\n",
        "        Nbpscs=4\n",
        "    return NumDataSymb*NumSubcarriers*Nbpscs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgX6tiqFpwvb"
      },
      "source": [
        "# **generate noise**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2LQwZvGaprKZ"
      },
      "outputs": [],
      "source": [
        "def AWGN(IFsig, SNR):\n",
        "    dP = np.zeros(len(IFsig))\n",
        "    P = 0\n",
        "\n",
        "    for i in range(len(IFsig)):\n",
        "        dP[i] = abs(IFsig[i])**2\n",
        "        P = P + dP[i]\n",
        "\n",
        "    P = P/len(IFsig)\n",
        "    gamma = 10**(SNR/10)\n",
        "    N0 = P/gamma\n",
        "    n = ((N0/2)**(0.5))*np.random.standard_normal(len(IFsig))\n",
        "    IF_n = np.zeros((len(IFsig),1))\n",
        "\n",
        "    for i in range(len(IFsig)):\n",
        "        IF_n[i,:] = IFsig[i] + n[i]\n",
        "\n",
        "    return(IF_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4FN4cjoqEnL"
      },
      "source": [
        "# Generate channel model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Kpiu9npGqEnL"
      },
      "outputs": [],
      "source": [
        "def unstructured_channel(Nt, Nr, type):\n",
        "    if (type == 'gauss'):\n",
        "        return (np.random.normal(size=(Nt, Nr))+1j*np.random.normal(size=(Nt, Nr)))/np.sqrt(2)\n",
        "\n",
        "def Generate_channel(Nt, Nr, d_H, array_type, elements_nor, type, Nr_ULA, Nr_UCA):\n",
        "    if (type == 'gauss'):\n",
        "\n",
        "        H = (np.random.normal(size=(Nt, Nr))+1j*np.random.normal(size=(Nt, Nr)))/np.sqrt(2)\n",
        "        H_oG = np.zeros((Nt, Nr), dtype=complex)\n",
        "        Gamma = []\n",
        "        Zoa = []\n",
        "        Aoa = []\n",
        "\n",
        "        Steering = np.zeros((Nt, Nr, d_H), dtype=complex)\n",
        "\n",
        "        for nt in range (Nt):\n",
        "            # gamma = (np.random.normal(size=d_H)+1j*np.random.normal(size=d_H))/np.sqrt(2)\n",
        "            zoa = np.random.uniform(-np.pi / 2, np.pi / 2, d_H)\n",
        "            aoa = np.random.uniform(-np.pi / 2, np.pi / 2, d_H)\n",
        "\n",
        "            # Gamma.append(gamma)\n",
        "            Zoa.append(zoa)\n",
        "            Aoa.append(aoa)\n",
        "\n",
        "        # Gamma = np.array(Gamma)\n",
        "        Zoa = np.array(Zoa)\n",
        "        Aoa = np.array(Aoa)\n",
        "\n",
        "        if array_type == 'ULA':\n",
        "            for nt in range (Nt):\n",
        "                for nr in range (Nr):\n",
        "                    h = 0\n",
        "                    for dh in range(d_H):\n",
        "                        r_x = np.sin(Zoa[nt,dh]) * np.cos(Aoa[nt,dh])\n",
        "                        r_y = np.sin(Zoa[nt,dh]) * np.sin(Aoa[nt,dh])\n",
        "                        r_z = np.cos(Zoa[nt,dh])\n",
        "\n",
        "                        # h = h + Gamma[nn,dh] * np.exp(-1j*2*np.pi * (elements_nor[0, 0, nr]*r_x\n",
        "                        #                                             + elements_nor[1, 0, nr]*r_y\n",
        "                        #                                             + elements_nor[2, 0, nr]*r_z))\n",
        "\n",
        "                        Steering[nt, nr, dh] = np.exp(-1j*2*np.pi * (elements_nor[0, 0, nr]*r_x\n",
        "                                                                    + elements_nor[1, 0, nr]*r_y\n",
        "                                                                    + elements_nor[2, 0, nr]*r_z))\n",
        "\n",
        "                    H_oG[nt, nr] = np.divide(H[nt, nr],  Steering[nt, nr, 0])\n",
        "\n",
        "                    # H[nr, nn] = h\n",
        "        else:\n",
        "            for nt in range (Nt):\n",
        "                r = -1\n",
        "                for Nr_ULA_index in range (Nr_ULA):\n",
        "                    for Nr_UCA_index in range (Nr_UCA):\n",
        "                        r=r+1\n",
        "                        h = 0\n",
        "                        for dh in range(d_H):\n",
        "                            r_x = np.sin(Zoa[nt, dh]) * np.cos(Aoa[nt, dh])\n",
        "                            r_y = np.sin(Zoa[nt, dh]) * np.sin(Aoa[nt, dh])\n",
        "                            r_z = np.cos(Zoa[nt, dh])\n",
        "\n",
        "                            # h = h + Gamma[nt, dh] * np.exp(-1j*2*np.pi *  (elements_nor[0, Nr_ULA_index, Nr_UCA_index]*r_x\n",
        "                            #                                             + elements_nor[1, Nr_ULA_index, Nr_UCA_index]*r_y\n",
        "                            #                                             + elements_nor[2, Nr_ULA_index, Nr_UCA_index]*r_z))\n",
        "\n",
        "                            Steering[nt, r, dh] = np.exp(-1j*2*np.pi *(elements_nor[0, Nr_ULA_index, Nr_UCA_index]*r_x\n",
        "                                                                        + elements_nor[1, Nr_ULA_index, Nr_UCA_index]*r_y\n",
        "                                                                        + elements_nor[2, Nr_ULA_index, Nr_UCA_index]*r_z))\n",
        "\n",
        "                        # tmp_1 = 0\n",
        "                        # gamma = 0\n",
        "                        # while(tmp_1 < 0.6):\n",
        "                        #     gamma = (np.random.normal(size=d_H - 1)+1j*np.random.normal(size=d_H - 1))/np.sqrt(2)\n",
        "                        #     tmp = 0\n",
        "                        #     for jj in range (d_H - 1):\n",
        "                        #         tmp += gamma[jj] * Steering[r, nt, jj]\n",
        "                        #     last_gamma = np.divide(H[r, nt] - tmp, Steering[r, nt, d_H - 1])\n",
        "                        #     gamma = np.append(gamma, last_gamma)\n",
        "\n",
        "                        #     tmp_1 = min(abs(gamma))\n",
        "\n",
        "                        H_oG[nt, r] = np.divide(H[nt, r],  Steering[nt, r, 0])\n",
        "                        # H[r, nt] = h\n",
        "\n",
        "        return H, H_oG, Gamma, Steering\n",
        "\n",
        "    if (type == 'rayleigh'):\n",
        "        return (np.random.rayleigh(scale=(1/np.sqrt(2)), size=(Nt, Nr)) + 1j*np.random.rayleigh(scale=(1/np.sqrt(2)), size=(Nt, Nr)))/np.sqrt(2)\n",
        "    if (type == 'rician'):\n",
        "        b = 1/np.sqrt(2)\n",
        "        return (rice.rvs(b, size=(Nt, Nr)) + 1j*rice.rvs(b, size=(Nt, Nr)))/np.sqrt(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eciNtnFjq2yd"
      },
      "source": [
        "# **Generate Dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AE4Q6jZCq3CY"
      },
      "outputs": [],
      "source": [
        "DataSet_x   = []  # x dataset after modulation\n",
        "DataSet_y   = []  # y dataset\n",
        "DataSet_HH  = []  # H dataset\n",
        "DataSet_b   = []  # binary dataset\n",
        "SNR_min_dB  = 0\n",
        "SNR_max_dB  = 20\n",
        "step_dB     = 5\n",
        "num_dB      = int((SNR_max_dB - SNR_min_dB) / step_dB) + 1\n",
        "\n",
        "SNR         = np.linspace(SNR_min_dB, SNR_max_dB, num=num_dB)\n",
        "\n",
        "\n",
        "Nt = 8             # Tx: 8\n",
        "Nr = 64            # Rx: 128\n",
        "N_samp = 4000\n",
        "\n",
        "\n",
        "def Gen_dataset(mode, array_type, snr, imperfect, N_samp):\n",
        "    DataSet_x   = []  # x dataset after modulation\n",
        "    DataSet_y   = []  # y dataset\n",
        "    DataSet_H   = []\n",
        "    DataSet_HH  = []\n",
        "    DataSet_Steering = []\n",
        "\n",
        "    NumSubcarriers = 1\n",
        "    Modulation = '16QAM'\n",
        "    QAM16 = [-1, -0.333, 0.333, 1]\n",
        "    NumDataSymb = 1\n",
        "    N_type = 'gauss'\n",
        "\n",
        "    d_H = 1\n",
        "    d_ULA_nor  = 0.5\n",
        "    d_UCA_nor  = 0.5\n",
        "    Nr_UCA = 16\n",
        "    Nr_ULA = 4\n",
        "\n",
        "    if array_type == 'ULA':\n",
        "        elements_nor = np.zeros((3, 1, Nr), dtype=float)\n",
        "        for Nr_index in range (Nr):\n",
        "            elements_nor[0, 0, Nr_index] = (Nr_index-1) * d_UCA_nor\n",
        "            elements_nor[1, 0, Nr_index] = 0\n",
        "            elements_nor[2, 0, Nr_index] = 0\n",
        "    else:\n",
        "        elements_nor = np.zeros((3, Nr_ULA, Nr_UCA), dtype=float)\n",
        "\n",
        "        R_nor = 0.5 * d_UCA_nor / np.sin(np.pi/Nr_UCA)\n",
        "\n",
        "        for Nr_ULA_index in range (Nr_ULA):\n",
        "            for Nr_UCA_index in range (Nr_UCA):\n",
        "                elements_nor[0, Nr_ULA_index, Nr_UCA_index] = R_nor * np.sin((Nr_UCA_index-1)*(2*np.pi/Nr_UCA)) ;\n",
        "                elements_nor[1, Nr_ULA_index, Nr_UCA_index] = R_nor * np.cos((Nr_UCA_index-1)*(2*np.pi/Nr_UCA)) ;\n",
        "                elements_nor[2, Nr_ULA_index, Nr_UCA_index] = (Nr_ULA_index-1) * d_ULA_nor;\n",
        "\n",
        "    if mode == 'train':\n",
        "        for snr in SNR:\n",
        "            for runIdx in range(0, N_samp):      # ! 20000 x Nt: samples\n",
        "                H, H_oG, Gamma, Steering = Generate_channel(Nt, Nr, d_H, array_type, elements_nor, N_type, Nr_ULA, Nr_UCA)\n",
        "\n",
        "                HH = np.concatenate((np.concatenate((H_oG.real, H_oG.imag), axis=1),\n",
        "                                    np.concatenate((-H_oG.imag, H_oG.real), axis=1)), axis=0)\n",
        "\n",
        "                x = np.zeros((2*Nt, NumSubcarriers))\n",
        "                a = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                DataRaw = np.zeros((Nt, a))\n",
        "                for t in range(Nt):\n",
        "                    #\"data symbol generate\"\n",
        "                    NumBits = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                    bit = np.random.randint(1, 3, NumBits)-1\n",
        "                    DataRaw[t, :] = bit\n",
        "                    for j in range(4):\n",
        "                        DataSet_b.append(bit[j])\n",
        "                    I = np.zeros((1, a))\n",
        "                    I[0, :] = DataRaw[t, :]\n",
        "                    (dataI, dataQ) = slicer(I[0])\n",
        "\n",
        "                    # Mapper\n",
        "                    mapI = mapper_16QAM(QAM16, dataI)\n",
        "                    mapQ = mapper_16QAM(QAM16, dataQ)\n",
        "                    x[t] = mapI[0]\n",
        "                    x[t+Nt] = mapQ[0]\n",
        "\n",
        "                # transpose\n",
        "                x = x.transpose()\n",
        "\n",
        "                y_wo_noise = np.matmul(x, HH)\n",
        "\n",
        "                # noise\n",
        "                noise = AWGN(y_wo_noise.transpose(), snr)\n",
        "\n",
        "                y = y_wo_noise + noise.transpose()\n",
        "\n",
        "                DataSet_x.append(x)    # ! I, Q sample distance by Nt.\n",
        "                DataSet_y.append(y)                 # ! output sample\n",
        "\n",
        "                # Imperfect channel: 5%\n",
        "                # coef = (2*np.random.randint(0,2,size=HH.shape) - 1)\n",
        "                # HH = HH + coef * HH * 0.05\n",
        "                DataSet_Steering.append(np.squeeze(Steering))\n",
        "                DataSet_HH.append(HH)\n",
        "                DataSet_H.append(H)               # ! Generated channel\n",
        "\n",
        "    else:\n",
        "        for runIdx in range(0, N_samp):      # ! 20000 x Nt: samples\n",
        "            H, H_oG, Gamma, Steering = Generate_channel(Nt, Nr, d_H, array_type, elements_nor, N_type, Nr_ULA, Nr_UCA)\n",
        "\n",
        "            HH = np.concatenate((np.concatenate((H_oG.real, H_oG.imag), axis=1),\n",
        "                                np.concatenate((-H_oG.imag, H_oG.real), axis=1)), axis=0)\n",
        "\n",
        "            x = np.zeros((2*Nt, NumSubcarriers))\n",
        "            a = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "            DataRaw = np.zeros((Nt, a))\n",
        "            for t in range(Nt):\n",
        "                #\"data symbol generate\"\n",
        "                NumBits = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                bit = np.random.randint(1, 3, NumBits)-1\n",
        "                DataRaw[t, :] = bit\n",
        "                for j in range(4):\n",
        "                    DataSet_b.append(bit[j])\n",
        "                I = np.zeros((1, a))\n",
        "                I[0, :] = DataRaw[t, :]\n",
        "                (dataI, dataQ) = slicer(I[0])\n",
        "\n",
        "                # Mapper\n",
        "                mapI = mapper_16QAM(QAM16, dataI)\n",
        "                mapQ = mapper_16QAM(QAM16, dataQ)\n",
        "                x[t] = mapI[0]\n",
        "                x[t+Nt] = mapQ[0]\n",
        "\n",
        "            # transpose\n",
        "            x = x.transpose()\n",
        "\n",
        "            y_wo_noise = np.matmul(x, HH)\n",
        "\n",
        "            # noise\n",
        "            noise = AWGN(y_wo_noise.transpose(), snr)\n",
        "\n",
        "            y = y_wo_noise + noise.transpose()\n",
        "\n",
        "            DataSet_x.append(x)    # ! I, Q sample distance by Nt.\n",
        "            DataSet_y.append(y)                 # ! output sample\n",
        "\n",
        "            # Imperfect channel: 5%\n",
        "            DataSet_Steering.append(np.squeeze(Steering))\n",
        "            DataSet_HH.append(HH)\n",
        "            DataSet_H.append(H)               # ! Generated channel\n",
        "\n",
        "\n",
        "    # Shuffle dataset\n",
        "    random.seed(1)\n",
        "    temp = list(zip(DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering))\n",
        "    random.shuffle(temp)\n",
        "    DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering = zip(*temp)\n",
        "\n",
        "    return DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kBOG8qvPqEnM"
      },
      "outputs": [],
      "source": [
        "def reconstruct_channel (H):\n",
        "# H_raw = [R(H) I(H); -I(H) R(H)]\n",
        "# we have four version of H_est\n",
        "    H_est_1 = []\n",
        "    H_est_2 = []\n",
        "    H_est_3 = []\n",
        "    H_est_4 = []\n",
        "\n",
        "    H_est_Re_1 = H[0:Nt, 0:Nr]\n",
        "    H_est_Im_1 = H[0:Nt, Nr:2*Nr]\n",
        "    H_est_Im_2 = - H[Nt:2*Nt, 0:Nr]\n",
        "    H_est_Re_2 = H[Nt:2*Nt, Nr:2*Nr]\n",
        "\n",
        "    H_est_1 = H_est_Re_1 + 1j * H_est_Im_1\n",
        "    H_est_2 = H_est_Re_1 + 1j * H_est_Im_2\n",
        "    H_est_3 = H_est_Re_2 + 1j * H_est_Im_1\n",
        "    H_est_4 = H_est_Re_2 + 1j * H_est_Im_2\n",
        "\n",
        "    return H_est_1, H_est_2, H_est_3, H_est_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0k-_If6tqEnN"
      },
      "outputs": [],
      "source": [
        "# def NMSE(H_est, H_raw):\n",
        "#     H_est_1, H_est_2, H_est_3, H_est_4 = reconstruct_channel(H_est)\n",
        "#     H_est_vec_1 = torch.reshape(H_est_1, [Nt * Nr, 1])\n",
        "#     H_est_vec_2 = torch.reshape(H_est_2, [Nt * Nr, 1])\n",
        "#     H_est_vec_3 = torch.reshape(H_est_3, [Nt * Nr, 1])\n",
        "#     H_est_vec_4 = torch.reshape(H_est_4, [Nt * Nr, 1])\n",
        "\n",
        "#     H_raw_vec = torch.reshape(H_raw, [Nt * Nr, 1])\n",
        "\n",
        "#     mse_1       = (torch.norm(H_raw_vec - H_est_vec_1)**2) / len(H_raw_vec)\n",
        "#     mse_2       = (torch.norm(H_raw_vec - H_est_vec_2)**2) / len(H_raw_vec)\n",
        "#     mse_3       = (torch.norm(H_raw_vec - H_est_vec_3)**2) / len(H_raw_vec)\n",
        "#     mse_4       = (torch.norm(H_raw_vec - H_est_vec_4)**2) / len(H_raw_vec)\n",
        "\n",
        "#     sigEner   = torch.norm(H_raw_vec)**2\n",
        "\n",
        "#     nmse_1      = mse_1 / sigEner\n",
        "#     nmse_2      = mse_2 / sigEner\n",
        "#     nmse_3      = mse_3 / sigEner\n",
        "#     nmse_4      = mse_4 / sigEner\n",
        "\n",
        "#     # Best nmse\n",
        "#     nmse        = min([nmse_1, nmse_2, nmse_3, nmse_4])\n",
        "\n",
        "#     return torch.abs(nmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DyrfkYT2qEnN"
      },
      "outputs": [],
      "source": [
        "def NMSE(H_est, H_raw):\n",
        "    H_est_1, H_est_2, H_est_3, H_est_4 = reconstruct_channel(H_est)\n",
        "\n",
        "    # Lấy phần thực của các tensor nếu chúng là complex\n",
        "    H_est_vec_1 = torch.reshape(H_est_1, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_2 = torch.reshape(H_est_2, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_3 = torch.reshape(H_est_3, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_4 = torch.reshape(H_est_4, [Nt * Nr, 1]).abs()\n",
        "\n",
        "    H_raw_vec = torch.reshape(H_raw, [Nt * Nr, 1]).abs()\n",
        "\n",
        "    mse_1 = (torch.norm(H_raw_vec - H_est_vec_1)**2) / len(H_raw_vec)\n",
        "    mse_2 = (torch.norm(H_raw_vec - H_est_vec_2)**2) / len(H_raw_vec)\n",
        "    mse_3 = (torch.norm(H_raw_vec - H_est_vec_3)**2) / len(H_raw_vec)\n",
        "    mse_4 = (torch.norm(H_raw_vec - H_est_vec_4)**2) / len(H_raw_vec)\n",
        "\n",
        "    sigEner = torch.norm(H_raw_vec)**2\n",
        "\n",
        "    nmse_1 = mse_1 / sigEner\n",
        "    nmse_2 = mse_2 / sigEner\n",
        "    nmse_3 = mse_3 / sigEner\n",
        "    nmse_4 = mse_4 / sigEner\n",
        "\n",
        "    # Chọn NMSE tốt nhất\n",
        "    nmse = min([nmse_1, nmse_2, nmse_3, nmse_4])\n",
        "\n",
        "    return torch.abs(nmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pyjIgxUurU0P"
      },
      "outputs": [],
      "source": [
        "def Input_ISDNN(mode, DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, N_samp):\n",
        "    H_in = []        # ! H_in    , np.diag(np.diag()) return a diag matrix instead of diag components.\n",
        "    H_true = []   # ! generated s\n",
        "    H_raw = []\n",
        "    # y = []\n",
        "    e = []        # ! vector errors\n",
        "    xTx = []\n",
        "    xTy = []\n",
        "    Di = []\n",
        "    steering = [] # ! Steering vector: ZoA and AoA\n",
        "\n",
        "    if mode == 'train':\n",
        "        n_sample = N_samp * len(SNR)\n",
        "    else:\n",
        "        n_sample = N_samp\n",
        "\n",
        "    for i in range (n_sample):\n",
        "        H_true.append(torch.tensor(DataSet_HH[i]))\n",
        "        H_raw.append(torch.tensor(DataSet_H[i]))\n",
        "        # y.append(torch.tensor(DataSet_y[i]))\n",
        "        Di.append(torch.tensor(np.linalg.pinv(np.diag(np.diag(np.dot(DataSet_x[i].transpose(), DataSet_x[i]))))))\n",
        "        xTy.append(torch.tensor(np.dot(DataSet_x[i].transpose(), DataSet_y[i])))\n",
        "        H_in.append(torch.matmul(Di[i], xTy[i]))\n",
        "        e.append(torch.rand([2*Nt, 2*Nr]))\n",
        "        xTx.append(torch.tensor(np.dot(DataSet_x[i].transpose(), DataSet_x[i])))\n",
        "        steering.append(torch.tensor(DataSet_Steering[i]))\n",
        "\n",
        "    H_true = torch.stack(H_true, dim=0)\n",
        "    H_raw = torch.stack(H_raw, dim=0)\n",
        "    H_in = torch.stack(H_in, dim=0)\n",
        "    # y = torch.stack(y, dim=0)\n",
        "    e = torch.stack(e, dim=0)\n",
        "    xTx = torch.stack(xTx, dim=0)\n",
        "    xTy = torch.stack(xTy, dim=0)\n",
        "    Di = torch.stack(Di, dim=0)\n",
        "    steering = torch.stack(steering, dim=0)\n",
        "\n",
        "    return H_true, H_raw, H_in, e, xTx, xTy, Di, steering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGhdBsghq3M9"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GHceh5kuq3ZD"
      },
      "outputs": [],
      "source": [
        "class xv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(xv, self).__init__()\n",
        "\n",
        "        self.alpha1 = torch.nn.parameter.Parameter(torch.rand(1))\n",
        "        self.alpha2 = torch.nn.parameter.Parameter(torch.tensor([0.5]))\n",
        "\n",
        "    def forward(self, Di, H, e, xTx, xTy):\n",
        "\n",
        "        xTxH = torch.bmm(xTx, H)\n",
        "\n",
        "        z    = H + torch.bmm(Di, torch.sub(xTy, xTxH)) + self.alpha1 * e\n",
        "\n",
        "        e    = torch.sub(xTy, xTxH)\n",
        "\n",
        "        H    = torch.add((1 - self.alpha2) * z, self.alpha2 * H)\n",
        "\n",
        "        return H, e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "woRjD7lJssRq"
      },
      "outputs": [],
      "source": [
        "class model_driven(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(model_driven, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc2 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc3 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc4 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc5 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc6 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc7 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc8 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc9 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc10 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc11 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc12 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "\n",
        "\n",
        "\n",
        "        self.layer1=xv()\n",
        "        self.layer2=xv()\n",
        "        self.layer3=xv()\n",
        "        self.layer4=xv()\n",
        "        self.layer5=xv()\n",
        "        self.layer6=xv()\n",
        "\n",
        "\n",
        "    def forward(self, Di, H_in, e, xTx, xTy):\n",
        "        e = self.fc1(e)\n",
        "        e = self.fc2(e)\n",
        "        H, e = self.layer1(Di, H_in, e, xTx, xTy)\n",
        "        H = torch.tanh(H)\n",
        "\n",
        "        e = self.fc3(e)\n",
        "        e = self.fc4(e)\n",
        "        H, e = self.layer2(Di, H, e, xTx, xTy)\n",
        "        H = torch.tanh(H)\n",
        "\n",
        "        e = self.fc5(e)\n",
        "        e = self.fc6(e)\n",
        "        H, e = self.layer3(Di, H, e, xTx, xTy)\n",
        "        H = torch.tanh(H)\n",
        "\n",
        "        e = self.fc7(e)\n",
        "        e = self.fc8(e)\n",
        "        H, e = self.layer4(Di, H, e, xTx, xTy)\n",
        "        H = torch.tanh(H)\n",
        "\n",
        "        e = self.fc9(e)\n",
        "        e = self.fc10(e)\n",
        "        H, e = self.layer5(Di, H, e, xTx, xTy)\n",
        "        H = torch.tanh(H)\n",
        "\n",
        "        e = self.fc11(e)\n",
        "        e = self.fc12(e)\n",
        "        H, e = self.layer6(Di, H, e, xTx, xTy)\n",
        "\n",
        "        return H, e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZjihTOXq3kG"
      },
      "source": [
        "# Define model, optimizer, and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Vp9fRd3gq3tw"
      },
      "outputs": [],
      "source": [
        "def def_model():\n",
        "    model = model_driven()\n",
        "    loss = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    folder_model = './model/'\n",
        "\n",
        "    if not os.path.isdir(folder_model):\n",
        "        os.makedirs(folder_model)\n",
        "\n",
        "    file_model = folder_model + 'H'\n",
        "    # if os.path.isfile(file_model):\n",
        "    #     generator = torch.load(file_model)\n",
        "\n",
        "    record_file = 'H'\n",
        "    return model, loss, optimizer, record_file, file_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYWM7SzItKzS"
      },
      "source": [
        "# Main program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jv7lDwyxtFe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aba4605-52bf-4780-c037-ea9ab2c3c2a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3e5f3c45b18a>:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  dP[i] = abs(IFsig[i])**2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dữ liệu đã được sinh và lưu lại!\n",
            "Begin training...\n",
            "143.88541794228843\n",
            "144.51302759830784\n",
            "146.13067242696948\n",
            "145.9594362543022\n",
            "149.64638166406542\n",
            "144.39925990266931\n",
            "146.18194396622678\n",
            "144.39610613062658\n",
            "145.79738787975037\n",
            "145.17333064794204\n",
            "145.5046847291972\n",
            "144.5973278707483\n",
            "144.8456847957446\n",
            "145.8687658998648\n",
            "142.52963368727987\n",
            "147.08562174609705\n",
            "144.70685108525535\n",
            "142.8642744077692\n",
            "144.76024084290503\n",
            "144.8445750588138\n",
            "147.15727739333386\n",
            "145.70610299339353\n",
            "148.91175136330065\n",
            "145.8624339014283\n",
            "147.03154797651072\n",
            "147.19415584410186\n",
            "148.45852849581135\n",
            "140.43069977861407\n",
            "144.84769708054947\n",
            "145.40039058908476\n",
            "142.37781782134684\n",
            "144.86676282541538\n",
            "143.0130505536447\n",
            "149.12560867107794\n",
            "146.43174634433535\n",
            "144.39751003892374\n",
            "144.9713242512894\n",
            "144.04740957717064\n",
            "142.01108695802634\n",
            "148.78897488009034\n",
            "147.6449789155267\n",
            "150.01746195915663\n",
            "144.74670587140767\n",
            "144.98962524803\n",
            "149.38378274740654\n",
            "141.4436696266514\n",
            "145.90863548166374\n",
            "146.9612897483107\n",
            "148.88482336255544\n",
            "143.85461475777186\n",
            "144.63176316126453\n",
            "146.70652431832892\n",
            "150.3694573772725\n",
            "148.59318326555209\n",
            "148.40041479686352\n",
            "145.44484029427298\n",
            "144.15474376786167\n",
            "147.01564984504165\n",
            "148.9125171938918\n",
            "148.1060455471047\n",
            "143.66735875940276\n",
            "146.2859690990302\n",
            "143.60108095275572\n",
            "145.9756913673779\n",
            "149.56527664138167\n",
            "146.9816959261414\n",
            "148.41117549351623\n",
            "143.79539184610275\n",
            "147.4078992222586\n",
            "146.2668406480683\n",
            "145.42487550842174\n",
            "149.1405214184842\n",
            "145.56762207934503\n",
            "141.82633520073762\n",
            "146.20375925964532\n",
            "146.11273028145172\n",
            "146.40603407874173\n",
            "143.35093579489492\n",
            "147.322027466455\n",
            "148.6538507107857\n",
            "139.98513750892275\n",
            "148.2666955604359\n",
            "147.54408819016425\n",
            "151.8166019498236\n",
            "142.33329499492828\n",
            "146.2972733140831\n",
            "148.47397475953784\n",
            "147.02536053908264\n",
            "147.78231263999433\n",
            "144.38798727450444\n",
            "147.5664850065766\n",
            "149.45009710779348\n",
            "142.08047223294184\n",
            "143.25590684747732\n",
            "148.87395837249346\n",
            "145.96886897130733\n",
            "142.7686991252969\n",
            "147.8554569774706\n",
            "148.34881691891076\n",
            "146.20578231019732\n",
            "150.04567476893465\n",
            "145.09178334147413\n",
            "146.02989883597937\n",
            "146.69976117101373\n",
            "146.7744488280546\n",
            "146.3981751400933\n",
            "143.85698175960044\n",
            "147.00496903170296\n",
            "148.69551905404347\n",
            "148.39501285740454\n",
            "149.61417466425365\n",
            "147.56430549602965\n",
            "145.26408181499121\n",
            "146.1102774985721\n",
            "141.71107281363808\n",
            "147.8442159514975\n",
            "145.8813592540011\n",
            "144.2817034461231\n",
            "150.42113719176484\n",
            "146.57929323045207\n",
            "148.51538878265058\n",
            "149.0653003268042\n",
            "145.8225867135713\n",
            "148.0946219259131\n",
            "147.73523904326015\n",
            "145.00805611161758\n",
            "142.75748743351969\n",
            "143.14617208973482\n",
            "147.20050205402245\n",
            "144.72356108891785\n",
            "149.04231382767182\n",
            "148.38553382314578\n",
            "148.9651589813597\n",
            "147.9498090638207\n",
            "145.03286351261318\n",
            "145.5487115678559\n",
            "144.64018190093367\n",
            "143.4131292973034\n",
            "150.59562578458386\n",
            "144.5743274193452\n",
            "148.0045167998983\n",
            "143.4213245497163\n",
            "144.304706845759\n",
            "146.35701430098618\n",
            "142.7701723731279\n",
            "146.2570174372165\n",
            "149.11942603041985\n",
            "144.16523928397575\n",
            "147.66822852594\n",
            "146.9304181409277\n",
            "148.5721590379418\n",
            "148.91796705547026\n",
            "146.91833132077647\n",
            "148.6884968630501\n",
            "146.49957526663826\n",
            "143.47954350214184\n",
            "145.3250809368665\n",
            "143.6556851559014\n",
            "144.77281664200228\n",
            "147.4888050862945\n",
            "144.33795279779252\n",
            "148.01531572994145\n",
            "144.99108322195173\n",
            "143.06555206140757\n",
            "146.3778456984935\n",
            "148.74183537867472\n",
            "149.31146122607828\n",
            "147.18054001173726\n",
            "146.3227061789328\n",
            "147.01309826880296\n",
            "147.22473684289915\n",
            "146.41503338146563\n",
            "143.87488742803544\n",
            "148.7204950239283\n",
            "146.63593454614337\n",
            "147.83499967258615\n",
            "147.38822301731585\n",
            "146.20314533437215\n",
            "141.70592810006298\n",
            "144.78200991460807\n",
            "144.32781499714767\n",
            "151.13796261099242\n",
            "142.21254491481844\n",
            "148.315263397367\n",
            "148.37678751062268\n",
            "147.15234983312746\n",
            "145.59109845991094\n",
            "142.06302108853552\n",
            "146.1275844580376\n",
            "143.9078535052319\n",
            "138.7369117372006\n",
            "145.76438743010885\n",
            "146.747728904717\n",
            "145.17433008735844\n",
            "140.0592817088377\n",
            "146.9387306093365\n",
            "148.6706158380239\n",
            "147.6668356285943\n",
            "150.88607194184175\n",
            "144.23111477287168\n",
            "148.25597432241966\n",
            "144.3156241536567\n",
            "147.51725481086143\n",
            "148.525749658477\n",
            "141.60420240772098\n",
            "142.31655967245015\n",
            "148.93797763097757\n",
            "144.8048463460573\n",
            "142.35562514326682\n",
            "147.3465325363878\n",
            "148.46372231141606\n",
            "146.2846077190107\n",
            "146.13650008730673\n",
            "147.6270151715224\n",
            "144.72772357770359\n",
            "145.70575939365997\n",
            "142.28426615215716\n",
            "145.57408871044302\n",
            "142.78113069226703\n",
            "141.41433670894818\n",
            "144.33024442185757\n",
            "143.12597947188493\n",
            "147.31725544530173\n",
            "147.98839288322569\n",
            "143.22914360943076\n",
            "147.28428555409766\n",
            "146.63652193127012\n",
            "144.41788275628576\n",
            "144.68279076628437\n",
            "150.1439318056578\n",
            "149.13625994528402\n",
            "141.58712074100825\n",
            "142.06030849740716\n",
            "148.58307311167525\n",
            "145.5944488141833\n",
            "147.0813781268042\n",
            "146.1955110258231\n",
            "145.58366805519307\n",
            "149.3245801368611\n",
            "146.55501753293112\n",
            "147.0250258829695\n",
            "143.96547398672183\n",
            "149.20561025565183\n",
            "145.85066518304055\n",
            "143.8507154332519\n",
            "146.10170106124284\n",
            "147.05177118794168\n",
            "147.5171299756524\n",
            "143.75406456734413\n",
            "145.83073297515645\n",
            "147.722041965123\n",
            "148.58727916345873\n",
            "147.0964510261919\n",
            "149.02637281521095\n",
            "148.18156189643358\n",
            "145.53844604026207\n",
            "148.28534986104134\n",
            "146.92147575009014\n",
            "146.1873760598393\n",
            "146.5735615155506\n",
            "146.28266959689867\n",
            "141.45470140105158\n",
            "146.09390318681858\n",
            "144.22552998823778\n",
            "148.7835200966594\n",
            "143.87623307592392\n",
            "143.45992553152198\n",
            "146.79653455831155\n",
            "144.58042256631262\n",
            "143.27389918795004\n",
            "146.44254282117248\n",
            "147.08428169736962\n",
            "148.77406787086207\n",
            "145.90370563363138\n",
            "145.3639798602178\n",
            "143.1793549805206\n",
            "146.69049218507908\n",
            "145.10822054395766\n",
            "150.6325577408653\n",
            "146.2823443791193\n",
            "146.75183477597662\n",
            "146.99905158666027\n",
            "148.2511451001517\n",
            "145.93733060804755\n",
            "142.85947348152487\n",
            "145.72697263744175\n",
            "147.16654498039665\n",
            "148.75636364347076\n",
            "145.39768321341305\n",
            "149.08853248053754\n",
            "145.0948563021157\n",
            "147.94050896846747\n",
            "153.5862302945933\n",
            "146.9763110527065\n",
            "145.8014514288589\n",
            "147.8683983523484\n",
            "147.3383526591894\n",
            "144.03636568382578\n",
            "146.77878896314286\n",
            "145.16103213894831\n",
            "144.0346969456276\n",
            "141.50684460194915\n",
            "148.41403785553734\n",
            "144.59623760734664\n",
            "143.85437751406144\n",
            "147.63362602947151\n",
            "144.40000413078417\n",
            "143.05315234349385\n",
            "145.22660314383143\n",
            "140.93350632249403\n",
            "146.21075780849392\n",
            "149.4128929798235\n",
            "146.06031918241132\n",
            "145.8046095575361\n",
            "148.25814744333243\n",
            "147.66419975802813\n",
            "146.74320625640087\n",
            "149.97117464478825\n",
            "147.05212772156236\n",
            "145.92390986164855\n",
            "146.23406094730186\n",
            "147.38028917160727\n",
            "138.61288305912765\n",
            "146.98669980269366\n",
            "146.85328959886763\n",
            "147.9068966126504\n",
            "145.21258535292387\n",
            "142.39516722823504\n",
            "145.57132587127106\n",
            "145.46879370525377\n",
            "148.28779990072394\n",
            "146.55800804373177\n",
            "149.23520962545547\n",
            "147.30120697778727\n",
            "143.87531000589232\n",
            "144.75875934133046\n",
            "144.19970435783634\n",
            "148.90693515836804\n",
            "144.108124226807\n",
            "146.68976972976327\n",
            "147.06377785262745\n",
            "142.15247583844723\n",
            "143.16363638753108\n",
            "144.176247231255\n",
            "147.42224674064497\n",
            "148.8037535796674\n",
            "146.17598239211765\n",
            "145.6210296036589\n",
            "148.8402497202696\n",
            "144.34072631490773\n",
            "145.15812828246808\n",
            "148.3365188455931\n",
            "143.56522719205626\n",
            "145.3243173560858\n",
            "147.9752959115106\n",
            "144.58075479629522\n",
            "143.8091497163398\n",
            "146.6277569425251\n",
            "140.55825854805136\n",
            "147.30581614879767\n",
            "144.77762456282565\n",
            "145.1794441007678\n",
            "145.9485241698891\n",
            "144.51729441557922\n",
            "145.00014153611494\n",
            "145.10955491014377\n",
            "150.51161638684607\n",
            "147.52324895108563\n",
            "150.45354316624113\n",
            "144.16982221635433\n",
            "147.25627816055444\n",
            "146.77576946826426\n",
            "142.7641318133131\n",
            "146.56744591447264\n",
            "146.51096284136426\n",
            "143.40146741225007\n",
            "145.0399867545794\n",
            "147.76373169115078\n",
            "145.97469046859734\n",
            "147.26616110338873\n",
            "146.81377018794362\n",
            "149.3432287621273\n",
            "143.98267136678297\n",
            "147.93285559186347\n",
            "148.11369993533455\n",
            "145.2322648741807\n",
            "143.47903583592773\n",
            "148.6541777759228\n",
            "146.17407216680877\n",
            "144.52086407462508\n",
            "145.69761919090607\n",
            "140.50983691975398\n",
            "147.23926074200853\n",
            "150.0801702967425\n",
            "143.059671210633\n",
            "143.46418383089093\n",
            "144.7550332107913\n",
            "144.08387982542627\n",
            "144.1792994239295\n",
            "144.70413737261697\n",
            "146.80815764706415\n",
            "148.6635280227264\n",
            "146.5593997922603\n",
            "145.1287249194542\n",
            "143.69237328376386\n",
            "147.57783381253105\n",
            "147.24785324245946\n",
            "145.72853149530007\n",
            "145.34539397366595\n",
            "145.50560571558617\n",
            "145.13718738273332\n",
            "146.4763645621777\n",
            "143.38412737035677\n",
            "150.07175024817911\n",
            "146.81162707698016\n",
            "143.79135991933083\n",
            "149.99588759174924\n",
            "147.96091213314116\n",
            "149.33551315672597\n",
            "146.6074859296013\n",
            "146.51756924299002\n",
            "145.9300451889289\n",
            "146.60046576769534\n",
            "149.93381486827408\n",
            "147.01246405862656\n",
            "147.32155513809863\n",
            "144.60514112828088\n",
            "144.77398666620832\n",
            "147.4503280198426\n",
            "145.24268868110687\n",
            "148.85149776850844\n",
            "143.61850431194878\n",
            "147.162142661997\n",
            "146.27382156280774\n",
            "147.67934417132304\n",
            "144.3899528428446\n",
            "144.87129097446353\n",
            "148.5119567959246\n",
            "145.79113677837165\n",
            "147.83877993853844\n",
            "146.1861539067836\n",
            "144.13766254482954\n",
            "148.675185696778\n",
            "143.86590874548043\n",
            "143.07978758085147\n",
            "145.48614774681337\n",
            "150.64473191026877\n",
            "145.51903580137602\n",
            "146.39673070679038\n",
            "145.02979536743834\n",
            "148.38814870277284\n",
            "146.32727009434566\n",
            "143.93470566687657\n",
            "146.4959836371034\n",
            "149.83484800063178\n",
            "144.32166991863926\n",
            "143.8657934283637\n",
            "148.70148923362592\n",
            "148.90189919177917\n",
            "146.09127301188855\n",
            "144.26334694709413\n",
            "150.49233165311557\n",
            "146.48506792971256\n",
            "146.18793227743686\n",
            "140.5939213196107\n",
            "145.93701382633756\n",
            "141.74123668882189\n",
            "137.45025365484565\n",
            "145.45673933921344\n",
            "147.95669012336765\n",
            "145.0727770385137\n",
            "148.57358350450914\n",
            "146.55464591591027\n",
            "143.3398164547078\n",
            "145.2135644795758\n",
            "145.39466925607815\n",
            "145.9108816057542\n",
            "146.991726268507\n",
            "141.21557669469107\n",
            "150.91572584841109\n",
            "147.86445042790655\n",
            "145.8126077805918\n",
            "147.05794877622785\n",
            "142.462364038012\n",
            "147.26838434436695\n",
            "144.57417936187457\n",
            "146.6476598901008\n",
            "146.66411949832445\n",
            "146.84930636755703\n",
            "144.8607236551808\n",
            "146.2837044957405\n",
            "144.79914149586645\n",
            "147.29928851852193\n",
            "145.68523460860388\n",
            "151.91289307959747\n",
            "146.3963423138655\n",
            "144.37694624711722\n",
            "146.746472427939\n",
            "149.47374519865474\n",
            "146.10364938997597\n",
            "145.95193109014852\n",
            "146.20426974431822\n",
            "145.21834607491866\n",
            "143.6082498505677\n",
            "146.02199467285473\n",
            "146.70844523687867\n",
            "143.97959446026826\n",
            "144.40386616138107\n",
            "148.89678544487197\n",
            "144.48526112670683\n",
            "147.19644795880384\n",
            "147.8759212029543\n",
            "1 0.06752459474827564 35.425864455242106\n",
            "100 0.0009435957626500087 1.451040528588822\n",
            "200 0.0039891319229312504 4.565535465276206\n",
            "300 0.012275136456023406 2.0426847944591096\n",
            "400 0.0005869853596274008 0.7347375386118737\n",
            "500 0.0005937807392934676 0.8572790893759685\n",
            "600 0.021038465857498634 13.035407157563943\n",
            "700 0.0005771089534023934 0.734688384742321\n",
            "800 0.0016437113403418768 4.66653748476431\n",
            "900 0.000577072583930037 0.7354599554368737\n",
            "1000 0.03135147187155355 19.51530172363684\n",
            "1100 0.2861384084680896 564.3586908620039\n",
            "1200 0.003049089525568481 1.1071899659109312\n",
            "6157.7559443009995\n"
          ]
        }
      ],
      "source": [
        "epoch         = 0\n",
        "expected_epoch = 20000\n",
        "num_samp      = N_samp * len(SNR)\n",
        "best_nmse     = 1e9\n",
        "early_stop    = 0\n",
        "best_model    = ''\n",
        "batch_size    = int(num_samp / 512)\n",
        "# DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering = Gen_dataset('train', 'UCyA', 0, 0, N_samp)\n",
        "# H_true, H_raw, H_in, e, xTx, xTy, Di, steering = Input_ISDNN('train', DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, N_samp)\n",
        "\n",
        "# Kiểm tra nếu file tĩnh tồn tại\n",
        "if os.path.exists('dataset_SISDNN.pkl'):\n",
        "    with open('dataset_SISDNN.pkl', 'rb') as f:\n",
        "        DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, H_true, H_raw, H_in, e, xTx, xTy, Di, steering = pickle.load(f)\n",
        "    print(\"Dữ liệu đã được tải từ file tĩnh!\")\n",
        "else:\n",
        "    # Sinh dữ liệu nếu file tĩnh không tồn tại\n",
        "    DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering = Gen_dataset('train', 'UCyA', 0, 0, N_samp)\n",
        "    H_true, H_raw, H_in, e, xTx, xTy, Di, steering = Input_ISDNN('train', DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, N_samp)\n",
        "\n",
        "    # Lưu dữ liệu để lần sau không phải sinh lại\n",
        "    with open('dataset_SISDNN.pkl', 'wb') as f:\n",
        "        pickle.dump((DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, H_true, H_raw, H_in, e, xTx, xTy, Di, steering), f)\n",
        "    print(\"Dữ liệu đã được sinh và lưu lại!\")\n",
        "\n",
        "print(\"Begin training...\")\n",
        "starttime = timeit.default_timer()\n",
        "\n",
        "while(True):\n",
        "        epoch = epoch + 1\n",
        "\n",
        "        init_loss = 1e9\n",
        "        while( epoch == 1 and init_loss > 150):\n",
        "\n",
        "                model, loss, optimizer, record_file, file_model = def_model()\n",
        "                for bs in range (int(num_samp / batch_size)):\n",
        "                    H_1, e_1 = model(Di[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 H_in[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 e[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTx[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTy[0 + batch_size * bs:batch_size * (bs+1), :, :])   # predict output from the model\n",
        "                    init_loss = loss(H_1, H_true[0 + batch_size * bs:batch_size * (bs+1), :, :]).item()\n",
        "                    print(init_loss)\n",
        "\n",
        "        optimizer.zero_grad()   # zero the parameter gradients\n",
        "        train_loss = 0\n",
        "        H_f = torch.empty([num_samp, 2*Nt, 2*Nr])\n",
        "        for bs in range (int(num_samp / batch_size)):\n",
        "                H_o, e_o = model(Di[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 H_in[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 e[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTx[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTy[0 + batch_size * bs:batch_size * (bs+1), :, :])   # predict output from the model\n",
        "                H_f[0 + batch_size * bs:batch_size * (bs+1), :, :] = H_o\n",
        "                train_loss = loss(H_o,\n",
        "                                  H_true[0 + batch_size * bs:batch_size * (bs+1), :, :])   # calculate loss for the predicted output\n",
        "                train_loss.backward()   # backpropagate the loss\n",
        "                optimizer.step()        # adjust parameters based on the calculated gradients\n",
        "\n",
        "        if (epoch % 100 == 0 or epoch == 1):\n",
        "                nmse = 0\n",
        "                for j in range (num_samp):\n",
        "                        nmse += NMSE(H_f[j], H_raw[j])\n",
        "                nmse = nmse / num_samp\n",
        "\n",
        "                if (nmse <= best_nmse):\n",
        "                        torch.save(model.state_dict(), file_model + '_' + str(epoch) + '.pth')\n",
        "                        best_model = file_model + '_' + str(epoch) + '.pth'\n",
        "                        best_nmse = nmse\n",
        "                        early_stop = 0\n",
        "                else:\n",
        "                        early_stop += 1\n",
        "\n",
        "                if (nmse > best_nmse and early_stop == 3):\n",
        "                        with Record(record_file + '_log.txt'):\n",
        "                                print(epoch, nmse.item(), train_loss.item())\n",
        "                                print(str(timeit.default_timer()-starttime))\n",
        "                        break\n",
        "\n",
        "                with Record(record_file + '_log.txt'):\n",
        "                        print(epoch, nmse.item(), train_loss.item())\n",
        "\n",
        "        if epoch  == expected_epoch:\n",
        "                torch.save(model.state_dict(), file_model + '_' + str(epoch) + '.pth')\n",
        "                best_model = file_model + '_' + str(epoch) + '.pth'\n",
        "                with Record(record_file + '_log.txt'):\n",
        "                        print(\"epoch:\\n\", epoch)\n",
        "                        print(\"Latest NMSE:\\n\", nmse.item())\n",
        "                        print(\"Latest Loss:\\n\", train_loss.item())\n",
        "                        print(str(timeit.default_timer()-starttime))\n",
        "\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOBK-_l-tRMO"
      },
      "source": [
        "# Test function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRRFGAX4tg_6"
      },
      "source": [
        "# Function to test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SfvpexfwthNq"
      },
      "outputs": [],
      "source": [
        "# from scipy.io import savemat\n",
        "\n",
        "def test(H_raw, Di, H_in, e, xTx, xTy, N_test, log):\n",
        "    # Load the model that we saved at the end of the training loop\n",
        "    model = model_driven()\n",
        "    model.load_state_dict(torch.load(best_model, map_location=torch.device('cpu')))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        H_o, e_o = model(Di, H_in, e, xTx, xTy)\n",
        "\n",
        "        nmse = 0\n",
        "        for j in range (N_test):\n",
        "            nmse += NMSE(H_o[j], H_raw[j])\n",
        "\n",
        "        nmse = nmse / N_test\n",
        "        with Record(log):\n",
        "            print(format(nmse.item(), '.7f'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "x2Sx4hiqqEnP"
      },
      "outputs": [],
      "source": [
        "## Generate dataset for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "v1Vvpw6-qEnP"
      },
      "outputs": [],
      "source": [
        "def LS(DataSet_x, DataSet_y):\n",
        "    start = timeit.default_timer()\n",
        "    for i in range (len(DataSet_x)):\n",
        "        H_hat = np.matmul(\n",
        "                    np.matmul(\n",
        "                        np.linalg.pinv(np.matmul(DataSet_x[i].transpose(), DataSet_x[i])),\n",
        "                        DataSet_x[i].transpose()),\n",
        "                        DataSet_y[i])\n",
        "    print(timeit.default_timer() - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "xPXHJP8QqEnP",
        "outputId": "c7f3df5e-6b1d-49f0-b0a8-0716bf243ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3e5f3c45b18a>:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  dP[i] = abs(IFsig[i])**2\n",
            "<ipython-input-17-466beddd61d6>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model, map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0005747\n",
            "0.0005759\n",
            "0.0005740\n",
            "0.0005742\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7a5f24f9c0be>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# with Record(log):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#     print(snr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mDataSet_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_Steering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'UCyA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mH_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxTx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxTy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput_ISDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_Steering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-f768c953aa79>\u001b[0m in \u001b[0;36mGen_dataset\u001b[0;34m(mode, array_type, snr, imperfect, N_samp)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrunIdx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_samp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m      \u001b[0;31m# ! 20000 x Nt: samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_oG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSteering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerate_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melements_nor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNr_ULA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNr_UCA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             HH = np.concatenate((np.concatenate((H_oG.real, H_oG.imag), axis=1),\n",
            "\u001b[0;32m<ipython-input-7-f27b99e23c62>\u001b[0m in \u001b[0;36mGenerate_channel\u001b[0;34m(Nt, Nr, d_H, array_type, elements_nor, type, Nr_ULA, Nr_UCA)\u001b[0m\n\u001b[1;32m     63\u001b[0m                             \u001b[0;31m#                                             + elements_nor[2, Nr_ULA_index, Nr_UCA_index]*r_z))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                             Steering[nt, r, dh] = np.exp(-1j*2*np.pi *(elements_nor[0, Nr_ULA_index, Nr_UCA_index]*r_x\n\u001b[0m\u001b[1;32m     66\u001b[0m                                                                         \u001b[0;34m+\u001b[0m \u001b[0melements_nor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNr_ULA_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNr_UCA_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                                                                         + elements_nor[2, Nr_ULA_index, Nr_UCA_index]*r_z))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "SNR_min_dB  = 0\n",
        "SNR_max_dB  = 20\n",
        "step_dB     = 5\n",
        "num_dB      = int((SNR_max_dB - SNR_min_dB) / step_dB) + 1\n",
        "\n",
        "SNR         = np.linspace(SNR_min_dB, SNR_max_dB, num=num_dB)\n",
        "log         = './model/log_test.txt'\n",
        "\n",
        "N_test = int(num_samp * 30 / 100)\n",
        "\n",
        "for i in range (100):\n",
        "    for snr in SNR:\n",
        "        # with Record(log):\n",
        "        #     print(snr)\n",
        "        DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering = Gen_dataset('test', 'UCyA', 0, 0, N_test)\n",
        "        H_true, H_raw, H_in, e, xTx, xTy, Di, steering = Input_ISDNN('test', DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, N_test)\n",
        "\n",
        "        # LS(DataSet_x, DataSet_y)\n",
        "        test(H_raw, Di, H_in, e, xTx, xTy, N_test, log)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google.colab import files\n",
        "\n",
        "files.download(\"dataset_SISDNN.pkl\")"
      ],
      "metadata": {
        "id": "1kH45h0QvQZX",
        "outputId": "110badef-c034-4722-b940-c6692bca5ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-21-14f4914d766c>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-14f4914d766c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    google.colab import files\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
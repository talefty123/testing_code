{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talefty123/testing_code/blob/main/Python/Structured/H_structured_ISD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSmcwLZuptDU"
      },
      "source": [
        "# Proposed Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG5fZn_ypunP"
      },
      "source": [
        "# **Biblioheque**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "--SvzvIspu-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d56d70dc-29dd-4110-82e3-bc4960335a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n",
            "  _C._set_default_tensor_type(t)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from scipy.stats import rice\n",
        "# import pandas as pd\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import sys\n",
        "import timeit\n",
        "import os\n",
        "\n",
        "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
        "torch.set_default_dtype(torch.float64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBk01Vu0pvMm"
      },
      "source": [
        "# class to save results in file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "06IymVCkpvYS"
      },
      "outputs": [],
      "source": [
        "class Record:\n",
        "    def __init__(self, TextName):\n",
        "        self.out_file = open(TextName, 'a')\n",
        "        self.old_stdout = sys.stdout\n",
        "        sys.stdout = self\n",
        "\n",
        "    def write(self, text):\n",
        "        self.old_stdout.write(text)\n",
        "        self.out_file.write(text)\n",
        "\n",
        "    def __enter__(self):\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout = self.old_stdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xPamGjNpv8E"
      },
      "source": [
        "# **slicer the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dlQdA0xHpwF7"
      },
      "outputs": [],
      "source": [
        "def slicer(data):\n",
        "    dataI = data[slice(0, len(data), 2)]\n",
        "    dataQ = data[slice(1, len(data), 2)]\n",
        "    return(dataI, dataQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOoiIo_LpwQl"
      },
      "source": [
        "# **Modulation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xIftC8fvpwir"
      },
      "outputs": [],
      "source": [
        "def mapper_16QAM(QAM16, data):\n",
        "    map0 = 2*data[slice(0, len(data), 2)] + data[slice(1, len(data), 2)]\n",
        "    map0 = list(map(int, map0))\n",
        "    dataMapped = []\n",
        "    for i in range(len(map0)):\n",
        "        dataMapped.append(QAM16[map0[i]])\n",
        "    return(dataMapped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AYhPgAIcqtGT"
      },
      "outputs": [],
      "source": [
        "def calculate_bits(Modulation,NumSubcarriers,NumDataSymb):\n",
        "    if Modulation=='QPSK':\n",
        "        Nbpscs=2\n",
        "    elif Modulation=='16QAM':\n",
        "        Nbpscs=4\n",
        "    return NumDataSymb*NumSubcarriers*Nbpscs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgX6tiqFpwvb"
      },
      "source": [
        "# **generate noise**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2LQwZvGaprKZ"
      },
      "outputs": [],
      "source": [
        "def AWGN(IFsig, SNR):\n",
        "    dP = np.zeros(len(IFsig))\n",
        "    P = 0\n",
        "\n",
        "    for i in range(len(IFsig)):\n",
        "        dP[i] = abs(IFsig[i])**2\n",
        "        P = P + dP[i]\n",
        "\n",
        "    P = P/len(IFsig)\n",
        "    gamma = 10**(SNR/10)\n",
        "    N0 = P/gamma\n",
        "    n = ((N0/2)**(0.5))*np.random.standard_normal(len(IFsig))\n",
        "    IF_n = np.zeros((len(IFsig),1))\n",
        "\n",
        "    for i in range(len(IFsig)):\n",
        "        IF_n[i,:] = IFsig[i] + n[i]\n",
        "\n",
        "    return(IF_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4FN4cjoqEnL"
      },
      "source": [
        "# Generate channel model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Kpiu9npGqEnL"
      },
      "outputs": [],
      "source": [
        "def unstructured_channel(Nt, Nr, type):\n",
        "    if (type == 'gauss'):\n",
        "        return (np.random.normal(size=(Nt, Nr))+1j*np.random.normal(size=(Nt, Nr)))/np.sqrt(2)\n",
        "\n",
        "def Generate_channel(Nt, Nr, d_H, array_type, elements_nor, type, Nr_ULA, Nr_UCA):\n",
        "    if (type == 'gauss'):\n",
        "\n",
        "        H = (np.random.normal(size=(Nt, Nr))+1j*np.random.normal(size=(Nt, Nr)))/np.sqrt(2)\n",
        "        H_oG = np.zeros((Nt, Nr), dtype=complex)\n",
        "        Gamma = []\n",
        "        Zoa = []\n",
        "        Aoa = []\n",
        "\n",
        "        Steering = np.zeros((Nt, Nr, d_H), dtype=complex)\n",
        "\n",
        "        for nt in range (Nt):\n",
        "            # gamma = (np.random.normal(size=d_H)+1j*np.random.normal(size=d_H))/np.sqrt(2)\n",
        "            zoa = np.random.uniform(-np.pi / 2, np.pi / 2, d_H)\n",
        "            aoa = np.random.uniform(-np.pi / 2, np.pi / 2, d_H)\n",
        "\n",
        "            # Gamma.append(gamma)\n",
        "            Zoa.append(zoa)\n",
        "            Aoa.append(aoa)\n",
        "\n",
        "        # Gamma = np.array(Gamma)\n",
        "        Zoa = np.array(Zoa)\n",
        "        Aoa = np.array(Aoa)\n",
        "\n",
        "        if array_type == 'ULA':\n",
        "            for nt in range (Nt):\n",
        "                for nr in range (Nr):\n",
        "                    h = 0\n",
        "                    for dh in range(d_H):\n",
        "                        r_x = np.sin(Zoa[nt,dh]) * np.cos(Aoa[nt,dh])\n",
        "                        r_y = np.sin(Zoa[nt,dh]) * np.sin(Aoa[nt,dh])\n",
        "                        r_z = np.cos(Zoa[nt,dh])\n",
        "\n",
        "                        # h = h + Gamma[nn,dh] * np.exp(-1j*2*np.pi * (elements_nor[0, 0, nr]*r_x\n",
        "                        #                                             + elements_nor[1, 0, nr]*r_y\n",
        "                        #                                             + elements_nor[2, 0, nr]*r_z))\n",
        "\n",
        "                        Steering[nt, nr, dh] = np.exp(-1j*2*np.pi * (elements_nor[0, 0, nr]*r_x\n",
        "                                                                    + elements_nor[1, 0, nr]*r_y\n",
        "                                                                    + elements_nor[2, 0, nr]*r_z))\n",
        "\n",
        "                    H_oG[nt, nr] = np.divide(H[nt, nr],  Steering[nt, nr, 0])\n",
        "\n",
        "                    # H[nr, nn] = h\n",
        "        else:\n",
        "            for nt in range (Nt):\n",
        "                r = -1\n",
        "                for Nr_ULA_index in range (Nr_ULA):\n",
        "                    for Nr_UCA_index in range (Nr_UCA):\n",
        "                        r=r+1\n",
        "                        h = 0\n",
        "                        for dh in range(d_H):\n",
        "                            r_x = np.sin(Zoa[nt, dh]) * np.cos(Aoa[nt, dh])\n",
        "                            r_y = np.sin(Zoa[nt, dh]) * np.sin(Aoa[nt, dh])\n",
        "                            r_z = np.cos(Zoa[nt, dh])\n",
        "\n",
        "                            # h = h + Gamma[nt, dh] * np.exp(-1j*2*np.pi *  (elements_nor[0, Nr_ULA_index, Nr_UCA_index]*r_x\n",
        "                            #                                             + elements_nor[1, Nr_ULA_index, Nr_UCA_index]*r_y\n",
        "                            #                                             + elements_nor[2, Nr_ULA_index, Nr_UCA_index]*r_z))\n",
        "\n",
        "                            Steering[nt, r, dh] = np.exp(-1j*2*np.pi *(elements_nor[0, Nr_ULA_index, Nr_UCA_index]*r_x\n",
        "                                                                        + elements_nor[1, Nr_ULA_index, Nr_UCA_index]*r_y\n",
        "                                                                        + elements_nor[2, Nr_ULA_index, Nr_UCA_index]*r_z))\n",
        "\n",
        "                        # tmp_1 = 0\n",
        "                        # gamma = 0\n",
        "                        # while(tmp_1 < 0.6):\n",
        "                        #     gamma = (np.random.normal(size=d_H - 1)+1j*np.random.normal(size=d_H - 1))/np.sqrt(2)\n",
        "                        #     tmp = 0\n",
        "                        #     for jj in range (d_H - 1):\n",
        "                        #         tmp += gamma[jj] * Steering[r, nt, jj]\n",
        "                        #     last_gamma = np.divide(H[r, nt] - tmp, Steering[r, nt, d_H - 1])\n",
        "                        #     gamma = np.append(gamma, last_gamma)\n",
        "\n",
        "                        #     tmp_1 = min(abs(gamma))\n",
        "\n",
        "                        H_oG[nt, r] = np.divide(H[nt, r],  Steering[nt, r, 0])\n",
        "                        # H[r, nt] = h\n",
        "\n",
        "        return H, H_oG, Gamma, Steering\n",
        "\n",
        "    if (type == 'rayleigh'):\n",
        "        return (np.random.rayleigh(scale=(1/np.sqrt(2)), size=(Nt, Nr)) + 1j*np.random.rayleigh(scale=(1/np.sqrt(2)), size=(Nt, Nr)))/np.sqrt(2)\n",
        "    if (type == 'rician'):\n",
        "        b = 1/np.sqrt(2)\n",
        "        return (rice.rvs(b, size=(Nt, Nr)) + 1j*rice.rvs(b, size=(Nt, Nr)))/np.sqrt(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eciNtnFjq2yd"
      },
      "source": [
        "# **Generate Dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AE4Q6jZCq3CY"
      },
      "outputs": [],
      "source": [
        "DataSet_x   = []  # x dataset after modulation\n",
        "DataSet_y   = []  # y dataset\n",
        "DataSet_HH  = []  # H dataset\n",
        "DataSet_b   = []  # binary dataset\n",
        "SNR_min_dB  = 0\n",
        "SNR_max_dB  = 20\n",
        "step_dB     = 5\n",
        "num_dB      = int((SNR_max_dB - SNR_min_dB) / step_dB) + 1\n",
        "\n",
        "SNR         = np.linspace(SNR_min_dB, SNR_max_dB, num=num_dB)\n",
        "\n",
        "\n",
        "Nt = 8             # Tx: 8\n",
        "Nr = 64            # Rx: 128\n",
        "N_samp = 4000\n",
        "\n",
        "\n",
        "def Gen_dataset(mode, array_type, snr, imperfect, N_samp):\n",
        "    DataSet_x   = []  # x dataset after modulation\n",
        "    DataSet_y   = []  # y dataset\n",
        "    DataSet_H   = []\n",
        "    DataSet_HH  = []\n",
        "    DataSet_Steering = []\n",
        "\n",
        "    NumSubcarriers = 1\n",
        "    Modulation = '16QAM'\n",
        "    QAM16 = [-1, -0.333, 0.333, 1]\n",
        "    NumDataSymb = 1\n",
        "    N_type = 'gauss'\n",
        "\n",
        "    d_H = 1\n",
        "    d_ULA_nor  = 0.5\n",
        "    d_UCA_nor  = 0.5\n",
        "    Nr_UCA = 16\n",
        "    Nr_ULA = 4\n",
        "\n",
        "    if array_type == 'ULA':\n",
        "        elements_nor = np.zeros((3, 1, Nr), dtype=float)\n",
        "        for Nr_index in range (Nr):\n",
        "            elements_nor[0, 0, Nr_index] = (Nr_index-1) * d_UCA_nor\n",
        "            elements_nor[1, 0, Nr_index] = 0\n",
        "            elements_nor[2, 0, Nr_index] = 0\n",
        "    else:\n",
        "        elements_nor = np.zeros((3, Nr_ULA, Nr_UCA), dtype=float)\n",
        "\n",
        "        R_nor = 0.5 * d_UCA_nor / np.sin(np.pi/Nr_UCA)\n",
        "\n",
        "        for Nr_ULA_index in range (Nr_ULA):\n",
        "            for Nr_UCA_index in range (Nr_UCA):\n",
        "                elements_nor[0, Nr_ULA_index, Nr_UCA_index] = R_nor * np.sin((Nr_UCA_index-1)*(2*np.pi/Nr_UCA)) ;\n",
        "                elements_nor[1, Nr_ULA_index, Nr_UCA_index] = R_nor * np.cos((Nr_UCA_index-1)*(2*np.pi/Nr_UCA)) ;\n",
        "                elements_nor[2, Nr_ULA_index, Nr_UCA_index] = (Nr_ULA_index-1) * d_ULA_nor;\n",
        "\n",
        "    if mode == 'train':\n",
        "        for snr in SNR:\n",
        "            for runIdx in range(0, N_samp):      # ! 20000 x Nt: samples\n",
        "                H, H_oG, Gamma, Steering = Generate_channel(Nt, Nr, d_H, array_type, elements_nor, N_type, Nr_ULA, Nr_UCA)\n",
        "\n",
        "                HH = np.concatenate((np.concatenate((H_oG.real, H_oG.imag), axis=1),\n",
        "                                    np.concatenate((-H_oG.imag, H_oG.real), axis=1)), axis=0)\n",
        "\n",
        "                x = np.zeros((2*Nt, NumSubcarriers))\n",
        "                a = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                DataRaw = np.zeros((Nt, a))\n",
        "                for t in range(Nt):\n",
        "                    #\"data symbol generate\"\n",
        "                    NumBits = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                    bit = np.random.randint(1, 3, NumBits)-1\n",
        "                    DataRaw[t, :] = bit\n",
        "                    for j in range(4):\n",
        "                        DataSet_b.append(bit[j])\n",
        "                    I = np.zeros((1, a))\n",
        "                    I[0, :] = DataRaw[t, :]\n",
        "                    (dataI, dataQ) = slicer(I[0])\n",
        "\n",
        "                    # Mapper\n",
        "                    mapI = mapper_16QAM(QAM16, dataI)\n",
        "                    mapQ = mapper_16QAM(QAM16, dataQ)\n",
        "                    x[t] = mapI[0]\n",
        "                    x[t+Nt] = mapQ[0]\n",
        "\n",
        "                # transpose\n",
        "                x = x.transpose()\n",
        "\n",
        "                y_wo_noise = np.matmul(x, HH)\n",
        "\n",
        "                # noise\n",
        "                noise = AWGN(y_wo_noise.transpose(), snr)\n",
        "\n",
        "                y = y_wo_noise + noise.transpose()\n",
        "\n",
        "                DataSet_x.append(x)    # ! I, Q sample distance by Nt.\n",
        "                DataSet_y.append(y)                 # ! output sample\n",
        "\n",
        "                # Imperfect channel: 5%\n",
        "                # coef = (2*np.random.randint(0,2,size=HH.shape) - 1)\n",
        "                # HH = HH + coef * HH * 0.05\n",
        "                DataSet_Steering.append(np.squeeze(Steering))\n",
        "                DataSet_HH.append(HH)\n",
        "                DataSet_H.append(H)               # ! Generated channel\n",
        "\n",
        "    else:\n",
        "        for runIdx in range(0, N_samp):      # ! 20000 x Nt: samples\n",
        "            H, H_oG, Gamma, Steering = Generate_channel(Nt, Nr, d_H, array_type, elements_nor, N_type, Nr_ULA, Nr_UCA)\n",
        "\n",
        "            HH = np.concatenate((np.concatenate((H_oG.real, H_oG.imag), axis=1),\n",
        "                                np.concatenate((-H_oG.imag, H_oG.real), axis=1)), axis=0)\n",
        "\n",
        "            x = np.zeros((2*Nt, NumSubcarriers))\n",
        "            a = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "            DataRaw = np.zeros((Nt, a))\n",
        "            for t in range(Nt):\n",
        "                #\"data symbol generate\"\n",
        "                NumBits = calculate_bits(Modulation, NumSubcarriers, NumDataSymb)\n",
        "                bit = np.random.randint(1, 3, NumBits)-1\n",
        "                DataRaw[t, :] = bit\n",
        "                for j in range(4):\n",
        "                    DataSet_b.append(bit[j])\n",
        "                I = np.zeros((1, a))\n",
        "                I[0, :] = DataRaw[t, :]\n",
        "                (dataI, dataQ) = slicer(I[0])\n",
        "\n",
        "                # Mapper\n",
        "                mapI = mapper_16QAM(QAM16, dataI)\n",
        "                mapQ = mapper_16QAM(QAM16, dataQ)\n",
        "                x[t] = mapI[0]\n",
        "                x[t+Nt] = mapQ[0]\n",
        "\n",
        "            # transpose\n",
        "            x = x.transpose()\n",
        "\n",
        "            y_wo_noise = np.matmul(x, HH)\n",
        "\n",
        "            # noise\n",
        "            noise = AWGN(y_wo_noise.transpose(), snr)\n",
        "\n",
        "            y = y_wo_noise + noise.transpose()\n",
        "\n",
        "            DataSet_x.append(x)    # ! I, Q sample distance by Nt.\n",
        "            DataSet_y.append(y)                 # ! output sample\n",
        "\n",
        "            # Imperfect channel: 5%\n",
        "            DataSet_Steering.append(np.squeeze(Steering))\n",
        "            DataSet_HH.append(HH)\n",
        "            DataSet_H.append(H)               # ! Generated channel\n",
        "\n",
        "\n",
        "    # Shuffle dataset\n",
        "    random.seed(1)\n",
        "    temp = list(zip(DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering))\n",
        "    random.shuffle(temp)\n",
        "    DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering = zip(*temp)\n",
        "\n",
        "    return DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kBOG8qvPqEnM"
      },
      "outputs": [],
      "source": [
        "def reconstruct_channel (H):\n",
        "# H_raw = [R(H) I(H); -I(H) R(H)]\n",
        "# we have four version of H_est\n",
        "    H_est_1 = []\n",
        "    H_est_2 = []\n",
        "    H_est_3 = []\n",
        "    H_est_4 = []\n",
        "\n",
        "    H_est_Re_1 = H[0:Nt, 0:Nr]\n",
        "    H_est_Im_1 = H[0:Nt, Nr:2*Nr]\n",
        "    H_est_Im_2 = - H[Nt:2*Nt, 0:Nr]\n",
        "    H_est_Re_2 = H[Nt:2*Nt, Nr:2*Nr]\n",
        "\n",
        "    H_est_1 = H_est_Re_1 + 1j * H_est_Im_1\n",
        "    H_est_2 = H_est_Re_1 + 1j * H_est_Im_2\n",
        "    H_est_3 = H_est_Re_2 + 1j * H_est_Im_1\n",
        "    H_est_4 = H_est_Re_2 + 1j * H_est_Im_2\n",
        "\n",
        "    return H_est_1, H_est_2, H_est_3, H_est_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0k-_If6tqEnN"
      },
      "outputs": [],
      "source": [
        "# def NMSE(H_est, H_raw):\n",
        "#     H_est_1, H_est_2, H_est_3, H_est_4 = reconstruct_channel(H_est)\n",
        "#     H_est_vec_1 = torch.reshape(H_est_1, [Nt * Nr, 1])\n",
        "#     H_est_vec_2 = torch.reshape(H_est_2, [Nt * Nr, 1])\n",
        "#     H_est_vec_3 = torch.reshape(H_est_3, [Nt * Nr, 1])\n",
        "#     H_est_vec_4 = torch.reshape(H_est_4, [Nt * Nr, 1])\n",
        "\n",
        "#     H_raw_vec = torch.reshape(H_raw, [Nt * Nr, 1])\n",
        "\n",
        "#     mse_1       = (torch.norm(H_raw_vec - H_est_vec_1)**2) / len(H_raw_vec)\n",
        "#     mse_2       = (torch.norm(H_raw_vec - H_est_vec_2)**2) / len(H_raw_vec)\n",
        "#     mse_3       = (torch.norm(H_raw_vec - H_est_vec_3)**2) / len(H_raw_vec)\n",
        "#     mse_4       = (torch.norm(H_raw_vec - H_est_vec_4)**2) / len(H_raw_vec)\n",
        "\n",
        "#     sigEner   = torch.norm(H_raw_vec)**2\n",
        "\n",
        "#     nmse_1      = mse_1 / sigEner\n",
        "#     nmse_2      = mse_2 / sigEner\n",
        "#     nmse_3      = mse_3 / sigEner\n",
        "#     nmse_4      = mse_4 / sigEner\n",
        "\n",
        "#     # Best nmse\n",
        "#     nmse        = min([nmse_1, nmse_2, nmse_3, nmse_4])\n",
        "\n",
        "#     return torch.abs(nmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DyrfkYT2qEnN"
      },
      "outputs": [],
      "source": [
        "def NMSE(H_est, H_raw):\n",
        "    H_est_1, H_est_2, H_est_3, H_est_4 = reconstruct_channel(H_est)\n",
        "\n",
        "    # Lấy phần thực của các tensor nếu chúng là complex\n",
        "    H_est_vec_1 = torch.reshape(H_est_1, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_2 = torch.reshape(H_est_2, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_3 = torch.reshape(H_est_3, [Nt * Nr, 1]).abs()\n",
        "    H_est_vec_4 = torch.reshape(H_est_4, [Nt * Nr, 1]).abs()\n",
        "\n",
        "    H_raw_vec = torch.reshape(H_raw, [Nt * Nr, 1]).abs()\n",
        "\n",
        "    mse_1 = (torch.norm(H_raw_vec - H_est_vec_1)**2) / len(H_raw_vec)\n",
        "    mse_2 = (torch.norm(H_raw_vec - H_est_vec_2)**2) / len(H_raw_vec)\n",
        "    mse_3 = (torch.norm(H_raw_vec - H_est_vec_3)**2) / len(H_raw_vec)\n",
        "    mse_4 = (torch.norm(H_raw_vec - H_est_vec_4)**2) / len(H_raw_vec)\n",
        "\n",
        "    sigEner = torch.norm(H_raw_vec)**2\n",
        "\n",
        "    nmse_1 = mse_1 / sigEner\n",
        "    nmse_2 = mse_2 / sigEner\n",
        "    nmse_3 = mse_3 / sigEner\n",
        "    nmse_4 = mse_4 / sigEner\n",
        "\n",
        "    # Chọn NMSE tốt nhất\n",
        "    nmse = min([nmse_1, nmse_2, nmse_3, nmse_4])\n",
        "\n",
        "    return torch.abs(nmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pyjIgxUurU0P"
      },
      "outputs": [],
      "source": [
        "def Input_ISDNN(mode, DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, N_samp):\n",
        "    H_in = []        # ! H_in    , np.diag(np.diag()) return a diag matrix instead of diag components.\n",
        "    H_true = []   # ! generated s\n",
        "    H_raw = []\n",
        "    # y = []\n",
        "    e = []        # ! vector errors\n",
        "    xTx = []\n",
        "    xTy = []\n",
        "    Di = []\n",
        "    steering = [] # ! Steering vector: ZoA and AoA\n",
        "\n",
        "    if mode == 'train':\n",
        "        n_sample = N_samp * len(SNR)\n",
        "    else:\n",
        "        n_sample = N_samp\n",
        "\n",
        "    for i in range (n_sample):\n",
        "        H_true.append(torch.tensor(DataSet_HH[i]))\n",
        "        H_raw.append(torch.tensor(DataSet_H[i]))\n",
        "        # y.append(torch.tensor(DataSet_y[i]))\n",
        "        Di.append(torch.tensor(np.linalg.pinv(np.diag(np.diag(np.dot(DataSet_x[i].transpose(), DataSet_x[i]))))))\n",
        "        xTy.append(torch.tensor(np.dot(DataSet_x[i].transpose(), DataSet_y[i])))\n",
        "        H_in.append(torch.matmul(Di[i], xTy[i]))\n",
        "        e.append(torch.rand([2*Nt, 2*Nr]))\n",
        "        xTx.append(torch.tensor(np.dot(DataSet_x[i].transpose(), DataSet_x[i])))\n",
        "        steering.append(torch.tensor(DataSet_Steering[i]))\n",
        "\n",
        "    H_true = torch.stack(H_true, dim=0)\n",
        "    H_raw = torch.stack(H_raw, dim=0)\n",
        "    H_in = torch.stack(H_in, dim=0)\n",
        "    # y = torch.stack(y, dim=0)\n",
        "    e = torch.stack(e, dim=0)\n",
        "    xTx = torch.stack(xTx, dim=0)\n",
        "    xTy = torch.stack(xTy, dim=0)\n",
        "    Di = torch.stack(Di, dim=0)\n",
        "    steering = torch.stack(steering, dim=0)\n",
        "\n",
        "    return H_true, H_raw, H_in, e, xTx, xTy, Di, steering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGhdBsghq3M9"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GHceh5kuq3ZD"
      },
      "outputs": [],
      "source": [
        "class xv(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(xv, self).__init__()\n",
        "\n",
        "        self.alpha1 = torch.nn.parameter.Parameter(torch.rand(1))\n",
        "        self.alpha2 = torch.nn.parameter.Parameter(torch.tensor([0.5]))\n",
        "\n",
        "    def forward(self, Di, H, e, xTx, xTy):\n",
        "\n",
        "        xTxH = torch.bmm(xTx, H)\n",
        "\n",
        "        z    = H + torch.bmm(Di, torch.sub(xTy, xTxH)) + self.alpha1 * e\n",
        "\n",
        "        e    = torch.sub(xTy, xTxH)\n",
        "\n",
        "        H    = torch.add((1 - self.alpha2) * z, self.alpha2 * H)\n",
        "\n",
        "        return H, e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "woRjD7lJssRq"
      },
      "outputs": [],
      "source": [
        "class model_driven(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(model_driven, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc2 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc3 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc4 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc5 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc6 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc7 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "        self.fc8 = torch.nn.Linear(2*Nr, 2*Nr)\n",
        "\n",
        "        self.layer1=xv()\n",
        "        self.layer2=xv()\n",
        "        self.layer3=xv()\n",
        "        self.layer4=xv()\n",
        "\n",
        "    def forward(self, Di, H_in, e, xTx, xTy):\n",
        "        e = self.fc1(e)\n",
        "        e = self.fc2(e)\n",
        "        H, e = self.layer1(Di, H_in, e, xTx, xTy)\n",
        "        H = torch.tanh(H)\n",
        "\n",
        "        e = self.fc3(e)\n",
        "        e = self.fc4(e)\n",
        "        H, e = self.layer2(Di, H, e, xTx, xTy)\n",
        "        H = torch.tanh(H)\n",
        "\n",
        "        e = self.fc5(e)\n",
        "        e = self.fc6(e)\n",
        "        H, e = self.layer3(Di, H, e, xTx, xTy)\n",
        "        H = torch.tanh(H)\n",
        "\n",
        "        e = self.fc7(e)\n",
        "        e = self.fc8(e)\n",
        "        H, e = self.layer4(Di, H, e, xTx, xTy)\n",
        "\n",
        "        return H, e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZjihTOXq3kG"
      },
      "source": [
        "# Define model, optimizer, and loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Vp9fRd3gq3tw"
      },
      "outputs": [],
      "source": [
        "def def_model():\n",
        "    model = model_driven()\n",
        "    loss = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    folder_model = './model/'\n",
        "\n",
        "    if not os.path.isdir(folder_model):\n",
        "        os.makedirs(folder_model)\n",
        "\n",
        "    file_model = folder_model + 'H'\n",
        "    # if os.path.isfile(file_model):\n",
        "    #     generator = torch.load(file_model)\n",
        "\n",
        "    record_file = 'H'\n",
        "    return model, loss, optimizer, record_file, file_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYWM7SzItKzS"
      },
      "source": [
        "# Main program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jv7lDwyxtFe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c740a41e-a7f7-4b93-e491-7fb81ad9f265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3e5f3c45b18a>:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  dP[i] = abs(IFsig[i])**2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dữ liệu đã được sinh và lưu lại!\n",
            "Begin training...\n",
            "175.60527557710796\n",
            "178.3023011917328\n",
            "179.43847825491903\n",
            "179.52473651124953\n",
            "177.13123003629508\n",
            "175.5193690224948\n",
            "169.2663680987919\n",
            "179.3082417679707\n",
            "174.7973329857093\n",
            "176.45434696527207\n",
            "175.9441725703673\n",
            "173.81181875400947\n",
            "172.50964317559294\n",
            "175.52677019923001\n",
            "176.22596699145558\n",
            "180.8685222066804\n",
            "173.19259846114042\n",
            "177.1800647239742\n",
            "173.86024905101985\n",
            "176.6710765342506\n",
            "175.618302598932\n",
            "173.20546174047303\n",
            "170.54016631443565\n",
            "177.7149623212289\n",
            "178.37556068741586\n",
            "174.41183927226078\n",
            "176.3300957712822\n",
            "175.95051100393064\n",
            "173.64964415056878\n",
            "176.92186426673717\n",
            "178.19680830028187\n",
            "180.09752242922616\n",
            "172.86390734932058\n",
            "174.63679016345944\n",
            "174.4952855299958\n",
            "174.13446129896016\n",
            "171.49354546587634\n",
            "176.1937962822552\n",
            "177.18006697294837\n",
            "177.35370652272468\n",
            "173.33206300823244\n",
            "177.76447852917576\n",
            "177.26005714214\n",
            "172.08695696635002\n",
            "178.29221173840466\n",
            "179.8397474028208\n",
            "179.02826469975304\n",
            "175.1583702138025\n",
            "177.39273410296425\n",
            "171.73363484382057\n",
            "174.9023793972323\n",
            "175.03598057757463\n",
            "180.20356121573897\n",
            "173.5806262747631\n",
            "179.5312364407938\n",
            "173.5424526685037\n",
            "178.13945940514813\n",
            "176.6919604258169\n",
            "173.16277434382118\n",
            "178.31519263207366\n",
            "175.72103251700443\n",
            "180.23605099923665\n",
            "175.0395211379695\n",
            "177.08442721636666\n",
            "177.0645513367273\n",
            "180.6921143893391\n",
            "175.37937314284778\n",
            "171.4885672908943\n",
            "172.72210110343633\n",
            "177.08163117656792\n",
            "178.54025107415293\n",
            "174.93804872594794\n",
            "179.42419558719638\n",
            "171.65005249299148\n",
            "174.66434149790135\n",
            "173.96531698461706\n",
            "176.73204687324971\n",
            "174.82585736412773\n",
            "176.90054411268017\n",
            "174.68354284838378\n",
            "174.49659832904376\n",
            "172.80377584283352\n",
            "174.10582518454368\n",
            "176.49890193107015\n",
            "177.48904238770646\n",
            "178.69519671349357\n",
            "178.23539044749802\n",
            "176.58720135759935\n",
            "178.80988811794043\n",
            "176.75099337728025\n",
            "174.83489891703482\n",
            "172.72578657170027\n",
            "175.77251869596503\n",
            "178.39350869572723\n",
            "178.06839927929136\n",
            "176.4460110197787\n",
            "176.31555285130702\n",
            "179.08329625519704\n",
            "178.63590023382872\n",
            "179.035879739531\n",
            "178.64030616115582\n",
            "175.75361609252482\n",
            "176.37412662196516\n",
            "177.77522113084254\n",
            "176.3900916678969\n",
            "172.41011443063343\n",
            "174.45628021967855\n",
            "176.62620341314937\n",
            "174.81180512598442\n",
            "177.82660783159972\n",
            "177.14340846278606\n",
            "174.20630917977908\n",
            "176.89023108307813\n",
            "178.35438940275824\n",
            "176.61462128480463\n",
            "173.15950066293018\n",
            "178.13251503727903\n",
            "178.12963286918168\n",
            "177.20280949105984\n",
            "177.79700706800898\n",
            "174.56467213966397\n",
            "175.69316329746124\n",
            "180.17900799141668\n",
            "171.48177191958632\n",
            "178.75272823210713\n",
            "178.56615698692184\n",
            "180.22605022618544\n",
            "175.7773117835116\n",
            "177.41029606972597\n",
            "179.03608046775878\n",
            "167.26081974801565\n",
            "175.92928401567002\n",
            "179.00898631449706\n",
            "173.61807791487863\n",
            "173.99927732742503\n",
            "173.6651837819139\n",
            "174.41311072208333\n",
            "177.06211432531137\n",
            "170.4510576979086\n",
            "176.0712189110621\n",
            "178.24471842086763\n",
            "172.5803556966832\n",
            "174.42180900620653\n",
            "170.74143865810066\n",
            "176.54720660218868\n",
            "176.34287867452457\n",
            "176.23175269939966\n",
            "177.43250317708086\n",
            "176.1673954332507\n",
            "173.6564361402298\n",
            "173.3516449074261\n",
            "179.01659737267642\n",
            "172.70522376825207\n",
            "177.32243392796542\n",
            "177.1072710701301\n",
            "173.7214198086709\n",
            "178.36676141770434\n",
            "175.1183639522022\n",
            "173.9296137878642\n",
            "174.7859494133752\n",
            "181.91889109754916\n",
            "177.82926857355355\n",
            "177.38380222942712\n",
            "176.65727612340584\n",
            "178.08524277531282\n",
            "174.86152477164316\n",
            "177.49381096770026\n",
            "175.03455627238932\n",
            "176.54272707546596\n",
            "175.80994954236274\n",
            "169.72230584065758\n",
            "177.77682246804645\n",
            "181.83981782908361\n",
            "172.88427241644962\n",
            "175.24011798512794\n",
            "173.81189075407428\n",
            "181.15894502775456\n",
            "175.20586539943966\n",
            "177.69870562734485\n",
            "172.95153696621458\n",
            "173.47603400017442\n",
            "174.68237060682412\n",
            "175.58908043877182\n",
            "179.3519916410248\n",
            "178.9619847058251\n",
            "175.82636107156168\n",
            "181.18284851198297\n",
            "178.0302751138435\n",
            "176.76935879230254\n",
            "174.5364094481142\n",
            "175.32875819990915\n",
            "172.54426207999109\n",
            "174.83300075966395\n",
            "176.53587601357324\n",
            "172.7412282982391\n",
            "175.64156541311425\n",
            "176.9335308678168\n",
            "175.10346044143026\n",
            "173.01875983218443\n",
            "174.55970835296316\n",
            "175.23088888802044\n",
            "174.6293887699731\n",
            "174.7263054921425\n",
            "175.74342942744684\n",
            "173.83842898531242\n",
            "177.22697455711716\n",
            "175.6572682688279\n",
            "178.00911979777575\n",
            "180.2388151939618\n",
            "174.61514669311782\n",
            "177.56828516352294\n",
            "169.79172112867616\n",
            "174.71820049093358\n",
            "175.1425372619694\n",
            "171.06476616576612\n",
            "174.92722466380243\n",
            "170.89511177553064\n",
            "178.43185062876404\n",
            "175.66560202280095\n",
            "174.6985327699395\n",
            "175.1265137987053\n",
            "174.84551393688707\n",
            "176.35708306271152\n",
            "173.21605389750732\n",
            "173.0587078514227\n",
            "176.26200871136479\n",
            "171.52261510891879\n",
            "175.26871427563051\n",
            "176.22377791100072\n",
            "176.65960288492607\n",
            "177.47101249011584\n",
            "174.0425477364075\n",
            "176.914201063729\n",
            "174.74343384596077\n",
            "174.80326856323038\n",
            "175.04248435362527\n",
            "181.1009044541221\n",
            "178.18151493911049\n",
            "173.71463988380225\n",
            "168.59443838800672\n",
            "179.3595353586361\n",
            "176.32743496132588\n",
            "176.32456799276528\n",
            "176.0308885028001\n",
            "170.96501696780942\n",
            "177.96007397297467\n",
            "171.05205596901763\n",
            "175.9041505056213\n",
            "174.591078719059\n",
            "181.02259035030295\n",
            "179.97013170857267\n",
            "177.09475597585234\n",
            "178.11555025196782\n",
            "178.662342716442\n",
            "178.57115937755296\n",
            "174.41001344664662\n",
            "174.45728360369856\n",
            "178.60722056572382\n",
            "179.12508949218676\n",
            "180.80404338012218\n",
            "178.10292658972395\n",
            "176.23790774112524\n",
            "172.83421617685804\n",
            "176.34186271889135\n",
            "176.0136801360507\n",
            "174.7426280575755\n",
            "176.44992351225213\n",
            "177.40001224696178\n",
            "179.95177327975333\n",
            "177.55089560570028\n",
            "177.38435445191055\n",
            "175.53137564210974\n",
            "177.78754408334405\n",
            "178.4774752293771\n",
            "174.8577549927678\n",
            "168.46232628053033\n",
            "174.27938462480873\n",
            "173.77811261724776\n",
            "178.94218693049817\n",
            "178.8022243427933\n",
            "177.30192776664123\n",
            "174.5369175300157\n",
            "174.39217060119117\n",
            "173.9765838140273\n",
            "179.6214466804224\n",
            "176.45245843112716\n",
            "180.95880688557116\n",
            "179.12818291112893\n",
            "174.82267102030244\n",
            "176.99042270509645\n",
            "175.213880575014\n",
            "177.9485866782279\n",
            "176.40117203249065\n",
            "176.23183563222474\n",
            "176.6409156914558\n",
            "175.60528102841732\n",
            "175.24666969835664\n",
            "178.02119384747954\n",
            "173.63142318340707\n",
            "175.29183590614926\n",
            "179.41668409199784\n",
            "174.33543749331423\n",
            "179.11210958438\n",
            "177.30424740152898\n",
            "176.08121950564023\n",
            "169.08729012880295\n",
            "171.86839955476486\n",
            "179.88550949118112\n",
            "174.35471723594216\n",
            "181.22984846472528\n",
            "177.96467254075617\n",
            "174.4594247302616\n",
            "174.3872191821438\n",
            "180.30293975796266\n",
            "180.52999341868392\n",
            "172.55759085458405\n",
            "173.11189941782132\n",
            "173.04433357309873\n",
            "178.3448930187706\n",
            "175.44606894725203\n",
            "169.50553979583188\n",
            "176.11621497501758\n",
            "175.19174903154325\n",
            "175.70117317675005\n",
            "175.596970350334\n",
            "176.0595527058077\n",
            "177.96151482028077\n",
            "178.6241697242915\n",
            "176.7835698937182\n",
            "174.70323112697216\n",
            "176.43087578390796\n",
            "174.17193574246383\n",
            "176.3144675626135\n",
            "178.00494681330426\n",
            "173.39744386278952\n",
            "173.10198504025763\n",
            "169.72537731301375\n",
            "175.46537090090914\n",
            "176.15776780739597\n",
            "172.6937462988551\n",
            "173.74181067126023\n",
            "176.83673662642445\n",
            "174.5033120202078\n",
            "177.6030999263628\n",
            "175.05242366766348\n",
            "178.68069070240264\n",
            "179.6517453907539\n",
            "169.4284218894245\n",
            "177.0406930359172\n",
            "180.08785748131478\n",
            "176.79992370842533\n",
            "176.0886572622096\n",
            "172.18130456897\n",
            "174.74127489609037\n",
            "175.97316362376975\n",
            "171.13926001890673\n",
            "172.49988938141402\n",
            "178.8089759921295\n",
            "176.9300164825924\n",
            "174.98848829384474\n",
            "170.90751948451864\n",
            "176.02373848040557\n",
            "175.86430209095474\n",
            "173.83692654864217\n",
            "179.06468117884415\n",
            "179.00794601000314\n",
            "175.27461745043968\n",
            "173.45101975439837\n",
            "176.0030108435687\n",
            "178.0002449825036\n",
            "180.22034664278326\n",
            "179.27149680630043\n",
            "174.2158961837776\n",
            "175.85105880620725\n",
            "175.52090256712947\n",
            "174.73884592495668\n",
            "179.4647307894988\n",
            "173.22119216206573\n",
            "177.79003940030046\n",
            "175.38960403464182\n",
            "173.2962528395699\n",
            "173.7385060798452\n",
            "178.5824202579366\n",
            "170.86375225557373\n",
            "172.23202030992195\n",
            "171.10729246278217\n",
            "177.72098604826434\n",
            "175.74484425442085\n",
            "177.8425919454081\n",
            "176.12413420039243\n",
            "174.6972298609843\n",
            "178.72285241486955\n",
            "176.04725119981077\n",
            "172.92082890846962\n",
            "177.01552608183502\n",
            "174.75640613861455\n",
            "174.14993814612853\n",
            "174.3660883585939\n",
            "180.46333732973773\n",
            "174.35926217820233\n",
            "176.47564078856638\n",
            "171.63976417889882\n",
            "176.21581087538027\n",
            "178.01378964365148\n",
            "178.93977210770095\n",
            "177.4716670955212\n",
            "173.71386186750155\n",
            "181.06848057084542\n",
            "174.52534950750868\n",
            "172.81552308495174\n",
            "176.82410812371631\n",
            "179.08091128439594\n",
            "176.5653994475305\n",
            "165.9590215834285\n",
            "175.97936166977337\n",
            "172.3320587614243\n",
            "177.1278809521911\n",
            "178.8399235629193\n",
            "175.68093226441843\n",
            "172.18630306200797\n",
            "174.12771006640128\n",
            "179.80515066049801\n",
            "175.42856639409905\n",
            "169.94951994114393\n",
            "169.27008519969684\n",
            "176.4690902734045\n",
            "169.16545239232335\n",
            "172.92782534209468\n",
            "174.041282864467\n",
            "180.45115333259713\n",
            "177.00345258727344\n",
            "181.0613933865153\n",
            "175.62770429906146\n",
            "180.42999083166268\n",
            "175.29270919432972\n",
            "178.2623123927243\n",
            "174.37735844854967\n",
            "177.69525606994526\n",
            "178.37288209057743\n",
            "174.41743294971758\n",
            "174.1626142140959\n",
            "172.7652426114178\n",
            "177.4690628616811\n",
            "173.30514598583244\n",
            "174.2913483984511\n",
            "171.34912757263882\n",
            "173.23068427183617\n",
            "179.04273927826816\n",
            "173.48757546409652\n",
            "175.80862295061112\n",
            "173.67893711799888\n",
            "174.56382792700376\n",
            "172.26593175271717\n",
            "178.186291769105\n",
            "177.55639452735\n",
            "176.79733385628253\n",
            "177.3596684023114\n",
            "172.27531889549073\n",
            "176.98538963973994\n",
            "175.0103555159901\n",
            "179.35965106245226\n",
            "173.93667082763025\n",
            "173.09924832704155\n",
            "171.39742249652178\n",
            "177.4223542601532\n",
            "172.51783425991474\n",
            "176.9782167799282\n",
            "173.730597868341\n",
            "174.4399225919671\n",
            "179.05860595413432\n",
            "173.83765765845018\n",
            "179.7307918146643\n",
            "174.1637999325706\n",
            "181.78350418082397\n",
            "176.43966764825126\n",
            "175.4336555530811\n",
            "175.997513734819\n",
            "176.10401158791225\n",
            "172.57289120615934\n",
            "174.13424828619114\n",
            "178.8137574764609\n",
            "175.00165995351398\n",
            "178.04384730039283\n",
            "174.59507607806353\n",
            "178.85957855281978\n",
            "173.4434256211429\n",
            "174.2692513802228\n",
            "179.3596000796478\n",
            "173.0286770228955\n",
            "175.94272683278842\n",
            "176.1996902679196\n",
            "173.7780154577373\n",
            "173.51211195723477\n",
            "179.005009387532\n",
            "178.11023582511473\n",
            "179.32131942713409\n",
            "178.24095271120956\n",
            "173.83467763566952\n",
            "176.66831022754573\n",
            "174.15947505097364\n",
            "176.56292028136798\n",
            "176.11226089740668\n",
            "176.78554219580406\n",
            "176.87799539992656\n",
            "178.92320489708635\n",
            "173.95614894786414\n",
            "176.38394687737468\n",
            "176.63524532289742\n",
            "180.59033872866115\n",
            "175.28076220383366\n",
            "175.43612391250895\n",
            "175.71305152750975\n",
            "138.64307208810845\n",
            "139.84101354098794\n",
            "141.8521120761042\n",
            "138.65547188189987\n",
            "137.85342488801382\n",
            "134.02645610292797\n",
            "130.89846137085763\n",
            "141.62204939391944\n",
            "133.74132399534673\n",
            "140.4535129802268\n",
            "137.62948909185485\n",
            "136.80170614921136\n",
            "130.5647748604457\n",
            "134.4098209042824\n",
            "138.83379439720318\n",
            "139.8750770997884\n",
            "135.28163429352762\n",
            "138.05571673261306\n",
            "137.07300098556232\n",
            "138.17335007546163\n",
            "137.08302863107454\n",
            "133.85241058922205\n",
            "134.86617824206613\n",
            "137.68817254825422\n",
            "139.96355822110993\n",
            "136.98373868807568\n",
            "138.99053607607715\n",
            "136.2270153179217\n",
            "132.33251765877708\n",
            "137.32092049023976\n",
            "139.78560652833528\n",
            "139.71393679595906\n",
            "132.86142058799646\n",
            "132.96885503718676\n",
            "135.74132261000366\n",
            "137.36214263661512\n",
            "132.34205946760872\n",
            "135.63321755059016\n",
            "137.2160692047115\n",
            "136.19128241349054\n",
            "134.7117542342619\n",
            "137.93116934808148\n",
            "138.85070019362405\n",
            "131.83684480195305\n",
            "140.02661497340117\n",
            "141.38420064300425\n",
            "136.4748428394712\n",
            "134.54411437534822\n",
            "137.03580433096897\n",
            "132.58773726080378\n",
            "136.69385429805044\n",
            "137.62471933327006\n",
            "138.1403779277202\n",
            "133.80793503055514\n",
            "138.36798583171964\n",
            "135.47390457175987\n",
            "136.51272760909805\n",
            "135.8132845757752\n",
            "135.36307055514516\n",
            "139.8597925008767\n",
            "138.18231040547244\n",
            "141.6788121099367\n",
            "134.95391851627724\n",
            "138.820888130394\n",
            "139.22094477271065\n",
            "141.38413529959212\n",
            "136.4645692701051\n",
            "132.55048182263826\n",
            "135.38744372735454\n",
            "136.26325352027865\n",
            "139.58098001648358\n",
            "134.85598241335683\n",
            "140.54209095915243\n",
            "131.6135995303211\n",
            "137.68734501869454\n",
            "135.97312225090158\n",
            "137.433280934418\n",
            "136.4325747567504\n",
            "138.39116479478167\n",
            "136.70207241723045\n",
            "136.81206918518464\n",
            "135.40284991771136\n",
            "132.82343730863272\n",
            "136.9659002278529\n",
            "139.45540806737708\n",
            "139.02365330555367\n",
            "139.1893764650939\n",
            "137.8082987605923\n",
            "138.1989545123579\n",
            "136.3473353189881\n",
            "135.70437227507037\n",
            "133.442373155837\n",
            "135.63915004102628\n",
            "137.7966250711467\n",
            "136.5733610683203\n",
            "136.80836953047287\n",
            "135.65825612221232\n",
            "139.27042472824473\n",
            "138.36015722173647\n",
            "139.52310840089555\n",
            "138.72588236067736\n",
            "139.14542428845215\n",
            "134.46672847775818\n",
            "136.5129376578529\n",
            "136.8536918000243\n",
            "137.20951479302832\n",
            "133.9588489432539\n",
            "135.1064391161168\n",
            "136.2530938410015\n",
            "138.08353143568914\n",
            "136.42056331834902\n",
            "134.14903771896255\n",
            "137.9362446515276\n",
            "138.21458215521264\n",
            "138.19317866765962\n",
            "135.77463067006357\n",
            "139.52171842372917\n",
            "138.4506032652653\n",
            "136.1021033051738\n",
            "140.2204793493878\n",
            "134.44311415900958\n",
            "137.6515151990709\n",
            "138.8343587864864\n",
            "133.94496044645712\n",
            "139.01490689510982\n",
            "139.3258314472733\n",
            "138.83761341759129\n",
            "135.33210389943883\n",
            "136.16823176938325\n",
            "140.9608253067243\n",
            "131.18440887974052\n",
            "136.88223784900907\n",
            "139.39604713997556\n",
            "135.8538413587272\n",
            "133.93775196343415\n",
            "135.73817697378584\n",
            "136.71347586297378\n",
            "136.4159909093146\n",
            "134.25682973264594\n",
            "137.3151454824225\n",
            "138.73414135055936\n",
            "134.73826715505083\n",
            "136.1130529155199\n",
            "132.43757374719283\n",
            "137.4236291981343\n",
            "133.6179641183077\n",
            "137.36500963346307\n",
            "137.6674321796036\n",
            "137.26645424795456\n",
            "133.37122821944328\n",
            "132.4573869545949\n",
            "140.34455414816398\n",
            "133.86226949698644\n",
            "138.43041234597013\n",
            "136.3361584326358\n",
            "133.5531121371972\n",
            "139.12268550895976\n",
            "136.3521240243089\n",
            "137.13492104021617\n",
            "133.74778177925285\n",
            "140.54656553094551\n",
            "138.1042190140085\n",
            "138.1362882726924\n",
            "133.53749429065428\n",
            "137.73375739861058\n",
            "136.6608486322114\n",
            "137.27567216037883\n",
            "136.43811850076258\n",
            "137.7302865623398\n",
            "137.37969078376375\n",
            "131.18188235010655\n",
            "136.2713345308958\n",
            "144.0883442473128\n",
            "132.188254566885\n",
            "135.59020063615299\n",
            "134.7176668118859\n",
            "142.2409518446181\n",
            "135.1503638753727\n",
            "138.86875248778654\n",
            "134.2901381444209\n",
            "133.9927870803199\n",
            "134.3669211901795\n",
            "134.857913998773\n",
            "140.87401566225722\n",
            "140.19750131490107\n",
            "137.57646912711266\n",
            "142.2525828743537\n",
            "136.18701930235753\n",
            "137.3751363314054\n",
            "133.9522300391032\n",
            "136.7152527390422\n",
            "137.05466749719753\n",
            "135.95263778577137\n",
            "136.5867180853705\n",
            "133.58753942372817\n",
            "136.83995214832868\n",
            "136.46025186625099\n",
            "136.45228895722002\n",
            "133.97955265846034\n",
            "136.2949691897565\n",
            "132.83855545911038\n",
            "135.72025360945125\n",
            "133.34216528830703\n",
            "135.92791413585036\n",
            "134.9360803311445\n",
            "135.5718098012474\n",
            "136.24571971637818\n",
            "137.58036319374975\n",
            "142.05175365344658\n",
            "135.60745217703837\n",
            "137.91527643074508\n",
            "131.9826227119707\n",
            "135.53797041261564\n",
            "137.2002988056062\n",
            "131.04887416789745\n",
            "137.4185832371698\n",
            "130.8816958025055\n",
            "142.76039667629374\n",
            "135.4523259841357\n",
            "135.52888418555713\n",
            "135.14981715825658\n",
            "134.79668447454\n",
            "135.88962151220707\n",
            "134.80624805297927\n",
            "133.98749521630234\n",
            "135.76384666512092\n",
            "134.46289735963364\n",
            "135.43404519408722\n",
            "138.7005917594791\n",
            "137.0972308547645\n",
            "138.6580375484224\n",
            "135.1857940315339\n",
            "138.42017208954158\n",
            "136.04290799591053\n",
            "135.92210536905617\n",
            "134.9631709661852\n",
            "139.2171305668289\n",
            "139.8628470559631\n",
            "134.29361569953147\n",
            "128.85156301320453\n",
            "137.8978336121573\n",
            "137.73345697848512\n",
            "139.4311159944782\n",
            "134.94283313847336\n",
            "131.1267463922353\n",
            "141.4579599209527\n",
            "131.47473281234\n",
            "135.65401230626043\n",
            "136.95499359440052\n",
            "139.5912826194128\n",
            "141.17910015231413\n",
            "137.47634798750863\n",
            "138.55443443280473\n",
            "139.77678504153928\n",
            "140.47117524319845\n",
            "134.06759893060803\n",
            "135.28574942572962\n",
            "138.73764876086824\n",
            "139.42448381410804\n",
            "141.26130334336267\n",
            "136.7556902411571\n",
            "137.9179808067828\n",
            "134.88031973928906\n",
            "139.964101413999\n",
            "138.19415280494263\n",
            "137.9400100653704\n",
            "139.5969434368746\n",
            "138.88607013242915\n",
            "141.33593039000147\n",
            "137.9240006380655\n",
            "136.4447446470798\n",
            "136.50966207574618\n",
            "138.35350404241393\n",
            "139.73137126273514\n",
            "135.79255006374623\n",
            "131.26778797940426\n",
            "137.71472385781658\n",
            "134.78186587646624\n",
            "138.0779453219238\n",
            "141.05663549311936\n",
            "136.42517647589057\n",
            "134.1065140622931\n",
            "135.5602761515129\n",
            "135.0750641856044\n",
            "140.48270089014116\n",
            "138.1516530332565\n",
            "143.17119990943272\n",
            "141.8350078503693\n",
            "134.93020470701845\n",
            "138.24620289173748\n",
            "135.02532152891652\n",
            "140.28128479905214\n",
            "134.70569487463297\n",
            "137.59690443508723\n",
            "138.05884384402316\n",
            "135.7352978388082\n",
            "136.1338764375837\n",
            "140.22442330647175\n",
            "133.68343281917967\n",
            "136.77301234917996\n",
            "140.13692518014406\n",
            "134.2135371752774\n",
            "136.91934061492842\n",
            "135.77081022606598\n",
            "136.69429325208284\n",
            "129.93669419643447\n",
            "132.63527587472058\n",
            "140.36162822307642\n",
            "133.7679512178884\n",
            "140.1415569090389\n",
            "138.15069212390756\n",
            "134.5111758173794\n",
            "133.83510945607327\n",
            "142.56488927611457\n",
            "141.60081230423947\n",
            "134.52264780043694\n",
            "133.28201169478774\n",
            "135.58302045829046\n",
            "139.42098658925082\n",
            "138.1103543621868\n",
            "130.3359595464686\n",
            "137.44198100040393\n",
            "137.6373131917228\n",
            "136.46041242570016\n",
            "136.0664337260226\n",
            "136.55599098361148\n",
            "136.91549712915426\n",
            "139.35662386629213\n",
            "136.212380166701\n",
            "133.63471744781464\n",
            "136.12778948535083\n",
            "135.0423342736889\n",
            "136.91803553122745\n",
            "138.39199187378546\n",
            "135.99345714249904\n",
            "133.96461629600518\n",
            "130.58973486186179\n",
            "136.41333284300816\n",
            "137.31196084050146\n",
            "132.8217636527986\n",
            "134.0637497022289\n",
            "139.54774514295067\n",
            "134.4971451648639\n",
            "137.2596997041555\n",
            "136.79937210482794\n",
            "138.98589603245003\n",
            "139.45906479628022\n",
            "129.58978681662708\n",
            "138.08281594431588\n",
            "142.27952276908206\n",
            "135.88717162776555\n",
            "138.36445255121896\n",
            "133.83339093598875\n",
            "134.60256090020306\n",
            "134.8820982445574\n",
            "131.06635980969372\n",
            "133.06470834374838\n",
            "140.2741551865302\n",
            "138.19686252096255\n",
            "136.89125137692966\n",
            "132.79034953653917\n",
            "134.37874213079655\n",
            "135.73363717651426\n",
            "134.06256172020395\n",
            "139.55164907580027\n",
            "136.72574163999272\n",
            "135.75415934125476\n",
            "135.81965914254866\n",
            "137.0395995822426\n",
            "138.04902330171896\n",
            "140.47242973945635\n",
            "138.39431163687485\n",
            "133.70434154800913\n",
            "136.7169910546342\n",
            "139.1536746913901\n",
            "135.75686806816006\n",
            "139.51175046560817\n",
            "132.44136918918403\n",
            "137.9536383800992\n",
            "134.19819899237032\n",
            "134.16201551816724\n",
            "132.91301345690286\n",
            "137.05338195413177\n",
            "132.72027156047423\n",
            "130.82620885850258\n",
            "131.17218569393714\n",
            "135.78285951577737\n",
            "135.04944104015553\n",
            "139.44210251500385\n",
            "136.04884529989158\n",
            "137.10648234462744\n",
            "141.01072402925274\n",
            "136.63520758411406\n",
            "133.9285567923093\n",
            "138.66796635613065\n",
            "135.98904468004832\n",
            "134.31305665526367\n",
            "136.92635388221635\n",
            "140.65996864383047\n",
            "137.75434842453936\n",
            "136.72732645025798\n",
            "133.59938958688784\n",
            "137.98757688163587\n",
            "140.0448677939349\n",
            "141.14672192412604\n",
            "137.66128989983736\n",
            "134.0040280819464\n",
            "142.89667057073612\n",
            "132.57996700886895\n",
            "133.47795626501807\n",
            "136.59725596267003\n",
            "140.17793273629462\n",
            "137.48010867743483\n",
            "127.52738566954311\n",
            "138.67890438601273\n",
            "133.89131535877087\n",
            "135.46182686214786\n",
            "137.26346870202931\n",
            "138.7967229340994\n",
            "132.86392343972008\n",
            "134.18923890826468\n",
            "141.04622407682305\n",
            "136.00602281558017\n",
            "133.25417784345476\n",
            "132.0277244681312\n",
            "139.9065825167795\n",
            "132.16051001222226\n",
            "132.56966345623906\n",
            "133.7885535085877\n",
            "142.38065452977585\n",
            "136.61063776060297\n",
            "143.37838338778957\n",
            "136.11858983003182\n",
            "141.55709487384883\n",
            "135.89692244305786\n",
            "140.35226104217335\n",
            "135.37457643753962\n",
            "137.94368147723065\n",
            "138.70192526367006\n",
            "133.31764283053863\n",
            "136.45449700254323\n",
            "132.2657999257137\n",
            "134.6454469863523\n",
            "132.45646560185787\n",
            "137.5332763104705\n",
            "133.1686957287926\n",
            "133.35333534742733\n",
            "140.61894589207353\n",
            "134.78207766433266\n",
            "135.07749176992473\n",
            "136.3720268907877\n",
            "134.22211541003222\n",
            "133.50949319135233\n",
            "137.8537753050002\n",
            "138.7126292962856\n",
            "136.42430307633566\n",
            "139.69722894086084\n",
            "133.45616660958754\n",
            "138.4007644865013\n",
            "136.49415697752224\n",
            "138.4095130105525\n",
            "134.1792237948269\n",
            "133.95495542598985\n",
            "132.8942686293022\n",
            "139.17806400568668\n",
            "133.51005717209114\n",
            "138.36746008446906\n",
            "132.94892504007868\n",
            "137.01442916872426\n",
            "139.1112501397588\n",
            "135.92957469762254\n",
            "141.65533243089698\n",
            "132.5653321418252\n",
            "143.369944295946\n",
            "139.3503627738787\n",
            "136.02308226373302\n",
            "137.60154433476762\n",
            "137.8611153743323\n",
            "131.12416131535247\n",
            "134.44625070785577\n",
            "137.52926453902393\n",
            "136.58794111069773\n",
            "135.80442631645928\n",
            "137.89931322383853\n",
            "143.84316933930043\n",
            "131.5351627838519\n",
            "134.6336011376572\n",
            "140.48231478163\n",
            "134.6717828581071\n",
            "139.2774223720951\n",
            "137.837898572289\n",
            "132.12682320061506\n",
            "136.47682473124254\n",
            "141.65302955924255\n",
            "139.82258246942325\n",
            "139.9745947714833\n",
            "138.12086121250738\n",
            "136.66762473105968\n",
            "137.4271031168219\n",
            "132.21624893003073\n",
            "140.65403683246967\n",
            "137.5534054287156\n",
            "139.38928376879747\n",
            "134.63168780009534\n",
            "137.8636280699398\n",
            "134.352337832424\n",
            "136.54734101446527\n",
            "138.40409815078254\n",
            "140.57426268379902\n",
            "137.8682285490467\n",
            "134.74951581632675\n",
            "138.85602337638556\n",
            "1 0.05569156275742048 21.58976484926748\n",
            "100 0.004220331176024941 1.3654450476836166\n",
            "200 0.0006377621125114739 0.8444692055442704\n",
            "300 0.0006196017327282605 0.7638242241977222\n",
            "400 0.0006114964204682424 0.8219753592762956\n",
            "500 0.0006715582687924755 0.7904172160761536\n",
            "600 0.006494534555308769 4.580050331647914\n",
            "700 0.0006146292933099294 0.9553959950092449\n",
            "2320.2633577789998\n"
          ]
        }
      ],
      "source": [
        "epoch         = 0\n",
        "expected_epoch = 20000\n",
        "num_samp      = N_samp * len(SNR)\n",
        "best_nmse     = 1e9\n",
        "early_stop    = 0\n",
        "best_model    = ''\n",
        "batch_size    = int(num_samp / 512)\n",
        "# DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering = Gen_dataset('train', 'UCyA', 0, 0, N_samp)\n",
        "# H_true, H_raw, H_in, e, xTx, xTy, Di, steering = Input_ISDNN('train', DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, N_samp)\n",
        "\n",
        "# Kiểm tra nếu file tĩnh tồn tại\n",
        "if os.path.exists('dataset_SISDNN.pkl'):\n",
        "    with open('dataset_SISDNN.pkl', 'rb') as f:\n",
        "        DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, H_true, H_raw, H_in, e, xTx, xTy, Di, steering = pickle.load(f)\n",
        "    print(\"Dữ liệu đã được tải từ file tĩnh!\")\n",
        "else:\n",
        "    # Sinh dữ liệu nếu file tĩnh không tồn tại\n",
        "    DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering = Gen_dataset('train', 'UCyA', 0, 0, N_samp)\n",
        "    H_true, H_raw, H_in, e, xTx, xTy, Di, steering = Input_ISDNN('train', DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, N_samp)\n",
        "\n",
        "    # Lưu dữ liệu để lần sau không phải sinh lại\n",
        "    with open('dataset_SISDNN.pkl', 'wb') as f:\n",
        "        pickle.dump((DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, H_true, H_raw, H_in, e, xTx, xTy, Di, steering), f)\n",
        "    print(\"Dữ liệu đã được sinh và lưu lại!\")\n",
        "\n",
        "print(\"Begin training...\")\n",
        "starttime = timeit.default_timer()\n",
        "\n",
        "while(True):\n",
        "        epoch = epoch + 1\n",
        "\n",
        "        init_loss = 1e9\n",
        "        while( epoch == 1 and init_loss > 150):\n",
        "\n",
        "                model, loss, optimizer, record_file, file_model = def_model()\n",
        "                for bs in range (int(num_samp / batch_size)):\n",
        "                    H_1, e_1 = model(Di[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 H_in[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 e[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTx[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTy[0 + batch_size * bs:batch_size * (bs+1), :, :])   # predict output from the model\n",
        "                    init_loss = loss(H_1, H_true[0 + batch_size * bs:batch_size * (bs+1), :, :]).item()\n",
        "                    print(init_loss)\n",
        "\n",
        "        optimizer.zero_grad()   # zero the parameter gradients\n",
        "        train_loss = 0\n",
        "        H_f = torch.empty([num_samp, 2*Nt, 2*Nr])\n",
        "        for bs in range (int(num_samp / batch_size)):\n",
        "                H_o, e_o = model(Di[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 H_in[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 e[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTx[0 + batch_size * bs:batch_size * (bs+1), :, :],\n",
        "                                 xTy[0 + batch_size * bs:batch_size * (bs+1), :, :])   # predict output from the model\n",
        "                H_f[0 + batch_size * bs:batch_size * (bs+1), :, :] = H_o\n",
        "                train_loss = loss(H_o,\n",
        "                                  H_true[0 + batch_size * bs:batch_size * (bs+1), :, :])   # calculate loss for the predicted output\n",
        "                train_loss.backward()   # backpropagate the loss\n",
        "                optimizer.step()        # adjust parameters based on the calculated gradients\n",
        "\n",
        "        if (epoch % 100 == 0 or epoch == 1):\n",
        "                nmse = 0\n",
        "                for j in range (num_samp):\n",
        "                        nmse += NMSE(H_f[j], H_raw[j])\n",
        "                nmse = nmse / num_samp\n",
        "\n",
        "                if (nmse <= best_nmse):\n",
        "                        torch.save(model.state_dict(), file_model + '_' + str(epoch) + '.pth')\n",
        "                        best_model = file_model + '_' + str(epoch) + '.pth'\n",
        "                        best_nmse = nmse\n",
        "                        early_stop = 0\n",
        "                else:\n",
        "                        early_stop += 1\n",
        "\n",
        "                if (nmse > best_nmse and early_stop == 3):\n",
        "                        with Record(record_file + '_log.txt'):\n",
        "                                print(epoch, nmse.item(), train_loss.item())\n",
        "                                print(str(timeit.default_timer()-starttime))\n",
        "                        break\n",
        "\n",
        "                with Record(record_file + '_log.txt'):\n",
        "                        print(epoch, nmse.item(), train_loss.item())\n",
        "\n",
        "        if epoch  == expected_epoch:\n",
        "                torch.save(model.state_dict(), file_model + '_' + str(epoch) + '.pth')\n",
        "                best_model = file_model + '_' + str(epoch) + '.pth'\n",
        "                with Record(record_file + '_log.txt'):\n",
        "                        print(\"epoch:\\n\", epoch)\n",
        "                        print(\"Latest NMSE:\\n\", nmse.item())\n",
        "                        print(\"Latest Loss:\\n\", train_loss.item())\n",
        "                        print(str(timeit.default_timer()-starttime))\n",
        "\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOBK-_l-tRMO"
      },
      "source": [
        "# Test function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRRFGAX4tg_6"
      },
      "source": [
        "# Function to test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SfvpexfwthNq"
      },
      "outputs": [],
      "source": [
        "# from scipy.io import savemat\n",
        "\n",
        "def test(H_raw, Di, H_in, e, xTx, xTy, N_test, log):\n",
        "    # Load the model that we saved at the end of the training loop\n",
        "    model = model_driven()\n",
        "    model.load_state_dict(torch.load(best_model, map_location=torch.device('cpu')))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        H_o, e_o = model(Di, H_in, e, xTx, xTy)\n",
        "\n",
        "        nmse = 0\n",
        "        for j in range (N_test):\n",
        "            nmse += NMSE(H_o[j], H_raw[j])\n",
        "\n",
        "        nmse = nmse / N_test\n",
        "        with Record(log):\n",
        "            print(format(nmse.item(), '.7f'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "x2Sx4hiqqEnP"
      },
      "outputs": [],
      "source": [
        "## Generate dataset for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "v1Vvpw6-qEnP"
      },
      "outputs": [],
      "source": [
        "def LS(DataSet_x, DataSet_y):\n",
        "    start = timeit.default_timer()\n",
        "    for i in range (len(DataSet_x)):\n",
        "        H_hat = np.matmul(\n",
        "                    np.matmul(\n",
        "                        np.linalg.pinv(np.matmul(DataSet_x[i].transpose(), DataSet_x[i])),\n",
        "                        DataSet_x[i].transpose()),\n",
        "                        DataSet_y[i])\n",
        "    print(timeit.default_timer() - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "xPXHJP8QqEnP",
        "outputId": "2fcda5b0-1be0-4b83-867d-1dbbf89b12cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3e5f3c45b18a>:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  dP[i] = abs(IFsig[i])**2\n",
            "<ipython-input-17-7d9cbc044369>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(best_model, map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0006922\n",
            "0.0006895\n",
            "0.0006920\n",
            "0.0006908\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7a5f24f9c0be>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# with Record(log):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#     print(snr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mDataSet_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_Steering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'UCyA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mH_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxTx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxTy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput_ISDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_HH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataSet_Steering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-12e7e3d5ebc9>\u001b[0m in \u001b[0;36mGen_dataset\u001b[0;34m(mode, array_type, snr, imperfect, N_samp)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrunIdx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_samp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m      \u001b[0;31m# ! 20000 x Nt: samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_oG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSteering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerate_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melements_nor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNr_ULA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNr_UCA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             HH = np.concatenate((np.concatenate((H_oG.real, H_oG.imag), axis=1),\n",
            "\u001b[0;32m<ipython-input-7-505537f7c596>\u001b[0m in \u001b[0;36mGenerate_channel\u001b[0;34m(Nt, Nr, d_H, array_type, elements_nor, type, Nr_ULA, Nr_UCA)\u001b[0m\n\u001b[1;32m     55\u001b[0m                         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mdh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                             \u001b[0mr_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZoa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAoa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                             \u001b[0mr_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZoa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAoa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                             \u001b[0mr_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZoa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "SNR_min_dB  = 0\n",
        "SNR_max_dB  = 20\n",
        "step_dB     = 5\n",
        "num_dB      = int((SNR_max_dB - SNR_min_dB) / step_dB) + 1\n",
        "\n",
        "SNR         = np.linspace(SNR_min_dB, SNR_max_dB, num=num_dB)\n",
        "log         = './model/log_test.txt'\n",
        "\n",
        "N_test = int(num_samp * 30 / 100)\n",
        "\n",
        "for i in range (100):\n",
        "    for snr in SNR:\n",
        "        # with Record(log):\n",
        "        #     print(snr)\n",
        "        DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering = Gen_dataset('test', 'UCyA', 0, 0, N_test)\n",
        "        H_true, H_raw, H_in, e, xTx, xTy, Di, steering = Input_ISDNN('test', DataSet_x, DataSet_y, DataSet_H, DataSet_HH, DataSet_Steering, N_test)\n",
        "\n",
        "        # LS(DataSet_x, DataSet_y)\n",
        "        test(H_raw, Di, H_in, e, xTx, xTy, N_test, log)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}